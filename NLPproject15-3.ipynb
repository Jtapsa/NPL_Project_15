{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rKRGRiSR_RU"
      },
      "source": [
        "# Project 15: Metaphor detection in poetry\n",
        "\n",
        "**Toivo Xiong, Joonas Tapaninaho**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXZ793h4SN6E"
      },
      "source": [
        "This project explores the detection of metaphors in poetry using natural language processing, aiming to\n",
        "distinguish figurative and non-figurative language.\n",
        "\n",
        "We shall consider the metaphor using FrameBERT whose implementation is available in GitHub -\n",
        "liyucheng09/MetaphorFrame: FrameBERT: Conceptual Metaphor Detection with Frame Embedding\n",
        "Learning. Presented at EACL 2023. as one of the state-of-the-art models in this field, and few dataset in the\n",
        "field. https://github.com/liyucheng09/MetaphorFrame\n",
        "\n",
        "Initially, we consider the verb metaphor as a classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D7xuZ7dCTl3y"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import nltk\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import numpy\n",
        "import requests\n",
        "import sklearn\n",
        "import scipy\n",
        "import torch\n",
        "import torchvision\n",
        "import tqdm\n",
        "import transformers\n",
        "\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "eIW3xDoTNK-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58593dd7-44c9-4b2c-ac54-d251612e6d6b",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.35.56-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting botocore<1.36.0,>=1.35.56 (from boto3)\n",
            "  Downloading botocore-1.35.56-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
            "  Downloading s3transfer-0.10.3-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.56->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.56->boto3) (2.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.56->boto3) (1.16.0)\n",
            "Downloading boto3-1.35.56-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.56-py3-none-any.whl (12.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.3-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.6/82.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.35.56 botocore-1.35.56 jmespath-1.0.1 s3transfer-0.10.3\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsauApFcR_Mt"
      },
      "source": [
        "**1. Consider the verb metaphor classification highlighted in metaphor/verbs/README.md at master ·\n",
        "EducationalTestingService/metaphor · GitHub, utilizing the Amsterdam Metaphor corpus. Suggest a\n",
        "script that uses NLTK library to tokenize the dataset, extract the individual tokens, sentences,\n",
        "vocabulary, total number of tokens, average number of token per sentence. Then use space Spacy\n",
        "named-entity tagger to identify the named-entities in the corpus and the average number of named-\n",
        "entity per tag. Summarize these statistical data in a table.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBA3SB77eOmx",
        "outputId": "6c363664-fe2e-418a-878b-b12d619d6131"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Name                                             Modified             Size\n",
            "2541/VUAMC.odd                                 2013-10-04 18:18:46        34535\n",
            "2541/VUAMC.rnc                                 2013-10-04 18:18:46        54689\n",
            "2541/VUAMC.rng                                 2013-10-04 18:18:46       132900\n",
            "2541/VUAMC.xml                                 2013-10-04 18:18:46     16820946\n",
            "2541.xml                                       2015-04-08 15:12:20         8092\n"
          ]
        }
      ],
      "source": [
        "# Downloading data set\n",
        "\n",
        "from zipfile import ZipFile\n",
        "from io import BytesIO\n",
        "\n",
        "VUA_corpus_url = 'https://web.archive.org/web/20151023150541/http://ota.ox.ac.uk/text/2541.zip'\n",
        "\n",
        "r = requests.get(VUA_corpus_url)\n",
        "\n",
        "with ZipFile(BytesIO(r.content), 'r') as zip:\n",
        "  zip.printdir()\n",
        "  file = zip.extract('2541/VUAMC.xml','r')\n",
        "\n",
        "with open(file) as f:\n",
        "  content = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(content, 'xml')\n",
        "\n",
        "# Extract all sentences in <s> tags\n",
        "sentences = [\" \".join(sentence.get_text().split()) for sentence in soup.find_all('s')]\n",
        "\n",
        "print(sentences[0:10])"
      ],
      "metadata": {
        "id": "8xZtVYDqmI6G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "845c57de-2c86-49df-9c6a-c2e554bf16ae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Latest corporate unbundler reveals laid-back approach : Roland Franklin , who is leading a 697m pound break-up bid for DRG , talks to Frank Kane', 'By FRANK KANE', 'IT SEEMS that Roland Franklin , the latest unbundler to appear in the UK , has made a fatal error in the preparation of his £697m break-up bid for stationery and packaging group DRG .', \"He has not properly investigated the target 's dining facilities .\", 'The 63-year-old head of Pembridge Investments , through which the bid is being mounted says , ‘ rule number one in this business is : the more luxurious the luncheon rooms at headquarters , the more inefficient the business ’ .', 'If he had taken his own rule seriously , he would have found out that DRG has a very modest self-service canteen at its Bristol head office .', 'There are other things he has , on his own admission , not fully investigated , like the value of the DRG properties , or which part of the DRG business he would keep after the break up .', 'When the bid was launched last week , Mr Franklin faced some criticism from City commentators on both those counts .', 'He regards the charges as unfounded .', 'On property , he is blunt .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_sentences = ','.join(sentences)\n",
        "\n",
        "counts_sentence = len(sentences)\n",
        "\n",
        "counts_sentence"
      ],
      "metadata": {
        "id": "qTMKC4qDDh56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ca11891-c980-449a-b049-5abd1873ac09"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16202"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenizing:**"
      ],
      "metadata": {
        "id": "GNfYtlDhe_1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloads\n",
        "nltk.download('punkt')\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "stopwords = nltk.download('stopwords')\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "chars = [',', '.', '´', '`', ')', '(', '-', ',', ':', '’', '‘', '—', ';']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kReMhesMpiA",
        "outputId": "db4d9367-9d20-4219-cbdc-1d8816060ca0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens = []\n",
        "tokenize_sentences = []\n",
        "tokens_sum = 0\n",
        "for s in sentences:\n",
        "  tokens = word_tokenize(s)\n",
        "  tokens = [token.lower() for token in tokens if token.lower() not in stopwords and token not in chars]\n",
        "  tokens_sum += len(tokens)\n",
        "  for token in tokens:\n",
        "    if token not in all_tokens:\n",
        "      all_tokens.append(token)\n",
        "  tokenize_sentences.append(tokens)\n"
      ],
      "metadata": {
        "id": "xL0MEIwJGH3l"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_tokens_per_sentence = tokens_sum / len(tokenize_sentences)\n",
        "unique_tokens = len(all_tokens)"
      ],
      "metadata": {
        "id": "GFPEkEAyqxE0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extracting Entities:**"
      ],
      "metadata": {
        "id": "RbDd6cZR354R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entities = []\n",
        "unique_entities = []\n",
        "tag_count = {}\n",
        "\n",
        "for s in tokenize_sentences:\n",
        "  s_nlp = nlp(' '.join(s))\n",
        "  for ent in s_nlp.ents:\n",
        "    string = str(ent.text) + ' ' + str(ent.label_)\n",
        "    entities.append(string)\n",
        "    if ent.text not in unique_entities:\n",
        "      unique_entities.append(ent.text)\n",
        "    if tag_count.get(ent.label_):\n",
        "      tag_count[ent.label_] = tag_count.get(ent.label_) + 1\n",
        "    else:\n",
        "      tag_count[ent.label_] = 1"
      ],
      "metadata": {
        "id": "1BuyNISLuA6d"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_num_entities = len(entities)\n",
        "num_unique_entities = len(unique_entities)"
      ],
      "metadata": {
        "id": "DPJHWISTx3kp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating diff entity popularity\n",
        "\n",
        "for tag in tag_count.keys():\n",
        "  val = tag_count.get(tag)\n",
        "  print(f'{tag} --> {(val/len(entities)) * 100} %')"
      ],
      "metadata": {
        "id": "q6j0Vaf42AXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "780fbc7f-99ea-4dd8-e630-feadd22bfd59"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORG --> 7.478376580172988 %\n",
            "QUANTITY --> 1.9693945442448437 %\n",
            "PERSON --> 21.144377910844977 %\n",
            "CARDINAL --> 23.446440452428476 %\n",
            "DATE --> 21.35728542914172 %\n",
            "MONEY --> 2.1290751829673984 %\n",
            "GPE --> 7.411842980705257 %\n",
            "ORDINAL --> 4.07185628742515 %\n",
            "NORP --> 5.349301397205589 %\n",
            "LAW --> 0.3060545575515636 %\n",
            "LOC --> 0.7052561543579507 %\n",
            "TIME --> 3.992015968063872 %\n",
            "LANGUAGE --> 0.2528276779773786 %\n",
            "PRODUCT --> 0.10645375914836992 %\n",
            "EVENT --> 0.05322687957418496 %\n",
            "FAC --> 0.11976047904191617 %\n",
            "PERCENT --> 0.09314703925482369 %\n",
            "WORK_OF_ART --> 0.01330671989354624 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable"
      ],
      "metadata": {
        "id": "DLIaWtDhd-0n"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myTable = PrettyTable([\"Measurement\", \"Result\"])\n",
        "\n",
        "# Add rows\n",
        "myTable.add_row([\"Sentences count\", counts_sentence])\n",
        "myTable.add_row([\"Total number of tokens\", tokens_sum])\n",
        "myTable.add_row([\"Unique tokens\", unique_tokens])\n",
        "myTable.add_row([\"Avg token per sentence\", f\"{avg_tokens_per_sentence:.2f}\"])\n",
        "myTable.add_row([\"Entity measurement\", \"----\"])\n",
        "myTable.add_row([\"Total number of Enitities\", total_num_entities])\n",
        "myTable.add_row([\"Unique Entities\", num_unique_entities])\n",
        "myTable.add_row([\"Tag % share of all tags\", \"----\"])\n",
        "\n",
        "for tag in tag_count.keys():\n",
        "  val = tag_count.get(tag)\n",
        "  myTable.add_row([tag, f\"{(val/len(entities)):.2%}\"])\n",
        "\n",
        "print(myTable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w2Oa9breiVg",
        "outputId": "6fce9d2b-3dcb-42d7-d229-d9842e4d9d01"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------+--------+\n",
            "|        Measurement        | Result |\n",
            "+---------------------------+--------+\n",
            "|      Sentences count      | 16202  |\n",
            "|   Total number of tokens  | 113765 |\n",
            "|       Unique tokens       | 17883  |\n",
            "|   Avg token per sentence  |  7.02  |\n",
            "|     Entity measurement    |  ----  |\n",
            "| Total number of Enitities |  7515  |\n",
            "|      Unique Entities      |  3095  |\n",
            "|  Tag % share of all tags  |  ----  |\n",
            "|            ORG            | 7.48%  |\n",
            "|          QUANTITY         | 1.97%  |\n",
            "|           PERSON          | 21.14% |\n",
            "|          CARDINAL         | 23.45% |\n",
            "|            DATE           | 21.36% |\n",
            "|           MONEY           | 2.13%  |\n",
            "|            GPE            | 7.41%  |\n",
            "|          ORDINAL          | 4.07%  |\n",
            "|            NORP           | 5.35%  |\n",
            "|            LAW            | 0.31%  |\n",
            "|            LOC            | 0.71%  |\n",
            "|            TIME           | 3.99%  |\n",
            "|          LANGUAGE         | 0.25%  |\n",
            "|          PRODUCT          | 0.11%  |\n",
            "|           EVENT           | 0.05%  |\n",
            "|            FAC            | 0.12%  |\n",
            "|          PERCENT          | 0.09%  |\n",
            "|        WORK_OF_ART        | 0.01%  |\n",
            "+---------------------------+--------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extracting methapore data**"
      ],
      "metadata": {
        "id": "mS14wVtv7rTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_2 = [sentence for sentence in soup.find_all('s')]\n",
        "methaporas = [[m.get_text().lower() for m in metaphor.find_all('seg')] for metaphor in sentences_2]\n",
        "methaporas[:2]\n"
      ],
      "metadata": {
        "id": "VjHSECST7wqE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffec0f17-e566-40a4-a474-5ece71f1797b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['reveals', 'approach', 'leading', 'to'], []]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating count of sentences with methapora\n",
        "\n",
        "sentence_with_methapor_count = 0\n",
        "\n",
        "for sent in methaporas:\n",
        "  if sent:\n",
        "    sentence_with_methapor_count += 1\n",
        "\n",
        "print(sentence_with_methapor_count)\n",
        "print(len(methaporas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsU7lAEdw84X",
        "outputId": "37a6addd-6731-4287-b463-dfb42c7839b2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8326\n",
            "16202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting unique metaphoras\n",
        "\n",
        "methaporas_2 = []\n",
        "\n",
        "for s in sentences_2:\n",
        "  for m in s.find_all('seg'):\n",
        "    if m.get_text() not in methaporas_2:\n",
        "      methaporas_2.append(m.get_text())\n",
        "\n",
        "methaporas_2[:10]"
      ],
      "metadata": {
        "id": "ZpjuGLJzOn4j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bf75f78-6edd-4b3b-e778-18e4d12a9e79"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['reveals',\n",
              " 'approach',\n",
              " 'leading',\n",
              " 'to',\n",
              " 'made',\n",
              " 'fatal',\n",
              " 'in',\n",
              " 'target',\n",
              " 'head',\n",
              " 'through']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extractin methaporas in sentences\n",
        "\n",
        "methaporas_in_sentence = []\n",
        "\n",
        "for sent in tokenize_sentences:\n",
        "  methaphoras = []\n",
        "  for token in sent:\n",
        "    if token in methaporas_2:\n",
        "      methaphoras.append(token)\n",
        "  methaporas_in_sentence.append(methaphoras)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "iJQcuPimraxt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "  \"sentence\": [i for i in range(1,(len(tokenize_sentences) + 1))],\n",
        "  \"metahporas\": [methaporas_in_sentence[i] for i in range(0, len(methaporas_in_sentence) )],\n",
        "  \"count\": [len(methaporas_in_sentence[i]) for i in range(0, len(methaporas_in_sentence) )],\n",
        "  \"y\": [1 if len(methaporas_in_sentence[i]) > 0 else 0 for i in range(0, len(methaporas_in_sentence) )],\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "A5nZNL3E-FVz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "230fa539-61d4-4633-d1e5-10c2d63ccf3f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       sentence                                         metahporas  count  y\n",
            "0             1  [corporate, reveals, approach, leading, pound,...      6  1\n",
            "1             2                                                 []      0  0\n",
            "2             3       [appear, made, fatal, bid, packaging, group]      6  1\n",
            "3             4             [investigated, target, 's, facilities]      4  1\n",
            "4             5  [head, bid, mounted, says, rule, number, one, ...     10  1\n",
            "...         ...                                                ...    ... ..\n",
            "16197     16198  [come, back, 've, got, know, 've, got, 's, wor...     10  1\n",
            "16198     16199                                             [know]      1  1\n",
            "16199     16200                                      ['s, sitting]      2  1\n",
            "16200     16201                     [well, know, know, kind, work]      5  1\n",
            "16201     16202                                  [well, 's, right]      3  1\n",
            "\n",
            "[16202 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-wCgReWSo0N"
      },
      "source": [
        "**2. Now we want to study the detection of the metaphor as a multi-class classification problem. You may\n",
        "inspire from the existing implementations for this task available on the same github account, see also\n",
        "some original papers, e,g., A Report on the 2018 VUA Metaphor Detection Shared Task\n",
        "(aclanthology.org). Consider a simple machine learning classifier, e.,g., SVM, or NaivesBayes with\n",
        "80-20 data split for training-testing, and use tf-idf features, testing various lengths of total feature\n",
        "sets, e.g., 500, 1000, 3000, to report the detection accuracy of the models.**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2\n",
        "\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error"
      ],
      "metadata": {
        "id": "IJkJEQZSj3HE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_for_tf_idf = []\n",
        "for i in range(0,len(tokenize_sentences)):\n",
        "  tokens = tokenize_sentences[i]\n",
        "  sentence = \"\"\n",
        "  for t in range(0,len(tokens)):\n",
        "    sentence += tokens[t] + \" \"\n",
        "  sentences_for_tf_idf.append(str(sentence))"
      ],
      "metadata": {
        "id": "wNdQ23Lrl8by"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_lengths = [250, 500, 1000, 3000]\n",
        "\n",
        "results = {'Dataset': [], 'Feature Length': [], 'Model': [], 'Accuracy': [], 'Precision': [], 'Recall': [], 'F1-Score': []}\n"
      ],
      "metadata": {
        "id": "KDTejQUBla91"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for length in feature_lengths:\n",
        "\n",
        "    vectorizer = TfidfVectorizer(max_features=length)\n",
        "    X = vectorizer.fit_transform(sentences_for_tf_idf)\n",
        "    names = vectorizer.get_feature_names_out()\n",
        "    y = df['y']\n",
        "\n",
        "    train_sentences, test_sentences, labels_train, labels_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train and eval Naive Bayes\n",
        "    nb_model = MultinomialNB()\n",
        "    nb_model.fit(train_sentences, labels_train)\n",
        "    nb_predictions = nb_model.predict(test_sentences)\n",
        "    nb_accuracy = accuracy_score(labels_test, nb_predictions)\n",
        "    nb_precision = precision_score(labels_test, nb_predictions)\n",
        "    nb_recall = recall_score(labels_test, nb_predictions)\n",
        "    nb_f1 = f1_score(labels_test, nb_predictions)\n",
        "\n",
        "\n",
        "    results['Feature Length'].append(length)\n",
        "    results['Model'].append('Naive Bayes')\n",
        "    results['Accuracy'].append(nb_accuracy)\n",
        "    results['Precision'].append(nb_precision)\n",
        "    results['Recall'].append(nb_recall)\n",
        "    results['F1-Score'].append(nb_f1)\n",
        "    results['Dataset'].append('VUA')\n",
        "    highestacc = nb_accuracy\n",
        "    bestmodel = 'NB'\n",
        "\n",
        "    # Train and eval SVM\n",
        "    svm_model = SVC(kernel='linear', random_state=42)\n",
        "    svm_model.fit(train_sentences, labels_train)\n",
        "    svm_predictions = svm_model.predict(test_sentences)\n",
        "    svm_accuracy = accuracy_score(labels_test, svm_predictions)\n",
        "    svm_precision = precision_score(labels_test, svm_predictions)\n",
        "    svm_recall = recall_score(labels_test, svm_predictions)\n",
        "    svm_f1 = f1_score(labels_test, svm_predictions)\n",
        "\n",
        "    results['Feature Length'].append(length)\n",
        "    results['Model'].append('SVM')\n",
        "    results['Accuracy'].append(svm_accuracy)\n",
        "    results['Precision'].append(svm_precision)\n",
        "    results['Recall'].append(svm_recall)\n",
        "    results['F1-Score'].append(svm_f1)\n",
        "    results['Dataset'].append('VUA')\n",
        "    if svm_accuracy > highestacc:\n",
        "        highestacc = svm_accuracy\n",
        "        bestmodel = 'SVM'\n",
        "\n",
        "    # Train and eval Logistic Regression\n",
        "    logreg = LogisticRegression(random_state=16)\n",
        "    logreg.fit(train_sentences, labels_train)\n",
        "    logreg_pred = logreg.predict(test_sentences)\n",
        "    logreg_acc = accuracy_score(labels_test, logreg_pred)\n",
        "    logreg_precision = precision_score(labels_test, logreg_pred)\n",
        "    logreg_recall = recall_score(labels_test, logreg_pred)\n",
        "    logreg_f1 = f1_score(labels_test, logreg_pred)\n",
        "\n",
        "    results['Feature Length'].append(length)\n",
        "    results['Model'].append('Logistic Reg.')\n",
        "    results['Accuracy'].append(logreg_acc)\n",
        "    results['Precision'].append(logreg_precision)\n",
        "    results['Recall'].append(logreg_recall)\n",
        "    results['F1-Score'].append(logreg_f1)\n",
        "    results['Dataset'].append('VUA')\n",
        "    if logreg_acc > highestacc:\n",
        "        highestacc = logreg_acc\n",
        "        bestmodel = 'LogReg'\n",
        "\n",
        "    # Train and eval Multi-Layer-Perceptron classifier\n",
        "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
        "                        hidden_layer_sizes=(5, 2), max_iter=100, random_state=1)\n",
        "    clf.fit(train_sentences, labels_train)\n",
        "    mlp_pred = clf.predict(test_sentences)\n",
        "    mlp_acc = accuracy_score(labels_test, mlp_pred)\n",
        "    mlp_precision = precision_score(labels_test, mlp_pred)\n",
        "    mlp_recall = recall_score(labels_test, mlp_pred)\n",
        "    mlp_f1 = f1_score(labels_test, mlp_pred)\n",
        "\n",
        "    results['Feature Length'].append(length)\n",
        "    results['Model'].append('MLP')\n",
        "    results['Accuracy'].append(mlp_acc)\n",
        "    results['Precision'].append(mlp_precision)\n",
        "    results['Recall'].append(mlp_recall)\n",
        "    results['F1-Score'].append(mlp_f1)\n",
        "    results['Dataset'].append('VUA')\n",
        "    if mlp_acc > highestacc:\n",
        "        highestacc = mlp_acc\n",
        "        bestmodel = 'MLP'\n",
        "\n",
        "    average = (nb_predictions + svm_predictions + logreg_pred + mlp_pred) / 4\n",
        "    averageacc = (nb_accuracy + svm_accuracy + logreg_acc + mlp_acc) / 4\n",
        "    print('Average accuracy', round(averageacc, 5))\n",
        "    print('RMSE: ', round(mean_squared_error(labels_test, average), 5))\n",
        "\n",
        "    if averageacc > highestacc:\n",
        "        highestacc = averageacc\n",
        "        bestmodel = 'Ensemble'\n",
        "\n",
        "    print('Best model: ', bestmodel + '    Model Accuracy: ', round(highestacc, 5))\n",
        "    print('------')\n"
      ],
      "metadata": {
        "id": "Cm8w0zTklcLn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaec7b08-398d-4329-b84c-ef15346f0a76"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracy 0.82019\n",
            "RMSE:  0.16363\n",
            "Best model:  LogReg    Model Accuracy:  0.83678\n",
            "------\n",
            "Average accuracy 0.83778\n",
            "RMSE:  0.10662\n",
            "Best model:  SVM    Model Accuracy:  0.88954\n",
            "------\n",
            "Average accuracy 0.87496\n",
            "RMSE:  0.07276\n",
            "Best model:  SVM    Model Accuracy:  0.91515\n",
            "------\n",
            "Average accuracy 0.88453\n",
            "RMSE:  0.07099\n",
            "Best model:  SVM    Model Accuracy:  0.93397\n",
            "------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_sum_labels = 0\n",
        "false_sum_labels = 0\n",
        "for num in labels_test:\n",
        "  if num == 1:\n",
        "    true_sum_labels += 1\n",
        "  else:\n",
        "    false_sum_labels += 1\n",
        "\n",
        "print(true_sum_labels)\n",
        "print(false_sum_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxUCrVO1AwNg",
        "outputId": "71780818-69df-478c-8f5c-f99f38e8834d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2514\n",
            "727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYjxUUKUlcI0",
        "outputId": "f7d4ca4e-e085-4533-c0c4-effc9d66493b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Dataset  Feature Length          Model  Accuracy  Precision    Recall  \\\n",
            "0      VUA             250    Naive Bayes  0.835545   0.832494  0.986476   \n",
            "1      VUA             250            SVM  0.832768   0.830429  0.985680   \n",
            "2      VUA             250  Logistic Reg.  0.836779   0.831829  0.989658   \n",
            "3      VUA             250            MLP  0.775687   0.775687  1.000000   \n",
            "4      VUA             500    Naive Bayes  0.842333   0.839147  0.985680   \n",
            "5      VUA             500            SVM  0.889540   0.966263  0.888624   \n",
            "6      VUA             500  Logistic Reg.  0.843567   0.839824  0.986476   \n",
            "7      VUA             500            MLP  0.775687   0.775687  1.000000   \n",
            "8      VUA            1000    Naive Bayes  0.845418   0.842231  0.985282   \n",
            "9      VUA            1000            SVM  0.915150   0.966264  0.922832   \n",
            "10     VUA            1000  Logistic Reg.  0.852823   0.847255  0.988465   \n",
            "11     VUA            1000            MLP  0.886455   0.971441  0.879475   \n",
            "12     VUA            3000    Naive Bayes  0.853440   0.846415  0.990851   \n",
            "13     VUA            3000            SVM  0.933971   0.960368  0.954256   \n",
            "14     VUA            3000  Logistic Reg.  0.863622   0.856749  0.989658   \n",
            "15     VUA            3000            MLP  0.887072   0.953931  0.897772   \n",
            "\n",
            "    F1-Score  \n",
            "0   0.902967  \n",
            "1   0.901419  \n",
            "2   0.903906  \n",
            "3   0.873675  \n",
            "4   0.906530  \n",
            "5   0.925818  \n",
            "6   0.907262  \n",
            "7   0.873675  \n",
            "8   0.908158  \n",
            "9   0.944049  \n",
            "10  0.912429  \n",
            "11  0.923173  \n",
            "12  0.912956  \n",
            "13  0.957302  \n",
            "14  0.918420  \n",
            "15  0.925000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bnrpIpDSs3C"
      },
      "source": [
        "**3. From the best performing algorithms that you may have scrutinized for the same application, suggest\n",
        "an ensemble model that combines three models, see example of implementations in Ensemble\n",
        "Methods in Python - GeeksforGeeks, and test the performance of the model.**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vecstack"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kADeunj6pAIj",
        "outputId": "33ca2cff-6b38-493a-b96d-f5a4517c3e07",
        "collapsed": true
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vecstack\n",
            "  Downloading vecstack-0.4.0.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vecstack) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from vecstack) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from vecstack) (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->vecstack) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->vecstack) (3.5.0)\n",
            "Building wheels for collected packages: vecstack\n",
            "  Building wheel for vecstack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vecstack: filename=vecstack-0.4.0-py3-none-any.whl size=19861 sha256=32599e14344099f97b19d548f959b75e5bb08334bd478081a10784cdc8552197\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/d8/51/3cf39adf22c522b0a91dc2208db4e9de4d2d9d171683596220\n",
            "Successfully built vecstack\n",
            "Installing collected packages: vecstack\n",
            "Successfully installed vecstack-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5yPke51mSdkY"
      },
      "outputs": [],
      "source": [
        "# Training Ensemble Model\n",
        "\n",
        "from vecstack import stacking\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=3000)\n",
        "X = vectorizer.fit_transform(sentences_for_tf_idf)\n",
        "names = vectorizer.get_feature_names_out()\n",
        "\n",
        "y = df['y']\n",
        "\n",
        "train_sentences_2, test_sentences_2, labels_train_2, labels_test_2 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# initializing all the base model objects with default parameters\n",
        "\n",
        "model_1 = LogisticRegression(random_state=16)\n",
        "model_2 = MultinomialNB()\n",
        "model_3 = SVC(kernel='linear', random_state=42)\n",
        "\n",
        "# putting all base model objects in one list\n",
        "all_models = [model_1, model_2, model_3]\n",
        "\n",
        "# computing the stack features\n",
        "s_train, s_test = stacking(all_models, train_sentences_2, labels_train_2, test_sentences_2, regression=True, shuffle=True, n_folds=4)\n",
        "\n",
        "# initializing the second-level model\n",
        "final_model = model_1\n",
        "\n",
        "# fitting the second level model with stack features\n",
        "final_model = final_model.fit(s_train, labels_train_2)\n",
        "\n",
        "# predicting the final output using stacking\n",
        "pred_final = final_model.predict(s_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error"
      ],
      "metadata": {
        "id": "DX5OF3997FYa"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate evaluation metrics for Ensemble Model\n",
        "accuracy = accuracy_score(labels_test_2, pred_final)\n",
        "precision = precision_score(labels_test_2, pred_final)\n",
        "recall = recall_score(labels_test_2, pred_final)\n",
        "f1 = f1_score(labels_test_2, pred_final)\n",
        "mean_sqr_error = mean_squared_error(labels_test_2, pred_final)\n",
        "\n",
        "# Print the results\n",
        "print(\"Evaluation Metrics for Metaphor Detection:\")\n",
        "print(f\"Accuracy: {accuracy*100:.4f} %\")\n",
        "print(f\"Precision: {precision*100:.4f} %\")\n",
        "print(f\"Recall: {recall*100:.4f} %\")\n",
        "print(f\"F1-Score: {f1*100:.4f} %\")\n",
        "print(f\"Mean squared error: {mean_sqr_error:.4f}\")\n",
        "\n",
        "model_3_new_row = {'Dataset': 'VUA', 'Feature Length': 3000, 'Model': 'Ensemble', 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-Score': f1}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGsC8v_Ykgac",
        "outputId": "09072056-feb5-4262-965d-65cbf07937f8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics for Metaphor Detection:\n",
            "Accuracy: 92.5332 %\n",
            "Precision: 94.2712 %\n",
            "Recall: 96.2212 %\n",
            "F1-Score: 95.2362 %\n",
            "Mean squared error: 0.0747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_true = 0\n",
        "\n",
        "for num in labels_test_2:\n",
        "  if num == 1:\n",
        "    labels_true += 1"
      ],
      "metadata": {
        "id": "y3li06gp82Na"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vua_data = {'Dataset': 'VUA',\n",
        "            'Measurement' : ['Sent. count', 'Tokens', 'Unique tokens', 'Avg token per sent', 'sent with methapor', 'Testing sent count', 'How many with metaphor'],\n",
        "            'Values' : [counts_sentence, tokens_sum, unique_tokens, avg_tokens_per_sentence, sentence_with_methapor_count, len(labels_test_2), labels_true ]\n",
        "            }"
      ],
      "metadata": {
        "id": "wajoV7H163kg"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ANPSynsSuxb"
      },
      "source": [
        "**4. Study the use of FrameBERT pointed out earlier on the same dataset and report its performances in terms precision, recall and F1-measure and compare this with results in 3.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr1YlVr-MM4_",
        "outputId": "9443dbc5-f3be-4cbe-de48-3314d89255a6",
        "collapsed": true
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import wandb\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "Lr3jGsZtyCyI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98b16639-417a-477b-d41b-96a122e1f73c",
        "collapsed": true
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/liyucheng09/MetaphorFrame.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYz_6Gy46qTp",
        "outputId": "62dbc6c4-f0cc-44c1-a0d5-04e4221d8e54",
        "collapsed": true
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MetaphorFrame'...\n",
            "remote: Enumerating objects: 287, done.\u001b[K\n",
            "remote: Counting objects: 100% (287/287), done.\u001b[K\n",
            "remote: Compressing objects: 100% (143/143), done.\u001b[K\n",
            "remote: Total 287 (delta 157), reused 257 (delta 132), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (287/287), 18.59 MiB | 18.92 MiB/s, done.\n",
            "Resolving deltas: 100% (157/157), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd MetaphorFrame"
      ],
      "metadata": {
        "id": "l4iFOMyW7EDc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0051f006-25c9-4ee1-d679-4f697d876033",
        "collapsed": true
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MetaphorFrame\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_b = df['y']\n",
        "\n",
        "train_sentences_b, test_sentences_b, labels_train_b, labels_test_b = train_test_split(tokenize_sentences, y_b, test_size=0.2, random_state=42)\n",
        "\n",
        "print(len(test_sentences_b))\n",
        "print(len(labels_test_b))\n",
        "print(test_sentences_b[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ7sH8pzYB-y",
        "outputId": "56b3345d-c892-4101-9a6b-83f0aae2575b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3241\n",
            "3241\n",
            "['glenys', 'ever', 'since', 'han']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string_b = ''\n",
        "\n",
        "for sentence in test_sentences_b:\n",
        "  for index, s in enumerate(sentence):\n",
        "    if index == len(sentence) - 1:\n",
        "      string_b += s + \"\\n\"\n",
        "    else:\n",
        "      string_b += s + \" \"\n",
        "\n",
        "import json\n",
        "\n",
        "temp = { \"articles\": string_b }\n",
        "\n",
        "json_sentences = json.dumps(temp)\n",
        "\n",
        "with open('sentences.json', 'w') as writefile:\n",
        "    writefile.write(json_sentences)"
      ],
      "metadata": {
        "id": "LDssAhKaQt1n"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# moves modified config file into correct location so it can be run\n",
        "!mv /content/wandb_config.py /usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_config.py"
      ],
      "metadata": {
        "id": "chkT7lHAyASw"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run FrameBert\n",
        "!python inference.py sentences.json\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwpgQGkhWNRo",
        "outputId": "79caa160-5103-4f39-cc53-3874d7dea130",
        "collapsed": true
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-08 09:07:06.233659: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-08 09:07:06.292140: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-08 09:07:06.306763: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-08 09:07:06.350587: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-08 09:07:08.528412: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "config.json: 100% 713/713 [00:00<00:00, 3.58MB/s]\n",
            "pytorch_model.bin: 100% 496M/496M [00:14<00:00, 34.1MB/s]\n",
            "tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 144kB/s]\n",
            "vocab.json: 100% 899k/899k [00:00<00:00, 15.7MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 47.5MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 7.25MB/s]\n",
            "config.json: 100% 481/481 [00:00<00:00, 2.32MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Map: 100% 549/549 [00:00<00:00, 1445.03 examples/s]\n",
            "{'tokens': ['glenys', 'ever', 'since', 'han', 'vicki', '!'], 'input_ids': [0, 5921, 225, 2459, 655, 187, 1368, 260, 748, 1758, 118, 27785, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'pad_mask': [-100, 0, -100, -100, 0, 0, 0, -100, 0, -100, -100, 0, -100]}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2888: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "100% 69/69 [04:11<00:00,  2.95s/it]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/MetaphorFrame/wandb/run-20241108_091318-jjdbnzev\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtmp_trainer\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/tapaninaho-joonas-university-of-oulu/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/tapaninaho-joonas-university-of-oulu/huggingface/runs/jjdbnzev\u001b[0m\n",
            "100% 69/69 [05:42<00:00,  4.96s/it]\n",
            "&&& Assuming tagging predictions:\n",
            "config.json: 100% 715/715 [00:00<00:00, 1.05MB/s]\n",
            "pytorch_model.bin: 100% 496M/496M [00:04<00:00, 102MB/s]\n",
            "Map: 100% 549/549 [00:00<00:00, 1226.20 examples/s]\n",
            "{'tokens': ['glenys', 'ever', 'since', 'han', 'vicki', '!'], 'input_ids': [0, 5921, 225, 2459, 655, 187, 1368, 260, 748, 1758, 118, 27785, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'pad_mask': [-100, 0, -100, -100, 0, 0, 0, -100, 0, -100, -100, 0, -100], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2888: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "100% 69/69 [04:25<00:00,  3.85s/it]\n",
            "&&& Assuming tagging predictions:\n",
            "config.json: 100% 37.0k/37.0k [00:00<00:00, 3.83MB/s]\n",
            "pytorch_model.bin: 100% 499M/499M [00:03<00:00, 126MB/s]\n",
            "100% 69/69 [04:24<00:00,  3.83s/it]\n",
            "&&& Assuming tagging predictions:\n",
            "Save to conll file predictions.tsv.\n",
            "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mtmp_trainer\u001b[0m at: \u001b[34mhttps://wandb.ai/tapaninaho-joonas-university-of-oulu/huggingface/runs/jjdbnzev\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241108_091318-jjdbnzev/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_predictions_df = pd.read_csv(\"predictions.tsv\", sep=\"\\t\")\n",
        "predicted_metaphors_bert = bert_predictions_df[\"Real_metaphors\"]\n",
        "print(bert_predictions_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iewSro3jcFdY",
        "outputId": "c2bfb8bd-8a41-4c4c-b430-f7570e862489",
        "collapsed": true
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Tokens  Borderline_metaphor  Real_metaphors         Frame_label\n",
            "0          glenys                    0               0                   _\n",
            "1            ever                    0               0                   _\n",
            "2           since                    0               0         Time_vector\n",
            "3             han                    0               0                   _\n",
            "4           vicki                    0               0                   _\n",
            "...           ...                  ...             ...                 ...\n",
            "21988        fell                    1               0  Motion_directional\n",
            "21989      victim                    1               1         Catastrophe\n",
            "21990        late                    0               0  Temporal_subregion\n",
            "21991       1960s                    0               0                   _\n",
            "21992  iconoclasm                    0               0                   _\n",
            "\n",
            "[21993 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_predictions_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "rtu8GoXtcmR3",
        "outputId": "84705702-b668-4088-fc97-e65b3474b24d",
        "collapsed": true
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Tokens  Borderline_metaphor  Real_metaphors  Frame_label\n",
              "0  glenys                    0               0            _\n",
              "1    ever                    0               0            _\n",
              "2   since                    0               0  Time_vector\n",
              "3     han                    0               0            _\n",
              "4   vicki                    0               0            _"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2fe7270-2390-4146-aea8-c02e880779fa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tokens</th>\n",
              "      <th>Borderline_metaphor</th>\n",
              "      <th>Real_metaphors</th>\n",
              "      <th>Frame_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>glenys</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ever</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>since</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Time_vector</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>han</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>vicki</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>_</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2fe7270-2390-4146-aea8-c02e880779fa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f2fe7270-2390-4146-aea8-c02e880779fa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f2fe7270-2390-4146-aea8-c02e880779fa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9cedd450-962a-42bf-99ea-98f3ffbd1888\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9cedd450-962a-42bf-99ea-98f3ffbd1888')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9cedd450-962a-42bf-99ea-98f3ffbd1888 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "bert_predictions_df",
              "summary": "{\n  \"name\": \"bert_predictions_df\",\n  \"rows\": 21993,\n  \"fields\": [\n    {\n      \"column\": \"Tokens\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7261,\n        \"samples\": [\n          \"coal\",\n          \"illogical\",\n          \"foresee\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Borderline_metaphor\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Real_metaphors\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Frame_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 497,\n        \"samples\": [\n          \"Fullness\",\n          \"Color\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_metaphor_df = bert_predictions_df.loc[bert_predictions_df['Real_metaphors'] == 1]\n",
        "bert_metaphoras = bert_metaphor_df['Tokens']\n",
        "bert_metaphoras = bert_metaphoras.values.tolist()\n",
        "\n",
        "# FrameBert Result to predictions\n",
        "\n",
        "bert_predictions = []\n",
        "\n",
        "for test_sentence in test_sentences_b:\n",
        "  metaphora = 0\n",
        "  for token in test_sentence:\n",
        "    if token in bert_metaphoras:\n",
        "      metaphora = 1\n",
        "  bert_predictions.append(metaphora)\n",
        "\n",
        "print(len(bert_predictions))\n",
        "print(len(labels_test_b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd4A7nUWiTRS",
        "outputId": "c7a450cd-75e1-4c09-ed77-73a7e8c0a50c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3241\n",
            "3241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate evaluation metrics for FrameBERT\n",
        "accuracy = accuracy_score(labels_test_b, bert_predictions)\n",
        "precision = precision_score(labels_test_b, bert_predictions)\n",
        "recall = recall_score(labels_test_b, bert_predictions)\n",
        "f1 = f1_score(labels_test_b, bert_predictions)\n",
        "\n",
        "# Print the results\n",
        "print(\"Evaluation Metrics for Metaphor Detection:\")\n",
        "print(f\"Accuracy: {accuracy*100:.4f} %\")\n",
        "print(f\"Precision: {precision*100:.4f} %\")\n",
        "print(f\"Recall: {recall*100:.4f} %\")\n",
        "print(f\"F1-Score: {f1*100:.4f} %\")\n",
        "\n",
        "model_bert_new_row = {'Dataset': 'VUA', 'Feature Length': 0, 'Model': 'BERT', 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-Score': f1}"
      ],
      "metadata": {
        "id": "JJWvhp2pScvV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "757c73a6-153a-41b4-a33a-6181e8135b2a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics for Metaphor Detection:\n",
            "Accuracy: 68.2197 %\n",
            "Precision: 99.2042 %\n",
            "Recall: 59.5068 %\n",
            "F1-Score: 74.3909 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH2zMe13SykJ"
      },
      "source": [
        "**5. We want to test the model on subsequent dataset -content word metaphor metaphor/content-\n",
        "words/README.md at master · EducationalTestingService/metaphor · GitHub available on the same\n",
        "repository. Test the performance of the machine learning model in 2), ensemble model and\n",
        "FrameBERT models.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset TOEFL Pfeature.jsonlines** toefl_skll_train_features.zip https://github.com/EducationalTestingService/metaphor/releases/download/v1.0/toefl_skll_train_features.zip\n"
      ],
      "metadata": {
        "id": "8Crg1wHw6l_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TOELF_corpus_url = 'https://github.com/EducationalTestingService/metaphor/releases/download/v1.0/toefl_skll_train_features.zip'\n",
        "\n",
        "r = requests.get(TOELF_corpus_url)\n",
        "\n",
        "with ZipFile(BytesIO(r.content), 'r') as zip:\n",
        "  zip.printdir()\n",
        "  file = zip.extract('features/all_pos/P.jsonlines','r')\n",
        "\n",
        "\n",
        "with open(file) as f:\n",
        "  content = f.readlines()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ODaJ_g15JnDm",
        "outputId": "d4a78fef-c9fe-410d-9a02-a4fd7b41224f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Name                                             Modified             Size\n",
            "features/                                      2020-01-11 22:48:22            0\n",
            "features/verbs/                                2020-01-11 22:48:22            0\n",
            "features/verbs/C-BiasDown.jsonlines            2020-01-11 22:48:22      5379532\n",
            "features/verbs/C-BiasUp.jsonlines              2020-01-11 22:48:22      5151596\n",
            "features/verbs/CCDB-BiasUpDown.jsonlines       2020-01-11 22:48:22      9880892\n",
            "features/verbs/P.jsonlines                     2020-01-11 22:48:22       490389\n",
            "features/verbs/T.jsonlines                     2020-01-11 22:48:22     22348021\n",
            "features/verbs/U.jsonlines                     2020-01-11 22:48:22       442972\n",
            "features/verbs/UL.jsonlines                    2020-01-11 22:48:22       445024\n",
            "features/verbs/WordNet.jsonlines               2020-01-11 22:48:22       755941\n",
            "features/all_pos/                              2020-01-11 22:47:28            0\n",
            "features/all_pos/C-BiasDown.jsonlines          2020-01-11 22:47:24     19824659\n",
            "features/all_pos/C-BiasUp.jsonlines            2020-01-11 22:47:24     18987001\n",
            "features/all_pos/CCDB-BiasUpDown.jsonlines     2020-01-11 22:47:24     19279955\n",
            "features/all_pos/P.jsonlines                   2020-01-11 22:47:24      1872848\n",
            "features/all_pos/T.jsonlines                   2020-01-11 22:47:28     82905327\n",
            "features/all_pos/U.jsonlines                   2020-01-11 22:47:28      1709753\n",
            "features/all_pos/UL.jsonlines                  2020-01-11 22:47:28      1727219\n",
            "features/all_pos/WordNet.jsonlines             2020-01-11 22:47:28      1679586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_toelf = []\n",
        "labels_toelf = []\n",
        "unique_tokens_toelf = []\n",
        "sent_count_toelf = 0\n",
        "sent_lenght_toelf_sum = 0\n",
        "token_sum_toelf = 0\n",
        "start_idx = 1\n",
        "sentence_temp = []\n",
        "containing_metaphor = 0\n",
        "sentence_with_methapor_count_toelf = 0\n",
        "\n",
        "for c in content:\n",
        "\n",
        "  json_token = json.loads(c.strip())\n",
        "  methapor = json_token['y']\n",
        "  word_data = json_token['id']\n",
        "  parsing_word = word_data.split('_')\n",
        "  sentence_num = parsing_word[1]\n",
        "  word = parsing_word[3]\n",
        "  token_sum_toelf += 1\n",
        "\n",
        "  if word not in unique_tokens_toelf:\n",
        "    unique_tokens_toelf.append(word)\n",
        "\n",
        "  if start_idx != int(sentence_num):\n",
        "    sentences_toelf.append(sentence_temp)\n",
        "    labels_toelf.append(containing_metaphor)\n",
        "    if containing_metaphor > 0:\n",
        "      sentence_with_methapor_count_toelf += 1\n",
        "\n",
        "    containing_metaphor = 0\n",
        "    sent_lenght_toelf_sum += len(sentence_temp)\n",
        "    sentence_temp = []\n",
        "    start_idx = int(sentence_num)\n",
        "    sentence_temp.append(word)\n",
        "    sent_count_toelf += 1\n",
        "\n",
        "  else:\n",
        "    sentence_temp.append(word)\n",
        "    if methapor == 1:\n",
        "      containing_metaphor = 1\n",
        "\n",
        "avg_tokens_per_sent_toelf = sent_lenght_toelf_sum / sent_count_toelf\n"
      ],
      "metadata": {
        "id": "WLTNk7GfKWWS"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_for_tf_idf_toelf = []\n",
        "for i in range(0,len(sentences_toelf)):\n",
        "  tokens = sentences_toelf[i]\n",
        "  sentence = \"\"\n",
        "  for t in range(0,len(tokens)):\n",
        "    sentence += tokens[t] + \" \"\n",
        "  sentences_for_tf_idf_toelf.append(str(sentence))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "iIuwTDAVUYIO"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_for_tf_idf_toelf"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6HEJFFvWpoF",
        "outputId": "b697b2ab-6db4-4a24-d472-9baa044461d3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['believe specializing subject better important world live today broad knowledge many academic subjects ',\n",
              " 'broad knowledge many academic subjects good socially allows person communicate people many subjects ',\n",
              " 'However enough society live today decent job merely broad knowledge things ',\n",
              " 'Jobs require specific thorough knowledge specific subject subjects ',\n",
              " 'Working lawyer example requires thorough indepth knowledge law general knowledge enough become lawyer ',\n",
              " 'Specializing subject means person going become really good subject therefore pursue future ',\n",
              " 'ensures person able find job specialized world ',\n",
              " 'Someone specializes finance example work bank learn many things help everyday life gain knowledge job ',\n",
              " 'Therefore specialization leads broader knowledge subjects ',\n",
              " 'Specialization discovered agreed economists including father economics Adam Smith leads greater efficiency ',\n",
              " 'someone specializes something time discovers ways improve therefore becomes expert field ',\n",
              " 'led increase specialisation workplace jobs ',\n",
              " 'way anyone wishes succeed life job needs specialize something ',\n",
              " 'Due broad knowledge many academic subjects better specializing subject atleast point time ',\n",
              " 'agree people better broad knowledge many academic subjects ',\n",
              " 'reasons ',\n",
              " 'First make people broad knowledge oto difficulties companie society ',\n",
              " 'get jobs enter schools oppotunities talking many people ',\n",
              " 'time However spcific knowledge example knowledge mathematics speak mathematics ',\n",
              " 'possibility giving people impression boring person ',\n",
              " 'dagerous able lead nice lives society ',\n",
              " 'Second studying specific subject make future narrow ',\n",
              " 'example person studying mathematics order professor changes mind person want animal doctor person ',\n",
              " 'knowledge mathematics change future job ',\n",
              " 'person studied specific subject change dicide future decided thier future thier childhood ',\n",
              " 'conclusion specialize specific subject dagerousness possibilities deciding futures ',\n",
              " 'Therefore agree former statement ',\n",
              " 'past scholl university specific subject students knowledge many subjects ',\n",
              " 'Today number course university increase people specialized specific subject ',\n",
              " 'opinion better first year study broad knowledge generic materials specialized specific subject ',\n",
              " 'method students increasing culture material rapidly strenght ideas ',\n",
              " 'point system incresing new post work new type work ',\n",
              " 'complete opinion agree spend part study stage important study work ',\n",
              " 'summary today students specialised specific subject world work remain far specialisation ',\n",
              " 'question perfectly fits personal experience fact face important question career student worker ',\n",
              " 'university studied political science faculty gave wide knowledge different subjects politic history economy languages sociology philosophy mathematic law etc ',\n",
              " 'period studies found really usefull boring study different issues time making university vary always new method learning ',\n",
              " 'day lessons private law mathematic sociology variety subjects avoided risk getting tired studing always thing ',\n",
              " 'graduated face incredible world job ',\n",
              " 'point found studied university gave side wide range knowledges lack specific knowledge main subject ',\n",
              " 'knowledge better ',\n",
              " 'broad knowledge many academic subjects specialization specific subject ',\n",
              " 'still find right answer arrange lack giving compromising answer better specialized knowledge subject like focus job career optimize specialization widening much possible basic knowledge different subjects ',\n",
              " 'important factor concerns goals goal find good well retributed job specialize subject needed asked job world ',\n",
              " 'Nowadays graduated good wide knoledge graduated good specialization field studies ',\n",
              " 'hand goal general knowledge different aspects help understand single sector life istance political science spend years different academic subjects studying bit everything ',\n",
              " 'ultimately agree fact better specialized specific subject spread energy different subjects ',\n",
              " 'However say ultimately staying focused subject means always discard subjects ',\n",
              " 'found focus necessary important certain late stage personal working career academic career ',\n",
              " 'reason build Spikes knowledge broad knowledge platform ',\n",
              " 'sharp spikes knowledge allow promote pull society forward ',\n",
              " 'said deep knowledge subject based focus certain subject none born direction goal ready accomplished day birth ',\n",
              " 'Instead find path focus ourself need broad range knowledge ',\n",
              " 'Think example manager company good financially doesent know history politics ',\n",
              " 'always take best financial decision time always strong opposition team industry nt know history culture people business never able respect ',\n",
              " 'Therefore think early stage positive broad knowledge different subjects history languages politics arts mathematics Phisics biology economy ',\n",
              " 'However middle later stage focus refocus subjects love subjects give satisfactions ',\n",
              " 'example talk ',\n",
              " 'received education differents topics latin mathematics study engineering got doctorate degree engineering however day found life business therefore years working sales marketing decide build knoledge focused business matters pursue MBA study sure bring success people ',\n",
              " 'article discuss advantages drawbacks broad knowledge many academic subjects respect specializing specific subject ',\n",
              " 'think required today successeful career ',\n",
              " 'rest work organized follows ',\n",
              " 'Firstly analyze main issues studying many subjects ',\n",
              " 'focus problems related specialization ',\n",
              " 'decide study many subjects prepared wide range jobs ',\n",
              " 'However also drawbacks ',\n",
              " 'First hard follow many academic courses completely different topics ',\n",
              " 'Moreover jobs required high level specialization case better little good knowledge many poor skills ',\n",
              " 'Instead specialized specific subject find well paid job people background focused particular field ',\n",
              " 'hand highly specialized skills needed market challenging find new job start studying ',\n",
              " 'time however probably choose something general ',\n",
              " 'prospective awful happens old family ',\n",
              " 'conclusion think best solution something choices ',\n",
              " 'broad knowledge general field also specialized particular subject field ',\n",
              " 'argued better gain wider knowledge numerous academic subjects rather deeply research specific subject ',\n",
              " 'disagree idea specializing particular subject brings several advantages following reasons ',\n",
              " 'First technology really advanced nowadays professinals deep knowledge subject required generalists broader knowledge ',\n",
              " 'instance uncle works Micro Soft ',\n",
              " 'told started working company many employees vast general knowledges ',\n",
              " 'However computer technology developed dramatically company hires specialists days sophisticated programmers essential order advance technology ',\n",
              " 'tendency explains better focus specific subject broad knowledge wider subjects ',\n",
              " 'Second technology sophisticated specialized knowledge mandatory protect well ',\n",
              " 'example PC security computer hackers good example ',\n",
              " 'uncle assigned computer security division Micro Soft ',\n",
              " 'core members division PhD including uncle ',\n",
              " 'Hackers computers study computer programs deeply ',\n",
              " 'Thus security division hire people specialized fight hackers ',\n",
              " 'example also represents better gain specialized knowledge broader knowledge many academic topics ',\n",
              " 'Lastly specialized knowledge brings higher income ',\n",
              " 'instance uncle receives much higher salary long time friend sales representative Micro Soft ',\n",
              " 'friend studied various subjects school age actually regrets focused particular subject ',\n",
              " 'summary people insist better develop broad knowledge many academic subjects focus particular subject disagree idea ',\n",
              " 'latest sophisticated technology requires specialists particular subject develop protect ',\n",
              " 'Specialized knowledge also brings higher incomes ',\n",
              " 'Knowing little many things knowing less things question face many times life ',\n",
              " 'explosion knowledge number knolege fields make question provocative ',\n",
              " 'think answering question affected expected gains answer well personality individual answer ',\n",
              " 'life experience career person support answer undermine answer ',\n",
              " 'Speciality relative concept case ',\n",
              " 'career needs certain degree speciality days ',\n",
              " 'go field necessary knowledge skills well attitudes compromise field ',\n",
              " 'think question related level speciality needs ',\n",
              " 'words deep need go field speciality ',\n",
              " 'level issue wether isolte fields ignoring horizental knowledge ',\n",
              " 'social worker think empowering work life broad knowledge ',\n",
              " 'broad knowledge facilite communication different types clients ',\n",
              " 'client feels yuo share language build trust feel ',\n",
              " 'reason stems ability understding environment case include different types knowledge ',\n",
              " 'save going time somebody help ',\n",
              " 'point makes oppose ignoring broad knowledge sake specializing related personality individual ',\n",
              " 'think people like grow vertically knowlege ignoring horizental growth end socially isolated like ',\n",
              " 'general reasonable richness horizental knowled ',\n",
              " 'foremost business philosopher America Jim Rohn said survive twentieth century know skill ',\n",
              " 'Today life changing high pace ever ',\n",
              " 'computer age revolutianized possible aspect world gotten call age knowledge specialize specific subject enough order fulfill self ',\n",
              " 'Therefore better imperative gets specialized domain economic reasons personal reasons ',\n",
              " 'Everyone wants lead comfortable lives safe future ',\n",
              " 'want rich ',\n",
              " 'nobody going specialized field ever fields related ',\n",
              " 'instance let take real estate ',\n",
              " 'investor wants invest real estate education business law finance banking even construction ',\n",
              " 'investor familiar business know taxation policies kind construction material choose ',\n",
              " 'Therefore knowledge subject prove valuable asset comes increasing wealth ',\n",
              " 'seek knowledge everyone personal ambition ',\n",
              " 'process tough lifelong ',\n",
              " 'requires thirst learning hunger seek many truths world stores ',\n",
              " 'knowledge lot subjects virtue society ',\n",
              " 'gives reputation instant recognition ',\n",
              " 'Take company wants hire new employee possibility choosing candidates person business degree worked kind firm life holding degree worked many differenet trends business ',\n",
              " 'company choose latter exposed world candidate ',\n",
              " 'Also idea lot subjects self satisfying laugh person try trick ',\n",
              " 'world filled cons crook men ',\n",
              " 're limited type education chances cheated high ',\n",
              " 'Therefore broad knowledge many domains rewarding personal basis ',\n",
              " 'sum involved subject much better involved many reasons economic reasons personal reasons ',\n",
              " 'Today world obliges invest time education affect living conditions ',\n",
              " 'knowledgeable also rewarding gives good image reputation serve defence cheating ',\n",
              " 'important thing keep learning keep living loving leaving legacy others follow ',\n",
              " 'world live full variety diffrences people ',\n",
              " 'share diffrent cultures diffrent traditions diffrent jobs diffrent responsibilties ',\n",
              " 'Everybody diffrent others ways expressing life ',\n",
              " 'world huge stage nearly everybody actor ',\n",
              " 'able communicate others know others intresets mainly based aquir academic life ',\n",
              " 'vaste subject list ',\n",
              " 'better broad knowledge many academic subjects simply society requieres variety requieres change living humains ',\n",
              " 'lead communication communication lead knowledge ',\n",
              " 'Immagine persons life specialized specific subject ',\n",
              " 'variety communication expanded knowledge ',\n",
              " 'TYhis type persons communicate ressemblance times become outsiders ',\n",
              " 'COMPLETE ISOLATION society lead public danger suicide ',\n",
              " 'prefarable open person ',\n",
              " 'Meeting diffrent persons diffrent intersts charing diffrent aspects life ',\n",
              " 'Image man specialized complexe physics complexe physics draw life kind people ',\n",
              " 'difficult built family communicate wife children neighbors friends ',\n",
              " 'step turn isolation live work outside society thus failure life ',\n",
              " 'live absurde world much diffrent desiers intrestes ',\n",
              " 'herebly agree statment ',\n",
              " 'much better broad knowledge many academics subjects specialize specific subject ',\n",
              " 'Life adventure live feel rite ',\n",
              " 're flower said Descart grow acquire knowledge feel re kings world grow realize know little perplexe complexe world start become humble die ',\n",
              " 'Many people called specialists specialized specific subject ',\n",
              " 'think specialists needed society figure solutions many problems ',\n",
              " 'However agree statement better hav broad knowledge many academic subjects specialize specific subject ',\n",
              " 'initelligent people specialists ',\n",
              " 'Specializing certain subject hard requires much concentration intelligence ',\n",
              " 'Ordinally people compete intelligent people ',\n",
              " 'Also bored thing continuously forever ',\n",
              " 'Intelligent people specialized work solving problems others ',\n",
              " 'Knowing wide range things helps socialize people ',\n",
              " 'People communicate common topics ',\n",
              " 'Broad knowledge gives people lot ideas topic enables communicate show ',\n",
              " 'example couple people enjoying talking English literatures ',\n",
              " 'knows get conversation well ',\n",
              " 'hand idea never find way communicate ',\n",
              " 'Knowledge many academic subjects gives many choices people ',\n",
              " 'person knowledge math English laws pick ',\n",
              " 'person specialized subject change mind middle way ',\n",
              " 'scary person realizes interest different specialized ',\n",
              " 'knowledge anything else ',\n",
              " 'needs go back first stage choice ',\n",
              " 'Overall people need broad knowledge many academic subjects specialize specific subjecet intelligents specialize subject people broad knowledge helps communicate people people get change mind want ',\n",
              " 'Speacializing specific subject much effective broad knowledge many academic subjects ',\n",
              " 'early years nt lots scientists doctors ',\n",
              " 'time chosen broad knowledge opposing specific subject spealize ',\n",
              " 'yet days education improving competion people ',\n",
              " 'Therefore rather speacialize area inorder shine known uniqeness area ',\n",
              " 'past years doctor went matter feeling pain stomache problem eye sight still went doctor ',\n",
              " 'Nowadays doctors speacialized ',\n",
              " 'Even pediatritions speacilized doctor concerned part human body ',\n",
              " 'Furthermore look teachers ',\n",
              " 'school usually class teacher taught subjects ',\n",
              " 'English Math Science rest subjects ',\n",
              " 'yet moved high school started realizing teachers greater sense speacalized teacher subject ',\n",
              " 'take Science example teacher science different teacher Physics Biology Chemistry ',\n",
              " 'oving university start choosing major ',\n",
              " 'Take buisness example ',\n",
              " 'speacilize major find different smaller topic buisness shows speacilized ',\n",
              " 'trying prove decsion already made one able take lots subjects speaclize major ',\n",
              " 'opportuinty choose major sometimes able choose double major subjects related business accounting ',\n",
              " 'speacilizing subject find easier find job university start working motivating self fullfilling feel know major well makes job appreciate ',\n",
              " 'important choose major carefully subject speacilize live ',\n",
              " 'possible change career feel shame waste years studying start beginning ',\n",
              " 'totally agree statment person gets broad knowledge join depates open conversations types people like get broad knowldge cause also make look smart well educated person thats goals life ',\n",
              " 'specialized specific subject also good thing make proffional specific subject comes socity choose person broad knowldge person spacified knowledge think one knowledge educated talk understand whats stituation whats question talking person broad knowldege gives chances apportunities subjects talk person specialliezed subject makes stricted allthough profficional subject ',\n",
              " 'person educated called intellgenet familiar subjects example lawyer understand custmers sitiouation goes details persons personality using phsicology trying analyzie persons problem situation person knowldge person used life time using secound trying learn knowldge ',\n",
              " 'person like talk person broad knowldge talking person specific knowldge gain information person broad knowledge ',\n",
              " 'However also like person broad knowldge able talk people freak knowing person comes talk asking subject rather telling idea love anser question good answer ',\n",
              " 'conclution point view totally agree statement makes sence also reasons mentioned makes belive statmenet ',\n",
              " 'Use time wisely better person ',\n",
              " 'Many people find specialization convincing advanced position especially modern business world ',\n",
              " 'appears however broader knowledge many academic subjects called generalist getting important ',\n",
              " 'work biggest banking groups Japan includes permanent employees part-time employees ',\n",
              " 'Generally speaking products services bank provides require high-level specialized knowledge particulary stage products services developed organised ',\n",
              " 'However provided professionals industry also ordinary people special know-how skills financial instruments ',\n",
              " 'marketing stage importance broad knowleadge many academic subjects clearly identified people variety perspectives based academic backgrounds approach possible customers various angles ',\n",
              " 'important elements promoting enhancing business ',\n",
              " 'Secondly according business experience like stress good managers organization often various academic backgrounds well variety business experience ',\n",
              " 'saying specialist concentrates specific subject good manager ',\n",
              " 'However cases fact senior managers need cover extremely wide range business area ',\n",
              " 'context company highly likely regard broad knowledge based many academic subjects potential candidates good manegers finally future board members ',\n",
              " 'reasons stated believe broad knowledge many academic subjects highly appreciated specialize specific subject especially future business world ',\n",
              " 'opinion broad knowledge change person going think important broad knowledge many academics subjects reasons opinion global knowledge lot possibility choise work difficult able know better problem possibility resolving problem type problem ready resolve ',\n",
              " 'May broad knowledge specific subject ready test ability problem specific suject think know aspect subjet lot difficult ',\n",
              " 'opinion better broad knowledge many academic subjects alternative specific subject want change doesn many problem free specialize specific subject ',\n",
              " 'think change think change situation interesting always situation boring person boring happy doesn know best situations life ',\n",
              " 'think person hoe specialized specific subject doesn lot means liberty think day moment think ',\n",
              " 'person general broad knowledge free happy person ',\n",
              " 'better broad knowledge many academic subjects specialize specific subject broad knowledge always make anything moment ',\n",
              " 'specific knowledge limited ',\n",
              " 'world work specific knowledge difficult find job person broadn knowledge ',\n",
              " 'think important broad knowledge many academic subjects usually work required specialize knowledge specific subject ',\n",
              " 'well think person beautiful broad knowledge many academic subjects specialize specific subject knowledge speak people meet ',\n",
              " 'speak various type people ',\n",
              " 'people different trucks life ',\n",
              " 'people arrive various places world speak different languages ',\n",
              " 'specialize knowledge specific subject understand different subject well nt basic knowledge subject ',\n",
              " 'past nt possibility know many sub ',\n",
              " 'people say broad knowledge better believe tha specialize specific subject better human lives ',\n",
              " 'First new things innovated discovered specialized knowledge specific subject ',\n",
              " 'cutting edge technologies arts bring development human lives ',\n",
              " 'example robots aid handicapped people invented special research robot thechnology ',\n",
              " 'field arts computer graphic entertains many people films TVs invented computer ',\n",
              " 'example clearly shows specialized knowledge contributes society ',\n",
              " 'addition worry society specialized people biased hard live true ',\n",
              " 'various kind people special knowkedge complement others ',\n",
              " 'example many manufacture companies employ specialized people make research special fields ',\n",
              " 'Sometimes specialists produce strange things specialists divisions point problems products ',\n",
              " 'Even odd products go market nt sell ',\n",
              " 'Consequently specialistes realize wrong improve products leads innovation ',\n",
              " 'example clearly shows specialized knowledge always make biased society ',\n",
              " 'Thus people worry ',\n",
              " 'reasons pointed sure specialized knowledge leads better human life respected broad knowledge ',\n",
              " 'opinion better broad knowledge many academic subjects instead specialization ',\n",
              " 'say think best solution order find work today society companies continously change require huge flexibility adaptability new works ',\n",
              " 'According school provide give basical instruction teaching many different subjects ',\n",
              " 'way student quite complete background fileld choose ',\n",
              " 'think also specialization important work course implies person really good something specific ',\n",
              " 'also think high level specialization reached years years study work school nt give opportunity everybody ',\n",
              " 'example study design lots kind designs ',\n",
              " 'Interior design virtual design graphic design much ',\n",
              " 'really like Web design ',\n",
              " 'school gives first opportunity learn different tipes design second understand best ',\n",
              " 'school specialize Web design work basical preparation school gave time students class choose specialization according preferences ',\n",
              " 'model teaching subjects gives lots advantages nt rigid boring ',\n",
              " 'gives anyone possibility choose create limits ',\n",
              " 'Academic subjects start student working life develope career ',\n",
              " 'time important allow student opportunity understand really like future ',\n",
              " 'agree statement better person broad knowledge many academic subjects rather specialize specific subject ',\n",
              " 'Specialization good thing life helps person good effecient work ',\n",
              " 'However sometimes person chooses take many academic subjects gets interesting ',\n",
              " 'Lets say example person takes biology history phsycology ',\n",
              " 'knowledge great advantage ',\n",
              " 'leads person knowledgable aware lots things also gives sense fun ',\n",
              " 'mind expands gets different interesting information day different topics ',\n",
              " 'Knowledge bunch facts accquire experiences everyday routines ',\n",
              " 'knowledge thing makes life boring especially person always curious wants learn new things ',\n",
              " 'knowledge unlimited access anytime anywhere ',\n",
              " 'choose know everything certain topic limits knowledge topic ',\n",
              " 'knowing information different topics ',\n",
              " 'makes even social different type people ',\n",
              " 'doctor knows history gets people astonished ',\n",
              " 'begin understand fact good also interest many things ',\n",
              " 'high school always chosen different electives music french also computer lessons ',\n",
              " 'wanted know even good major subject ',\n",
              " 'made feel wise able talk people alot subjects ',\n",
              " 'argue talk different areas different types people gives good impression also makes life interesting learn new stuff facts everyday ',\n",
              " 'explains actors persuing careers singing leaders charity acts organizations ',\n",
              " 'want try ',\n",
              " 'better broad knowledge many academic subjects ',\n",
              " 'learn different facts everyday gives color mind ',\n",
              " 'Life short say make use ',\n",
              " 'easy say better approach personally agree statement think broad knowledge many academic subjects good specializing specific subject ',\n",
              " 'say main reasons ',\n",
              " 'first reason practical students ',\n",
              " 'mean concentrate subject easier learn lots things subject able become prepared ',\n",
              " 'say practical refer also fact studing subject instead good student path ',\n",
              " 'mean student entered subject know subject requires important aspects able organise studies best way ',\n",
              " 'aintaining mind open lot subjects big effort ',\n",
              " 'true keep mind open good thing giving wide range knowledge question knowledge useful future ',\n",
              " 'question brings expose second reason supports opinion ',\n",
              " 'argue specialising useful working ',\n",
              " 'Companies institutions usually hire people generalistic approach know lot things remain surface ',\n",
              " 'Companies require people expert something become expert get things discover aspects prevent problems ',\n",
              " 'personal experience say m class generalistic approach think good ',\n",
              " 'm glad ve got solid basic culural background sincerely worried future ',\n",
              " 'ask class answer know ',\n",
              " 'chose class thougth specialistic wrong think lucky well opportunity attend lots intersting courses meet lots good professors ',\n",
              " 'key answer question think different pourposes study ',\n",
              " 'Certainly specialization specific academic topic essential research ',\n",
              " 'First specialization brings deep knowledge better comprehension ',\n",
              " 'want say orginal thing concerning subject know almost already written ',\n",
              " 'sense focalized study foundamental ',\n",
              " 'hand want reasearch broad knowledge surely useful ',\n",
              " 'mind open outside topic find diffent approach problems help ',\n",
              " 'also bring ideas fields specific ',\n",
              " 'able use analogy resolve problems powerful method ',\n",
              " 'observations surely better specialize ',\n",
              " 'pourpose study merely stay world instruments person studied many different topics cultured ',\n",
              " 'better position anyone nt studied studied thing ',\n",
              " 'also difficult betray ',\n",
              " 'pousposes nt stop studying always curious brain always active ',\n",
              " 'Concernig reasons support idea restrict fields interest ',\n",
              " 'read written topic able start studying different subject contrary nt ',\n",
              " 'known different topic involves different part brain vital development whole brain specialize learn different subjects music literature sciences ',\n",
              " 'conclusion better spend efforts topic study much subjects ',\n",
              " 'help work life keep safe longer brain ',\n",
              " 'good specialize subject agree opinion people broad knowledge many academic subjects ',\n",
              " 'First even interested subject study better see subjects ',\n",
              " 'Seeing ranges helpful enlarge knowledge ',\n",
              " 'see many things read many kinds books brain feelings soft learn things ',\n",
              " 'Secondly also help make sure learned ',\n",
              " 'way know correct sight narrow small ',\n",
              " 'learned something specific subject say subject ',\n",
              " 'see many ways judge ',\n",
              " 'also academic subjects connect subject ',\n",
              " 'exist world many materials exist together complex way well ',\n",
              " 'subject look different fact telling world ',\n",
              " 'Unexpectedly subjects things ',\n",
              " 'sum support opinion better broad knowledge many academic subjects reasons ',\n",
              " 'better specialize specific subject broad knowledge many academic subjects easier normal human study subject spend time ',\n",
              " 'People prefare studying languages sue nt time many things life take aolt human time ',\n",
              " 'reason human amny social prblems make confused consetrating studying better study subject ',\n",
              " 'Also studying subject make human sucsessful studying ',\n",
              " 'eaxample person studied business administration spend time energy became amazing career job ',\n",
              " 'little time take courses thing likes ',\n",
              " 'hand broad knowledge good haver well informations many things life disagree many knowledge many academic subjects wasting time espcially person familly childrens difficult take care family studying time ',\n",
              " 'family need time spend main ting life good family grow good peple ',\n",
              " 'perents nt time thier family reflect negative way childrens ',\n",
              " 'studying subject allow person time life take care ',\n",
              " 'thing study better peaon self also better country live ',\n",
              " 'think subject study well ',\n",
              " 'depends person personality life scadule ',\n",
              " 'person idea ',\n",
              " 'disagree opinion young people enjoy life older people ',\n",
              " 'think true young people students much time going friends ',\n",
              " 'graduate school life style going changed suddenly especialy Tokyo ',\n",
              " 'First lose private time ',\n",
              " 'work hard improve ablility job earn money payment apartment fee haviing dating saving future marriage holidays ',\n",
              " 'Old people money time people young generation ',\n",
              " 'main reason disageed opinion ',\n",
              " 'First better experience younger people ',\n",
              " 'Fine foods shopping good quality funiture clothes go abload cruesing etc ',\n",
              " 'experience said m better life 30s experienced 20s ',\n",
              " 'enjoy eating good restaurant going precious classic concert buying good quality clothing ',\n",
              " 'thing said negative point old people nt enough energy physically sometime ',\n",
              " 'example hobby used skiing feel start losing enogh physical toughness recently keep high speed big snow slope keep moving mountain montain ',\n",
              " 'know natural changing everyone face actually kind sad ',\n",
              " 'm sure people enjoy better life getting old thant yonger generation ',\n",
              " 'know want ',\n",
              " 'enough financial confident much free time leisure enjoy life style ',\n",
              " 'Exellent statement ',\n",
              " 'think phrase question lots ask oneself ',\n",
              " 'difficult analyze try explain idea ',\n",
              " 'Immagine mind right hand young people supposed young fouty years old opposite hand old people ',\n",
              " 'idea fist part people simpler find something general enjoy life second part ',\n",
              " 'reasons young always suppose much energy dicover something new example new sports new interests new passions new works ',\n",
              " 'reasons used old people young reason old people enjoy life less young ',\n",
              " 'get old people mind think start look think worked life studied life pretty tired ',\n",
              " 'mind difficult think future spend time nothing maybe able like young want discover new part wolrd seen love sport think live want increase knoledge start work ',\n",
              " 'reasons understand old people cannnot think wolud difficult organize life old ',\n",
              " 'However think possible personal example grandfather morning new day discover ',\n",
              " 'disagree young people enjoy life older people ',\n",
              " 'reasons ',\n",
              " 'First older people much time young people older people retired thier jobs enjoy second life slowly ',\n",
              " 'working busy want ',\n",
              " 'take many vacations ',\n",
              " 'things working lot time ',\n",
              " 'However young people nt lot time ',\n",
              " 'go school work ',\n",
              " 'Students exams ',\n",
              " 'recqired study harder harder exams ',\n",
              " 'Second money young people ',\n",
              " 'working save money future ',\n",
              " 'buy want go want eat want ',\n",
              " 'Finally course older people experienced lot things ',\n",
              " 'know problem happens ',\n",
              " 'also know avoid problem ',\n",
              " 'experience hard things seemed solve problem young people experienced thing yet ',\n",
              " 'Even young people experienced thing number much less older people ',\n",
              " 'Yes agree statment says Young people enjoy life older people basid follwing facts Young people responsipelties older people going schools enjoy rest day playing spending time deferent actevity admit time changed dramaticlly current time facility avalible yong people lived past lettel chances faciliteis happning days ',\n",
              " 'Old people got aeg need enjoy rest days spend saved past years time spicially beleves jobs somebody eals times ',\n",
              " 'young people still young responseblities stage sould live chaildhood good enviroment ',\n",
              " 'beleve parents willing anything kids nt chaildhood addition seames everything availible young people days old days ',\n",
              " 'parents days keening grant kids best aportunity grant best chances raising put best schools comodations stand living ',\n",
              " 'also agree parents best kids official organaizitions world protecting childhood mon ',\n",
              " 'provided topic states young people enjoy life older people ',\n",
              " 'disagree statement opinion older people enjoy life young people ',\n",
              " 'Nowadays live world economically driven requires good planning wise decision making ',\n",
              " 'Due wide experiences life older people able plan wisely order enjoy lives ',\n",
              " 'example older people plan outings vacations activities events effectively young people ',\n",
              " 'vaction plan wanted go wanted see much cost ',\n",
              " 'way enjoy aspects vacation miss important events sightings ',\n",
              " 'went vaction younger people plan well eventually miss lot important activities sightings ',\n",
              " 'Consequently good planning older people spend mony wanted see enjoy ',\n",
              " 'younger people run money usually regret things see vacation ',\n",
              " 'addition older people money enjoy life younger people ',\n",
              " 'Older people established careers therfore financially sound actually save saved money enjoy lives stage ',\n",
              " 'younger people much money enjoy life school employed ',\n",
              " 'even thought career point lives ',\n",
              " 'hand always exceptions younger people plan well established careers financially well ',\n",
              " 'generally speaking due life experiences older people plan well established fields financially sound younger people ',\n",
              " 'disagree young people enjoy life older people becasue following reason ',\n",
              " 'enjoy life first thing realize precious lives ',\n",
              " 'life special celebrities politician ',\n",
              " 'normal life already special enough ',\n",
              " 'appriciate lives never really enjoy youth life ',\n",
              " 'However many young people seem loose interest thier lives ',\n",
              " 'Even many things take advantages education children development computer systems easy access world avalability social supports seem happy ',\n",
              " 'rather seem take advatages granted realize lucky ',\n",
              " 'reasons young people lost live thier life actively able picturelize years later ',\n",
              " 'Becasue bad economy political mess untrustable politicians strange teachers etc ',\n",
              " 'easy keep dreams ambitions children ',\n",
              " 'Instead learn word life way feeling giving ',\n",
              " 'chirdlen grow become young adult vision future ',\n",
              " 'hands even older people loosing physical abilities still live ',\n",
              " 'Especially old people war-experience know appriciate ',\n",
              " 'Life becomes enjoyable long people appriciate ',\n",
              " 'life simply consume time awful time waitng ending ',\n",
              " 'Even joung people usually enjoying older people necessarily true ',\n",
              " 'exemple meet really cool 60-years-old man everything power fun make life worth lived boring 20-years-old boy never step house go school ',\n",
              " 'hand iif true joung people enjoy life belief better take advantage youth late ',\n",
              " 'totally agree statement fact think people courage enjoy whole life wasting chances teenagers waiting long start following dreams ',\n",
              " 'Talking real facts people nominate many teens older people enjoying lifes ',\n",
              " 'Today world offers chances fun people ages lot parks resorts child go enjoy days parents great time ',\n",
              " 'Holiday resorts grandparents love spend week found almost anywhere course lot structures offer amusement teens years old ',\n",
              " 'person wants enjoy life nothing keeping ',\n",
              " 'Nevertheless always meet someone wanting ',\n",
              " 'really pay attention find kind behavior present people ages real average ',\n",
              " 'wants fuun nt ',\n",
              " 'Maybe way enjoying life even people consider boring worthless ',\n",
              " 'say young people enjoy life older ',\n",
              " 'causes bare big responsibilities shoulders responsible themself time rely help parents trouble category composed mainly composed high school university students ',\n",
              " 'important factor young tend explore life try new experiences go places never visited ',\n",
              " 'important factore also biological factore young people energy try new stuff enjoy life max ',\n",
              " 'opposite old people mostly big responsibilities ',\n",
              " 'children dependent ',\n",
              " 'povide stability famillies financial psychological ',\n",
              " 'Old poeple calculate steps take risks false step bad consequences dependent ',\n",
              " 'forget bilological factor also old people eager energy explore vibrant youngs ',\n",
              " 'last paragraphes represent population ',\n",
              " 'lots young people big responsibilites depend others help work support themself sometimes support famillies ',\n",
              " 'category youth enjoy life others ',\n",
              " 'also old people financial security stability category tend enjoy life ',\n",
              " 'conclusion statement nt simple YES answer ',\n",
              " 'Agreeing desagreeing depends personality person personality environement responsibilities ',\n",
              " 'really agree young people enjoy life older ',\n",
              " 'think enjoy different areas life intensity ',\n",
              " 'looks young people fun lot physical activities stage life body always full energy rich sensations ',\n",
              " 'side see lot old people prefer mental activities reading meditation conversation ',\n",
              " 'happens stage life learn take advantage mental skills ',\n",
              " 'exemple see park group kids blast soccer game grandparents sitting bench completly immerse conversation reading book ',\n",
              " 'Even music different worlds young generation enjoy fast laud music dance drop floor ',\n",
              " 'Adults get excited less hectic music listen dance well ',\n",
              " 'go dance studio see regardless age kind music people dancing everybody enjoing activity ',\n",
              " 'intencity put reward get related age ',\n",
              " 'get different sorses joy Sorses fitting physical mental status age ',\n",
              " 'impression young old people get lot joy activites choose ',\n",
              " 'said begining choose different ways spend time intencity pleasure level achive sure ',\n",
              " 'going grandpa ',\n",
              " 'shopping golfing maybe cruise yacht ',\n",
              " 'usually get really bored studing tired endless working hours grandfather even father getting ready go sort selfpleasing activity ',\n",
              " 'believe old people enjoy life youth even teenagers study work hours restrictions forced parents ',\n",
              " 'hard young family member enjoy life much elders ',\n",
              " 'begining old people kind study midterms finals care ',\n",
              " 'spend hours studing going school attending classes even buying books ',\n",
              " 'alot free time spend selfpleasing activity brings happiness joy ',\n",
              " 'addition old people job career care ',\n",
              " 'business owners unemployed evern better nothing distract fun ',\n",
              " 'young people spends hours week work ',\n",
              " 'much time enjoy ',\n",
              " 'Also financial wise young people alot bills payments ',\n",
              " 'school fees rent maybe car morgage enough money left spend fun enjoyment ',\n",
              " 'time elder people kind concerns Finaly limitations restrictions forced family kids donot leave much space fun ',\n",
              " 'supposed go allowed late thats usually young member family getting ',\n",
              " 'liek elder ones total freedom ',\n",
              " 'spare time avilability money abscence limitaions dought older people enjoy life much youn ones ',\n",
              " 'well start utterly disagree statement believe man life resembles different semesters year lies beauty happiness well problems solutions ',\n",
              " 'younger people motivated start thier journey life feel stronger motivated prove different kinds activities interest ',\n",
              " 'spring semester llives still green growing fast ',\n",
              " 'vast majority choices load decisions make ',\n",
              " 'older people relaxed autum semester thier lives made thier minds crucial things life took desicions handling life maturely less motivated aware ',\n",
              " 'trying shed light mentality status people different stages thier lives effect interact much enjoy life ',\n",
              " 'opinion effect level happiness pleasure enjoyment life differs individual totally related ones perception life prioreties goals ',\n",
              " 'much achieved ',\n",
              " 'want life ',\n",
              " 'need life ',\n",
              " 'ask questions time ',\n",
              " 'young people enjoy life older people ',\n",
              " 'really ',\n",
              " 'sum say people enjoy life regerdless thier age ',\n",
              " 'Thus make difference age individual personality look life achievments level sucess failure ',\n",
              " 'disagree statment think older people enjoy life yonger ones becouse older people money time health ',\n",
              " 'money older people alot money form savings years form sizing need big houses size move smaller houses get alot money also retierment plans give good money month relay ',\n",
              " 'time mostof retiered alot time enjoy find traveling alot engaged social activity fancy sports golfing sailing fishing need alot money time ',\n",
              " 'go economics magazines find alot atrticals elderly people baby boomers much spend traveling entertaiment sports ',\n",
              " 'Also exelent health servecise advanced health facilitis world see avarage life span female USA years male years thing enjoy thier life ',\n",
              " 'hand youner people work hard pay bills example graduate student working good job good career work hard order pay student loans dosent loan pay mortgage house young person doesnot acadimic dgree work job order live decent life hard working day donot time energy enjoy thing else want thing plan years ahead charge credit card pay later years intrest also younger people work hard plan retirment ',\n",
              " 'resons think older poeple enjoing life younger ones ',\n",
              " 'totally agree idea young people enjoy life older people ',\n",
              " 'Young people lot lifetime healthy many good communities ',\n",
              " 'first reason lot lifetime ',\n",
              " 'people country Japan live years ',\n",
              " 'Therefor young people age years old years lifetime ',\n",
              " 'buy lot things money however nt buy time ',\n",
              " 'Time important tings enjoy life think young people enjoy life lot ',\n",
              " 'next reason young people really healthy ',\n",
              " 'healthy really important enjoy life ',\n",
              " 'healthy everything want ',\n",
              " 'kind job want study lot everywhere ',\n",
              " 'kind sports enjoyable time travel everywhere want ',\n",
              " 'Even nt much money enertainments things possible make money want ',\n",
              " 'third reason young people lot community ',\n",
              " 'Young people unsually keep touch friends hometown school ',\n",
              " 'young lot time enjoy lot things together ',\n",
              " 'Also lot community maybe get lot help ',\n",
              " 'really healpful make life going well enjoy life lot ',\n",
              " 'really fun spend time people ',\n",
              " 'keep good relationship others make life great ',\n",
              " 'Thus totally agree idea young people enjoy life old people ',\n",
              " 'nt think considered natural rule fact older people enjoy life less young people ',\n",
              " 'time say generally happens several reasons ',\n",
              " 'First live society m specifically talking italian society age person decides leave family many reasons lack job opportunity lack bravery close ',\n",
              " 'means age young people nt face lot responsabilities ll obliged face future ',\n",
              " 'Less responsabilities young people means time available time generally use enjoy life b less available time thoughts consequence responsabilities parents ',\n",
              " 'general scheme normal italian family dynamic ',\n",
              " 'Fortunately it-s always ',\n",
              " 'personal experience support stating hat ',\n",
              " 'fact left house came live study Milan found job life dependence anyone ',\n",
              " 'allowed also parents spend time earned activities hobbies developing personal interests ',\n",
              " 'Enjoying time ',\n",
              " 'Enjoying life ',\n",
              " 'Even important reasons brings affirm young people generally enjoy life older ones second physiological reason ',\n",
              " 'difficult understand young feel climb mountains traveling world stops ',\n",
              " 'full energies bodies ready face almost kind situation ',\n",
              " 'thing older people necessarely maintain sort proportion efforts forces dispose ',\n",
              " 'lot things become forbidden physical reasons ',\n",
              " 'hand said older people enjoy life different way proportioned possibilities traveling developing interests ',\n",
              " 'disagree idea young people enjoy life older people ',\n",
              " 'idea seems shallow narrow ',\n",
              " 'rather say depends individual enjoy life generalize age ',\n",
              " 'going state examples support idea ',\n",
              " 'Firstly increasing number young people clear purpose life loss ',\n",
              " 'kind people often even work naturally means enough opportunity show ability ',\n",
              " 'kind life seems boring meaningless ',\n",
              " 'people enjoy moment life something funny stimulas impression fun temporary ',\n",
              " 'think mean fully enjoy thier life ',\n",
              " 'long many young people living obvious purpose destination think said young people enjoy life ',\n",
              " 'Secondly let introduce experience grand mother ',\n",
              " 'lives alone husband died energetic vigorous seems enjoy life much ',\n",
              " 'probably lot friends usually drop chat ',\n",
              " 'think needed others gives people life ',\n",
              " 'Lately even started singing friend Karaoke putting much enthusiasm ',\n",
              " 'seeing grand mother well convinced older people live life many enjoyments ',\n",
              " 'reasons think given statement superficial ',\n",
              " 'Even Young people feel life meaninngless boring enough chance older people fully enjoy life ',\n",
              " 'theirselves ',\n",
              " 'seems young people spend time something enjoy moment mean young people enjoy life mroe older people ',\n",
              " 'opinion older people enjoy life young people ',\n",
              " 'father year old life time job seems enjoying life younger brother year old still attending school ',\n",
              " 'reasons think way ',\n",
              " 'younger brother goes school everyday still time spend wants ',\n",
              " 'enjoying life ',\n",
              " 'answer ',\n",
              " 'often worried future problems face order succeed future ',\n",
              " 'still idea become later life many concerns achieve wants ',\n",
              " 'hand father works company busy time ',\n",
              " 'seems spare time spend enjoying life much ',\n",
              " 'experienced younger brother knowledge ',\n",
              " 'comes question person enjoying life believe lot experience ',\n",
              " 'older experienced handling problem easier face young age ',\n",
              " 'father life goal get job wants family already achieved concern future ',\n",
              " 'Therefore enjoy life much better younger brother concern life makes life enjoyable ',\n",
              " 'conclusion case family always true old people young people ',\n",
              " 'people able achieve goal still young perhaps young people enjoy life old people still struggling achieve goal ',\n",
              " 'cases believe older people enjoy life young people ',\n",
              " 'years old personal experience covers half statement part regarding young people however look relatives elder people infer something thay enjoy life ',\n",
              " 'first appoximation think enjoy life different way easy generalize evaluation distinguishing younger older people ',\n",
              " 'However point necessary even sufficient condition person enjoy life good health statistically true older people chances bad health Apart first consideration matter facts youngers olders conduct lifes ',\n",
              " 'fact important consideration work ',\n",
              " 'Younger people work harder olders often retirement younger less time spend enjoyment depending retirement system also less money ',\n",
              " 'Nonetheless young people opportunities fun enterteinments better fits discos kinds sport activities kinds concerts travels ',\n",
              " 'negative aspect connected wider range opportunities sometimes young people suffer kind anxiety fun lots things ends make always unhappy ',\n",
              " 'fact true maybe older people different way approaching life allows get best situation enjoy simple things ',\n",
              " 'different way appreciating things perhaps derives maturity whole experience make lifes relaxed sometimes serene ',\n",
              " 'conclusion think possible completely agree disagree statement depends individual attitudes external conditions person enjoy life different periods ',\n",
              " 'see life complicated people different described short phrase ',\n",
              " 'agree disagree statement ',\n",
              " 'strongly believe advantages well disadvantages phases life youth old age ',\n",
              " 'generally agreed young people strong physical qualities energy wide range opportunities potentially available life nt written yet ',\n",
              " 'time older people weaker need medical attention higher probabilities many choices young people grow older becomes late seize increasing number opportunities doors closed speak particular career-wise ',\n",
              " 'example young woman pursuing career acting attending theater classes struck sudden revelation decides true vocation marine biology simply quits theater studies enrolls science school ',\n",
              " 'Changing mind possible re say years old matter hard work competition probably field years kind gap practically impossible fill ',\n",
              " 're years old ve say theater actress re probably bound stay least nt opportunities d changed mind younger age short guess safely say getting old reduces opportunities successfully changing career field ',\n",
              " 'However clear advantages go older age security reduced uncertainty future comfort relying family feeling safety steady job gives likely happen age increases ',\n",
              " 'wise generalize much countries job market present high levels protection job-security low old well young divorce popular behavior dream happy family easily shattered turn nightmare ',\n",
              " 'agree opinion expressed statement ',\n",
              " 'day life possible hear statements ',\n",
              " 'Simple statements deriving philosophical thoughts simple expressions day life observation ',\n",
              " 'think possible explain cliche giving examples truly confirm point ',\n",
              " 'Young people time adults enjoy life ',\n",
              " 'Usually young people go school opportunity meet people age ',\n",
              " 'Sharing school-time make young people eager play sports together go night together enjoy life ',\n",
              " 'Adults usually think families usually work earn money necessary feed children less time want ',\n",
              " 'Adults actually time enjoy life ',\n",
              " 'Even adult rich person possibility organize life independently responsabilities ',\n",
              " 'become older accomplish order respect people expect ',\n",
              " 'written contrasted adfirming young people enjoy life know life ',\n",
              " 'Young people see hidden difficulties everyone experiences life ',\n",
              " 'know sometimes good know everything ',\n",
              " 'give also personal example Ichild life seemed easy thought become everybody wanted know real life different ',\n",
              " 'reach want want reach need forget sometimes friends sports things help enjoing life ',\n",
              " 'know necessary adult person find accomplishments work sources life enjoyment ',\n",
              " 'adult learns understand important things life enjoy life ',\n",
              " 'people say young people enjoy life older people ',\n",
              " 'However live older people healthy acitive used ',\n",
              " 'opinion older people enjoy life younger people ',\n",
              " 'first reason older people time money couterparts lot activities want ',\n",
              " 'example parents retired ',\n",
              " 'lot free time ',\n",
              " 'addition worked years large amount money spend ',\n",
              " 'travel almost month country already visited prefectuers country ',\n",
              " 'contrary work day less available time money got job last year ',\n",
              " 'able go somewhere even summer vacation ',\n",
              " 'reason young people concerns futures compared optimistic opinions showed older people leads young people negative ideas lives general ',\n",
              " 'illustration makes clear young people concerns pensions receive future ',\n",
              " 'aging society country getting serious young people receive enough money live retirement ',\n",
              " 'Therefore save money future lives afford enjoy present lives ',\n",
              " 'consideration respect available time money well negative ideas future lives think older people enjoy life younger people ',\n",
              " 'old people mature young persons money make lots interesting plans life traveling going fancy restaurants responsabilities increase age think responsabilies less get enjoy life ',\n",
              " 'life student full surprising experiments someone get discover day day ',\n",
              " 'nothing interesting simple student responsabilty studying little spending free time getting meet new friends partying often ',\n",
              " 'remember young person best time life meet friends true still contact thing young see often use time want meet schedule meetings advance even meet fun use ',\n",
              " 'age ',\n",
              " 'old happening ',\n",
              " 'stay late anymore thinking collecting momey difficulties responsabilities life ',\n",
              " 'point mentioned health athlete enjoy sport gathering friends soccer game unfornately anymore ',\n",
              " 'time small effort stop right away continue ',\n",
              " 'rekated growing older older alot responsabilities ',\n",
              " 'thing talk house duties shoping cleaning kisd demands weekend little free time things make busy enjoying life days day someone becoming older responsabilities increase think young people enjoy life yhan old people ',\n",
              " 'community many type people ',\n",
              " 'chiledren yong people old people ',\n",
              " 'part helping developing community even rlise way young people help community getting educated job forming family ',\n",
              " 'getting young people educated something impotant person community ',\n",
              " 'person get educated becomes intilligant wise right thing right time gives effort job help community develop graduate engneer bulid better roads doctor help pations become healthy police man protect community safer placeagain yong person helped community ',\n",
              " 'Afterwards young people get older get married children teach children good person help develop community children grow helpful community conclusion person working develop community getting educated good job forming family ',\n",
              " 'Young people today faced constant pressures family school community ',\n",
              " 'lives young person teenager today focuses common goal education ',\n",
              " 'pressures education family expectations time young person gives helping communtity enough ',\n",
              " 'reality young people today help community factor looked help community ',\n",
              " 'help community summer work load school decreased ',\n",
              " 'summer young people look summer jobs helping families working small businesses ',\n",
              " 'summer jobs young person dedicated bring community closer help community stronger future ',\n",
              " 'young person helps community indirect way working different aspects strengthen bonds community ',\n",
              " 'young person works Super Market greets everyone community warmth works give extra hand Super Market long run benefits community strong community happy provided food resources Super Market ',\n",
              " 'example young person volunteers summer work orphanage helping community greatly person volunteers giving expecting something back giving help community ',\n",
              " 'question asked much time person give helping communtity ',\n",
              " 'young person dedicate time gave helping community summer whole year ',\n",
              " 'Even minutes day benefit community significantley future ',\n",
              " 'conclusion young people helping commuinity need give time helping ',\n",
              " 'fully agree people nowadays give enough time helping communities think time money-oriented think going able make drastic changes ',\n",
              " 'People past however use dedicate time money effort community service ',\n",
              " 'fellow students think time join NGO help raising money poor follow schedule ',\n",
              " 'time eaten studying lazing asked make contributions helping raising money poor organising certain event think going prevent getting good grades ',\n",
              " 'people money-oriented ',\n",
              " 'time money ',\n",
              " 'want waste time helping communities ',\n",
              " 'tried recruit people order teach illeterate children read write ',\n",
              " 'question asked much going paid knew free declined ',\n",
              " 'reminded Doria Shafeek eminent feminist used buy children presents money make attend reading writing classes shrugged shoulders ',\n",
              " 'people think irrespective time effort going put helping communities able effect changes ',\n",
              " 'remember girl asked join Red Cross training course opinion skillful enough ',\n",
              " 'woman responsible recruiting people gave book Florence Nightingale started scratch difference made field nursing talked pampered women society princesses used pride learned nurse casualties war ',\n",
              " 'really boosted girl morale made join course ',\n",
              " 'Poeple give enough time communities busy ignorant benefits going reap difference going make ',\n",
              " 'think conscience raising sessions point people important working community ',\n",
              " 'perfectly agree statement obviously young people course including help comunities ',\n",
              " 'think biggest reason connection became weak ',\n",
              " 'years ago parents ages strong connection neighbors ',\n",
              " 'Sometimes took care neighbor babies made dinner share neighbors ',\n",
              " 'often helped usual help comunities ',\n",
              " 'However many apartment houses many people live cities grow ',\n",
              " 'connection becoming weak weak sometimes know neighbors ',\n",
              " 'know people comunity probably feeling spend time help comunity ',\n",
              " 'addition time help comunity ',\n",
              " 'schools part time jobs working day ',\n",
              " 'also leave home eary morning come back home late night ',\n",
              " 'lifestyle time help people ',\n",
              " 'hand young people enough time help comunities ',\n",
              " 'examples people families live comunity sinch generations parents grandparents ',\n",
              " 'young people understand comunities help easily something ',\n",
              " 'conclusion agree statement perfectly ',\n",
              " 'mentioned know people enough time help comunities even busy ',\n",
              " 'connection communities help comunities also make time ',\n",
              " 'Nowadays young people organizations expected support communities liveare located ',\n",
              " 'life complexities growing responsibilities young people sufficient time help communities ',\n",
              " 'true individuals increasing number young people devoting time help communities communities need support ',\n",
              " 'observed young students sacrificing summer holidays help build houses volunteer poor African communities ',\n",
              " 'Yet also observed young people self involved day day life helping community care simply time priorities play friends go camp ',\n",
              " 'broader issue education young people taught classroom home ',\n",
              " 'Many homes lead example embed sence community sharing education children ',\n",
              " 'Hence young people devotng time communities ',\n",
              " 'indeed young people support communities however support sufficient growing world problems seeing nowadays ',\n",
              " 'therefore agree statement sufficient support available ',\n",
              " 'Young people energy provide lot help communities allocating little time day ',\n",
              " 'example teaching child community read write helping old person tasks capable support building new school hospital etc ',\n",
              " 'Many people associate help spending money sometimes case helping ones community ones personal time equally rewarding ',\n",
              " 'Helping ones community always financial ',\n",
              " 'many cisrcustances funding issue many organization available help fund communities need lacking human helping hand ',\n",
              " 'Seeing poverty Africa developing counties eye opener ',\n",
              " 'number size problems lives communities horrifying required help quantneeded world ',\n",
              " 'always problems continent helping hand however start increasing help communities best improve lives communities live ',\n",
              " 'statment really general disagree ',\n",
              " 'think category young people divided different groups ',\n",
              " 'Surely first division big groups teens young people ',\n",
              " 'Teens go studying becouse help communitie bigger usefull work ',\n",
              " 'time think period teen hold part day couriosity ',\n",
              " 'People category yet worker still student ',\n",
              " 'think situations helping communitie ',\n",
              " 'Obviously exceptions people different reasons nt found way ',\n",
              " 'exeptions ',\n",
              " 'Italy decide give social services society also stopping study year work hospitals old people houses something similar ',\n",
              " 'always think better way help communities find position worker system ',\n",
              " 'young people ',\n",
              " 'sould supposed ',\n",
              " 'really like understand becouse read statements child ',\n",
              " 'think past world wars private young people youth ',\n",
              " 'think right ',\n",
              " 'realize m living really beatiful time really comfortable place think mine going study improve work enjoy self ',\n",
              " 'things think m helping communitie ',\n",
              " 'said young people nt care community think general new generations keen helping towns variety ways ',\n",
              " 'many young boys girls spend lot time working poor disadvantaged ',\n",
              " 'example country several associations recruit personnel drive ambulances best friends demanding time-consuming job works compensation least week ',\n",
              " 'friend mine spends Sunday serving meals poor people church often tells performing service benefit community rewarding ',\n",
              " 'also ways help people skilled professionals great help certain areas ',\n",
              " 'classmate mine graduated medical school part association called Doctors boundaries sends doctors world help poor communities less developed countries ',\n",
              " 'sent Africa provided medical assistance many people ',\n",
              " 'think person clear sign young people willing help others therefore relied become active members communities ',\n",
              " 'fact young doctor willing help people remote country sure much keen contributing well community ',\n",
              " 'try get involved activities ',\n",
              " 'lawyer able spend past years assisting poor clients involved various kinds litigations charging ',\n",
              " 'examples see opinion eloquent signs younger generations less willing help others communities older ones ',\n",
              " 'Young people engine build communities ',\n",
              " 'benificial class communities years ago ',\n",
              " 'people believe young people give enough time helping communities ',\n",
              " 'First higher authority places elderly experienced persons community ',\n",
              " 'limit young people chances help community ',\n",
              " 'reason full time studying work obtain income benifits ',\n",
              " 'Many people believe young people nowadays give enough time help communities several reasons ',\n",
              " 'First young adults time help people university projects assignments ',\n",
              " 'example emphasize topics assignments helping people ',\n",
              " 'projects search people problems needs ',\n",
              " 'Secondly young adults enegy health utilize helping people visiting homes determining needs ',\n",
              " 'Finally young people give enough time real motivation ',\n",
              " 'Motivation move help communities much ',\n",
              " 'believe young people nowadays given enough time help people ',\n",
              " 'young people help communities better achievements improvements communities ',\n",
              " 'personally agree fact young people nowadays give enough time helping communities ',\n",
              " 'say aspect contemporary society due selfish behavior new generations something deeper explain situation ',\n",
              " 'belong internet era everything flowing everything moving quickly ',\n",
              " 'society way living changed lot 20th century nowadays people less time others ',\n",
              " 'helping poor needy people remarkable activities still commom communities young people educated help communities something young people find parents help ',\n",
              " 'sum say era history children ',\n",
              " 'globalisation era making world big total town everything seems ',\n",
              " 'situation understand little community catch attention young people sons world find difficult look perspective little town ',\n",
              " 'Nowadays many persons impression young people dedicate enough time helping communities ',\n",
              " 'personal experience provides society strong tendency observe negative examples provided young people really hard find free time dedicate others ',\n",
              " 'Today society seems love notice bad examples young people unfortunately phenomen usually brings strong critic young people general ',\n",
              " 'true quite big amount young people pretty selfish care others good ',\n",
              " 'extremely important hand unluckily noticed society times many young people involved example volunteering activities ',\n",
              " 'even important number strongly increase young people free time ',\n",
              " 'School really hard requires lots efforts many young people also dedicate times activities playing musical instrument learning new language perhaps also need rest sometimes easy understand finding free afternoon dedicate others easy ',\n",
              " 'reason young people engaged volunteering activities admired society able time care good others ',\n",
              " 'example dedicate Friday afternoon help young children homework ',\n",
              " 'activity gives lot often renounce study order time ',\n",
              " 'amount young people involved volunteering activies big number young people involved activities big ',\n",
              " 'young people admired able week full things find time dedicate others ',\n",
              " 'agree idea young people nowadays give enough time helping communities ',\n",
              " 'reasons supporting idea free time young people space help society lack corelate experience others ',\n",
              " 'First young people seem losing free time ',\n",
              " 'competing era need work hard get good education suppose give better future ',\n",
              " 'Therefore young people including children expected spent much time make prepartion coming test ',\n",
              " 'Increasing number cram school especially one young people crealy shows fact many young pepople spenting time study ',\n",
              " 'Thus time help community ',\n",
              " 'Second space role help society ',\n",
              " 'Nowadays many crimes young people ',\n",
              " 'Therefore people suspecting young people ',\n",
              " 'result even young people willing help society limited spaces available ',\n",
              " 'example students want help wipe snow deep-snow city checked name school going help ',\n",
              " 'school lower level school able help possibility one cheet community ',\n",
              " 'result say even young people want help society society reject ',\n",
              " 'Finally young people lose chance experience good co-relationship others ',\n",
              " 'lower rate get job people competing time many enemys young people ',\n",
              " 'result good corelationship others core idea helping community hard task think ',\n",
              " 'feel importance helping think spent little free time help community ',\n",
              " 'conclusion busy rejected society idea corelation others young people helping communities point view ',\n",
              " 'factors strongly connected ',\n",
              " 'question agree statement young pepole need perticipate community mpew ',\n",
              " 'resons economical benefit learning social ability improving personality ',\n",
              " 'Firstly helping thir community purly benefit economic ',\n",
              " 'take part non-profit group keeping environment good condition gorvenment need spend extra money order improve environment ',\n",
              " 'Acording survey countries people help communities spend less money countries many pepole help communities ',\n",
              " 'reasons certain need make young people help comunities ',\n",
              " 'Secondly helping communities enables teenagers learn social ability ',\n",
              " 'used help home old ',\n",
              " 'helping know comminicate old pepole ',\n",
              " 'However helping begin learn speak old pepole also also understood really important talk old people ',\n",
              " 'experience hardly learn social ability ',\n",
              " 'Lastly young people able grow helping community ',\n",
              " 'brother used really rude ',\n",
              " 'However become far humane bny ',\n",
              " 'experience maintain take part communities better personality become ',\n",
              " 'resons say helping society really important ',\n",
              " 'Nevertheless recently young pepole spend time taking part communities ',\n",
              " 'Consequently need spend time participating communities ',\n",
              " 'Nowadays life tough expensive young people lot responsibilies life ',\n",
              " 'Depending economic system depending country live young people study get diploma able find job earn money independant parents studying takes lot time need work well study hard hep give time community ',\n",
              " 'stay healthy young people spend time gym practicing sport outside take extra time ',\n",
              " 'small percentage young people get engaged early maybe family take care lead lack free time family members work depending employment law young people need work full time duty nt time help outside ',\n",
              " 'young people come wealthy families depending family education maybe conditions allow helpful communities improve community living help needy people young person participate personnal skillls possibility best community members ',\n",
              " 'Everyone active member help others way stronger ans life look easier others knows maybe oneday need help happy find support others ',\n",
              " 'opinion everyone little time give community improve life better future country citizenship residency ',\n",
              " 'active member community mother children help others giving little time psycholgical support needy persons helping children vaccinations updated way help improve life community ',\n",
              " 'agree statement young people nowadays give enough time helping communities ',\n",
              " 'days many young people playing around even obstacle others ',\n",
              " 'country Japan unemployed young people serious problem ',\n",
              " 'people never goes outside work ',\n",
              " 'often get food supplies hobby goods parents ',\n",
              " 'people surely helping communities spend time playing computer games ',\n",
              " 'friend used play lot childhood friend staying house day nothing ',\n",
              " 'friend mother saying great get room start searching job family income sufficient ',\n",
              " 'case ',\n",
              " 'young people Japan spend time running neighborhoods motorcycles usually noisy sound motorcycles ',\n",
              " 'hostile causes lot fights ',\n",
              " 'fights public property destroyed people get injured ',\n",
              " 'got injured people last week ',\n",
              " 'standing park waiting friend people came saying park place never enter ',\n",
              " 'punced face badly injured ',\n",
              " 'Young people ones help develop communities yet achieved country ',\n",
              " 'think people obstacle others stop harming people destroying public property first ',\n",
              " 'gradually helping communities make better ',\n",
              " 'agree statement young people nowadays give enough time helping communities ',\n",
              " 'many young people seen community activities seems interest local ',\n",
              " 'reasons thought thinking issue ',\n",
              " 'Firstly young people seem busy life less interest communities ',\n",
              " 'everyday life basically achool university ',\n",
              " 'study subjects interest also participating circle school activitiy ',\n",
              " 'guessed young people spend time instead helping local communities ',\n",
              " 'Secondly community systematically organized young people participate ',\n",
              " 'problem Japanese society local communities working many places people less contact neighbors ',\n",
              " 'example big cities people living high building appartments normal people know people live ',\n",
              " 'see people busy life rarely chance really get together form community ',\n",
              " 'Therefore young people spend time help communities ',\n",
              " 'Lastly local communities mainly run older people people retired jobs time ',\n",
              " 'people gather organize community activities spread neighbors ',\n",
              " 'example takes time organize event community ',\n",
              " 'need plan things also go knock doors ask participation ',\n",
              " 'enough people struggle work harder ',\n",
              " 'natural say people time chance participate help communitiy ',\n",
              " 'reasons youg people spend less time community compared older people ',\n",
              " 'points stated agree young people nowadays give enough time helping communities ',\n",
              " 'Young people energetic big help interest somewhere else difficult bring back attention ',\n",
              " 'personally diagree statement says young people give enough time communities ',\n",
              " 'disagree general statment typical stereotype categorizing young people ',\n",
              " 'addition statment non credible statement abviouly based personal opinion rather facts supported statistics menaingfull numbers ',\n",
              " 'statment carries alot hidden meaning even insults young people pictures selfish people nt care community ',\n",
              " 'also indirectly indicates young people irresponsible people positively contribut communities activeusefull members community ',\n",
              " 'addition statment made young people general statment young people give enough time communities ',\n",
              " 'young people addicted charity work dedicates lot time helping improve community helping others ',\n",
              " 'Thus nt generalize ',\n",
              " 'also disagree statement personally think weak statment becaue supported kind eveidence survey statistics meaning full numbers ',\n",
              " 'statement throwing accusasions others ',\n",
              " 'statments acceptable disagree witth particular statment accepted stereotypes means well accept stereotypes ',\n",
              " 'encouraging stereotypes serious even dangerous seriouly affcet society community even way even quality living ',\n",
              " 'first sight inferred young people show interest helping community seem become ego-directed order prevent duties society asking ',\n",
              " 'likely explanations help community seen convenient used rewarded enough ',\n",
              " 'Young people nt feel duty think world probably go help ',\n",
              " 'Furthermore young people seem live present moment future almost feel duties society effect future future next generations ',\n",
              " 'youngers seem share opinion absolutely true ',\n",
              " 'likely grown strong ideals steady sense tradition still continue putting efforts helping community ',\n",
              " 'people living small towns easily influenced touched community problems ',\n",
              " 'unusual prepared helping surroundings live ',\n",
              " 'nt say youngers living cities able contrary thanks devices provided city easily help communities interested ',\n",
              " 'Compared decades ago modern society living doubt passed huge number changings ',\n",
              " 'Given hard say really brought improvement decrease quality everyday life ',\n",
              " 'certainly true young people summerize important common features society ',\n",
              " 'believe young people nowadays least trying give enough time help communities ',\n",
              " 'seems helping enough time lives fully commit percent service ',\n",
              " 'However help others little litte ',\n",
              " 'communities anyway ',\n",
              " 'countries neighbors ',\n",
              " 'least school American School Japan focuses service communities countries neighbors ',\n",
              " 'recently joined club school called Sok Sabay supports cambodian orphanages provide home food supply ',\n",
              " 'non-profit organization profits make club goes straight shelter Cambodia ',\n",
              " 'sometimes collect clothes pencils toys books children send ',\n",
              " 'get thanks letters children primary source happiness motivation commitment club ',\n",
              " 'Sok Sabay non-profit organization school ',\n",
              " 'Habitat Humanity Phillipine Relief Organization UNICEF ',\n",
              " 'students join clubs even join ',\n",
              " 'busy lives try somehow part service program countries ',\n",
              " 'also National Honor Society strongly focuses service program especially neighbor communities ',\n",
              " 'make rice balls homeless people weekends visit orphanage shelter month ',\n",
              " 'optional attend acitives members NHS help willingly ',\n",
              " 'also support Runnathon acitivity year American Club ',\n",
              " 'Moreover meetings almost week keep minds NHS members necessary think issues service programs ',\n",
              " 'actively help support neighbors ',\n",
              " 'young people care others believe people school different ',\n",
              " 'know somehow part services least think ',\n",
              " 'believe necessity enough time service ',\n",
              " 'Nothing enough therefore need keep reminding taking action worths ',\n",
              " 'Even little action help someone school builds sense service others ',\n",
              " 'disagree idea society formed selfish young people ',\n",
              " 'completely true ',\n",
              " 'depends family friends social background ',\n",
              " 'Indeed lived family parents think concentrated job difficult think helping communities ',\n",
              " 'case son daughter usually thinks studies toys things goods others need help ',\n",
              " 'lived different family parents taught help people also animals matter change ',\n",
              " 'start also home daily routine ',\n",
              " 'taught son important help something occasions home ',\n",
              " 'son stayed home front tv day said nothing negative sense help responsabilities ',\n",
              " 'begins education ',\n",
              " 'education help someone basis ',\n",
              " 'nt depend young people education ',\n",
              " 'met life lot interesting young people help day friends people need ',\n",
              " 'always belong catholic society many strong values family love friendship sacrifice ',\n",
              " 'always believe something God politic values ',\n",
              " 'believe utopistic theory communism ',\n",
              " 'never met generous unselfish young people strong values ',\n",
              " 'young people interested help communities lack important values ',\n",
              " 'believe strong catholic values try free time help people differrent ways ',\n",
              " 'm teacher work cases earning order help poor people ',\n",
              " 'important point always depends education young people sometimes many hobbies appointments day time left helping people ',\n",
              " 'parent prohibited kind day routine young people less busy available time help others need ',\n",
              " 'conclusion souls young people desire help communities adults help ',\n",
              " 'agree young people nowadays give enough time helping communities ',\n",
              " 'thinking friends find many young people interacted community lot ',\n",
              " 'believe culture change happening worldwide considered usual days ',\n",
              " 'grandparents young said remembered parents interacting community deeply felt normanl live way ',\n",
              " 'time grandparents little Wordl War II happening therefore strong bond community needed nowadays ',\n",
              " 'Young teenagers look little children help old people ',\n",
              " 'something order survive ',\n",
              " 'However war ended parent generation born much situations needed people stick together way survive ',\n",
              " 'parent said remember parent tell care community help parent grew parent said never really understood ',\n",
              " 'also remember parents teaching interact community spend time ',\n",
              " 'years life moved times father job time moved new community hard family join easily ',\n",
              " 'kind giving kind culture ',\n",
              " 'Even person never moved around much believe many people like interact community people became colder connection different people ',\n",
              " 'western parts eastern countries cultural change religion also significance change ',\n",
              " 'old days religion strict christian attend mass Sunday ',\n",
              " 'However nowadays attending mass quite free many people critisises attend mass ',\n",
              " 'However mean spending time community wastful people acting way ',\n",
              " 'Human beings live interacting imporant well help benefits ',\n",
              " 'sad nowadays young people spending enough time community future connect people create comfortable community ',\n",
              " 'totally agree statmentYoung people nowadays give enough time helping communities ',\n",
              " 'evaluate following paragraphs ',\n",
              " 'tell reasons state mean helping communities ',\n",
              " 'working society time free means Volunteer ',\n",
              " 'First nowadays young people lot things school ',\n",
              " 'example small test everyday big exam onece month Leaving certificate end school really important colleage ',\n",
              " 'mean young people study takes enough lot time ',\n",
              " 'Hence difficult time comminties ',\n",
              " 'second reason many ways fun weekend ',\n",
              " 'past taking pictures freinds Shopping Game Center Disco ',\n",
              " 'popular young people ',\n",
              " 'Hence much prefer instead helping comunties ',\n",
              " 'Also opinion young people imagie community hard ',\n",
              " 'care fashion points school Celeblities gosships ',\n",
              " 'never interested real societies ',\n",
              " 'see society people cahnged ',\n",
              " 'words young people things ',\n",
              " 'know selfish ridiculous opinions young people nowdays give enough yimr y ',\n",
              " 'Nowadays common young people always away responsibility self management self motivation beeing caretaker ',\n",
              " 'people believe phase recognize right thing ',\n",
              " 'believe young people helping thier communities many reasons ',\n",
              " 'First well grown families perents problem touch perents childeren word say careless problem ',\n",
              " 'previous situatuation deffinetly lead unsatisfied person care thing self ',\n",
              " 'Second bad friends serious problem experienced situation believe natural thing young people always want know try see new things ',\n",
              " 'nature humen intrest need directed right way unfortunetlly directed people civilized ',\n",
              " 'Third free time fullfilling time useful benificial things Sports Studying working job important young people builds feeling responsibility enhanse feeling ownership improve personality ',\n",
              " 'conclusion young people well raised good friend selected spending free useful productive works iam sure really helpful community far body see happenning ',\n",
              " 'totally agree statement rather simplistic ',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_lengths = [250, 500, 1000, 3000]\n",
        "\n",
        "results_toelf = {'Dataset': [], 'Feature Length': [], 'Model': [], 'Accuracy': [], 'Precision': [], 'Recall': [], 'F1-Score': []}\n",
        "\n",
        "for length in feature_lengths:\n",
        "\n",
        "    vectorizer = TfidfVectorizer(max_features=length)\n",
        "    X = vectorizer.fit_transform(sentences_for_tf_idf_toelf)\n",
        "    names = vectorizer.get_feature_names_out()\n",
        "\n",
        "    train_sentences, test_sentences, labels_train, labels_test = train_test_split(X, labels_toelf, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train and eval Naive Bayes\n",
        "    nb_model = MultinomialNB()\n",
        "    nb_model.fit(train_sentences, labels_train)\n",
        "    nb_predictions = nb_model.predict(test_sentences)\n",
        "    nb_accuracy = accuracy_score(labels_test, nb_predictions)\n",
        "    nb_precision = precision_score(labels_test, nb_predictions)\n",
        "    nb_recall = recall_score(labels_test, nb_predictions)\n",
        "    nb_f1 = f1_score(labels_test, nb_predictions)\n",
        "\n",
        "    results_toelf['Feature Length'].append(length)\n",
        "    results_toelf['Model'].append('Naive Bayes')\n",
        "    results_toelf['Accuracy'].append(nb_accuracy)\n",
        "    results_toelf['Precision'].append(nb_precision)\n",
        "    results_toelf['Recall'].append(nb_recall)\n",
        "    results_toelf['F1-Score'].append(nb_f1)\n",
        "    results_toelf['Dataset'].append('TOEFL')\n",
        "    highestacc = nb_accuracy\n",
        "    bestmodel = 'NB'\n",
        "\n",
        "    # Train and eval SVM\n",
        "    svm_model = SVC(kernel='linear', random_state=42)\n",
        "    svm_model.fit(train_sentences, labels_train)\n",
        "    svm_predictions = svm_model.predict(test_sentences)\n",
        "    svm_accuracy = accuracy_score(labels_test, svm_predictions)\n",
        "    svm_precision = precision_score(labels_test, svm_predictions)\n",
        "    svm_recall = recall_score(labels_test, svm_predictions)\n",
        "    svm_f1 = f1_score(labels_test, svm_predictions)\n",
        "\n",
        "    results_toelf['Feature Length'].append(length)\n",
        "    results_toelf['Model'].append('SVM')\n",
        "    results_toelf['Accuracy'].append(svm_accuracy)\n",
        "    results_toelf['Precision'].append(svm_precision)\n",
        "    results_toelf['Recall'].append(svm_recall)\n",
        "    results_toelf['F1-Score'].append(svm_f1)\n",
        "    results_toelf['Dataset'].append('TOEFL')\n",
        "    if svm_accuracy > highestacc:\n",
        "        highestacc = svm_accuracy\n",
        "        bestmodel = 'SVM'\n",
        "\n",
        "    # Train and eval Logistic Regression\n",
        "    logreg = LogisticRegression(random_state=16)\n",
        "    logreg.fit(train_sentences, labels_train)\n",
        "    logreg_pred = logreg.predict(test_sentences)\n",
        "    logreg_acc = accuracy_score(labels_test, logreg_pred)\n",
        "    logreg_precision = precision_score(labels_test, logreg_pred)\n",
        "    logreg_recall = recall_score(labels_test, logreg_pred)\n",
        "    logreg_f1 = f1_score(labels_test, logreg_pred)\n",
        "\n",
        "    results_toelf['Feature Length'].append(length)\n",
        "    results_toelf['Model'].append('Logistic Reg.')\n",
        "    results_toelf['Accuracy'].append(logreg_acc)\n",
        "    results_toelf['Precision'].append(logreg_precision)\n",
        "    results_toelf['Recall'].append(logreg_recall)\n",
        "    results_toelf['F1-Score'].append(logreg_f1)\n",
        "    results_toelf['Dataset'].append('TOEFL')\n",
        "    if logreg_acc > highestacc:\n",
        "        highestacc = logreg_acc\n",
        "        bestmodel = 'LogReg'\n",
        "\n",
        "    # Train and eval Multi-Layer-Perceptron classifier\n",
        "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
        "                        hidden_layer_sizes=(5, 2), max_iter=4000, random_state=1)\n",
        "    clf.fit(train_sentences, labels_train)\n",
        "    mlp_pred = clf.predict(test_sentences)\n",
        "    mlp_acc = accuracy_score(labels_test, mlp_pred)\n",
        "    mlp_precision = precision_score(labels_test, mlp_pred)\n",
        "    mlp_recall = recall_score(labels_test, mlp_pred)\n",
        "    mlp_f1 = f1_score(labels_test, mlp_pred)\n",
        "\n",
        "    results_toelf['Feature Length'].append(length)\n",
        "    results_toelf['Model'].append('MLP')\n",
        "    results_toelf['Accuracy'].append(mlp_acc)\n",
        "    results_toelf['Precision'].append(mlp_precision)\n",
        "    results_toelf['Recall'].append(mlp_recall)\n",
        "    results_toelf['F1-Score'].append(mlp_f1)\n",
        "    results_toelf['Dataset'].append('TOEFL')\n",
        "    if mlp_acc > highestacc:\n",
        "        highestacc = mlp_acc\n",
        "        bestmodel = 'MLP'\n",
        "\n",
        "    average = (nb_predictions + svm_predictions + logreg_pred + mlp_pred) / 4\n",
        "    averageacc = (nb_accuracy + svm_accuracy + logreg_acc + mlp_acc) / 4\n",
        "    print('Average accuracy', round(averageacc, 5))\n",
        "    print('RMSE: ', round(mean_squared_error(labels_test, average), 5))\n",
        "\n",
        "    if averageacc > highestacc:\n",
        "        highestacc = averageacc\n",
        "        bestmodel = 'Ensemble'\n",
        "\n",
        "    print('Best model: ', bestmodel + '    Model Accuracy: ', round(highestacc, 5))\n",
        "    print('------')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLbE9XZy3pOg",
        "outputId": "8948e075-9dfb-4c5b-e206-ddbaa8ce001e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracy 0.63686\n",
            "RMSE:  0.29927\n",
            "Best model:  SVM    Model Accuracy:  0.65693\n",
            "------\n",
            "Average accuracy 0.66286\n",
            "RMSE:  0.27977\n",
            "Best model:  NB    Model Accuracy:  0.66971\n",
            "------\n",
            "Average accuracy 0.6615\n",
            "RMSE:  0.28513\n",
            "Best model:  SVM    Model Accuracy:  0.68431\n",
            "------\n",
            "Average accuracy 0.64599\n",
            "RMSE:  0.28878\n",
            "Best model:  SVM    Model Accuracy:  0.67701\n",
            "------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df_toelf = pd.DataFrame(results_toelf)\n",
        "print(results_df_toelf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxOFS4Kr4dW_",
        "outputId": "651298e1-07c0-4cf8-f963-abd78cb8a1ac"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Dataset  Feature Length          Model  Accuracy  Precision    Recall  \\\n",
            "0    TOEFL             250    Naive Bayes  0.631387   0.626016  0.330472   \n",
            "1    TOEFL             250            SVM  0.656934   0.639752  0.442060   \n",
            "2    TOEFL             250  Logistic Reg.  0.656934   0.643312  0.433476   \n",
            "3    TOEFL             250            MLP  0.602190   0.532468  0.527897   \n",
            "4    TOEFL             500    Naive Bayes  0.669708   0.683099  0.416309   \n",
            "5    TOEFL             500            SVM  0.664234   0.652174  0.450644   \n",
            "6    TOEFL             500  Logistic Reg.  0.655109   0.648649  0.412017   \n",
            "7    TOEFL             500            MLP  0.662409   0.613208  0.557940   \n",
            "8    TOEFL            1000    Naive Bayes  0.660584   0.669065  0.399142   \n",
            "9    TOEFL            1000            SVM  0.684307   0.678571  0.489270   \n",
            "10   TOEFL            1000  Logistic Reg.  0.658759   0.655405  0.416309   \n",
            "11   TOEFL            1000            MLP  0.642336   0.586047  0.540773   \n",
            "12   TOEFL            3000    Naive Bayes  0.667883   0.742857  0.334764   \n",
            "13   TOEFL            3000            SVM  0.677007   0.679487  0.454936   \n",
            "14   TOEFL            3000  Logistic Reg.  0.664234   0.702479  0.364807   \n",
            "15   TOEFL            3000            MLP  0.574818   0.000000  0.000000   \n",
            "\n",
            "    F1-Score  \n",
            "0   0.432584  \n",
            "1   0.522843  \n",
            "2   0.517949  \n",
            "3   0.530172  \n",
            "4   0.517333  \n",
            "5   0.532995  \n",
            "6   0.503937  \n",
            "7   0.584270  \n",
            "8   0.500000  \n",
            "9   0.568579  \n",
            "10  0.509186  \n",
            "11  0.562500  \n",
            "12  0.461538  \n",
            "13  0.544987  \n",
            "14  0.480226  \n",
            "15  0.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(sentences_for_tf_idf_toelf))\n",
        "print(len(labels_toelf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB3XsHRzbOnd",
        "outputId": "8bb32cd0-a429-4382-bd48-02ad20eb6111"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2737\n",
            "2737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ensemble model**"
      ],
      "metadata": {
        "id": "JxbSiWBV7uCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vecstack import stacking\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=3000)\n",
        "X = vectorizer.fit_transform(sentences_for_tf_idf_toelf)\n",
        "names = vectorizer.get_feature_names_out()\n",
        "\n",
        "train_sentences_toelf_3, test_sentences_toelf_3, labels_train_toelf_3, labels_test_toelf_3 = train_test_split(X, labels_toelf, test_size=0.2, random_state=42)\n",
        "\n",
        "# initializing all the base model objects with default parameters\n",
        "\n",
        "model_1_toelf = LogisticRegression(random_state=16)\n",
        "model_2_toelf = MultinomialNB()\n",
        "model_3_toelf = SVC(kernel='linear', random_state=42)\n",
        "\n",
        "# putting all base model objects in one list\n",
        "all_models_toelf = [model_1_toelf, model_2_toelf, model_3_toelf]\n",
        "\n",
        "# computing the stack features\n",
        "s_train_toelf, s_test_toelf = stacking(all_models_toelf, train_sentences_toelf_3, labels_train_toelf_3, test_sentences_toelf_3, regression=True, shuffle=True, n_folds=4)\n",
        "\n",
        "# initializing the second-level model\n",
        "final_model_toelf = model_1_toelf\n",
        "\n",
        "# fitting the second level model with stack features\n",
        "final_model_toelf = final_model_toelf.fit(s_train_toelf, labels_train_toelf_3)\n",
        "\n",
        "# predicting the final output using stacking\n",
        "pred_final_toelf = final_model_toelf.predict(s_test_toelf)\n"
      ],
      "metadata": {
        "id": "8fhYdVoB7fXV"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate evaluation metrics for Ensemble Model\n",
        "accuracy = accuracy_score(labels_test_toelf_3,pred_final_toelf)\n",
        "precision = precision_score(labels_test_toelf_3, pred_final_toelf)\n",
        "recall = recall_score(labels_test_toelf_3, pred_final_toelf)\n",
        "f1 = f1_score(labels_test_toelf_3, pred_final_toelf)\n",
        "mean_sqr_error = mean_squared_error(labels_test_toelf_3, pred_final_toelf)\n",
        "\n",
        "# Print the results\n",
        "print(\"Evaluation Metrics for Metaphor Detection:\")\n",
        "print(f\"Accuracy: {accuracy*100:.4f} %\")\n",
        "print(f\"Precision: {precision*100:.4f} %\")\n",
        "print(f\"Recall: {recall*100:.4f} %\")\n",
        "print(f\"F1-Score: {f1*100:.4f} %\")\n",
        "print(f\"Mean squared error: {mean_sqr_error:.4f}\")\n",
        "\n",
        "model_3_new_row_toelf = {'Dataset': 'TOEFL', 'Feature Length': 3000, 'Model': 'Ensemble', 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-Score': f1}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFJsjeBecB-Z",
        "outputId": "6b38d07c-a85c-437d-fc94-78388b6c5470"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics for Metaphor Detection:\n",
            "Accuracy: 67.8832 %\n",
            "Precision: 71.7557 %\n",
            "Recall: 40.3433 %\n",
            "F1-Score: 51.6484 %\n",
            "Mean squared error: 0.3212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_true_toelf = 0\n",
        "\n",
        "for num in labels_test_toelf_3:\n",
        "  if num == 1:\n",
        "    labels_true_toelf += 1"
      ],
      "metadata": {
        "id": "PDmZsJZUBKc6"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toelf_data = {'Dataset': 'toelf',\n",
        "            'Measurement' : ['Sent. count', 'Tokens', 'Unique tokens', 'Avg token per sent', 'sent with methapor', 'Testing sent count', 'How many with metaphor'],\n",
        "            'Values' : [sent_count_toelf, token_sum_toelf, len(unique_tokens_toelf), avg_tokens_per_sent_toelf, sentence_with_methapor_count_toelf, len(labels_test_toelf_3), labels_true_toelf]\n",
        "            }"
      ],
      "metadata": {
        "id": "sYVCfBFwAvgV"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FrameBERT**"
      ],
      "metadata": {
        "id": "MH_AZDe-3wKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modifying Ottawa data for FrameBert testing\n",
        "\n",
        "train_sentences_toelf_b, test_sentences_toelf_b, labels_train_toelf_b, labels_test_toelf_b = train_test_split(sentences_toelf, labels_toelf, test_size=0.2, random_state=42)\n",
        "\n",
        "string_toelf = ''\n",
        "\n",
        "for sentence in test_sentences_toelf_b:\n",
        "  for index, s in enumerate(sentence):\n",
        "    if index == len(sentence) - 1:\n",
        "      string_toelf += s + \"\\n\"\n",
        "    else:\n",
        "      string_toelf += s + \" \"\n",
        "\n",
        "temp = { \"articles\": string_toelf }\n",
        "\n",
        "json_sentences_toelf = json.dumps(temp)\n",
        "\n",
        "with open('sentences_toelf.json', 'w') as writefile:\n",
        "    writefile.write(json_sentences_toelf)"
      ],
      "metadata": {
        "id": "pSivNWkr9TpJ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py sentences_toelf.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4SzYSpI-f7_",
        "outputId": "39014bd8-e9c5-4564-d1fa-bf26e48d0212"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-08 09:28:31.647845: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-08 09:28:31.683060: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-08 09:28:31.693633: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-08 09:28:31.722119: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-08 09:28:33.525302: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Map: 100% 1/1 [00:00<00:00,  8.84 examples/s]\n",
            "{'tokens': ['general', 'scheme', 'normal', 'italian', 'family', 'dynamic', 'Moreover', 'source', 'clean', 'pollutant', 'air', 'environment', 'make', 'easier', 'terms', 'regulations', 'obtain', 'car', 'People', 'learn', 'things', 'thier', 'mistakes', 'order', 'successful', 'face', 'new', 'obstacles', 'overcome', 'rather', 'know', 'gaining', 'anything', 'safely', 'say', 'people', 'never', 'get', 'chance', 'success', 'manualized', 'never', 'want', 'take', 'risks', 'everybody', 'things', 'way', 'reasons', 'mentioned', 'believe', 'impossible', 'decrease', 'number', 'cars', 'use', 'today', 'years', 'visited', 'India', 'Egipt', 'Morocco', 'Instead', 'learn', 'word', 'life', 'way', 'feeling', 'giving', 'firstly', 'persons', 'stood', 'wiaited', 'people', 'thing', 'successful', 'persons', 'want', 'need', 'understand', 'learn', 'implicate', 'Even', 'young', 'student', 'office', 'workers', 'difficult', 'adjust', 'curcumstances', 'person', 'knowledge', 'math', 'English', 'laws', 'pick', 'Today', 'society', 'seems', 'love', 'notice', 'bad', 'examples', 'young', 'people', 'unfortunately', 'phenomen', 'usually', 'brings', 'strong', 'critic', 'young', 'people', 'general', 'points', 'stated', 'agree', 'young', 'people', 'nowadays', 'give', 'enough', 'time', 'helping', 'communities', 'mother', 'always', 'say', 'lazy', 'generation', 'Nevertheless', 'think', 'aspects', 'justified', 'marginal', 'aspects', 'core', 'ones', 'example', 'look', 'projects', 'greater', 'engineers', 'undertaken', 'work', 'new', 'cars', 'model', 'new', 'mechanical', 'tecnological', 'sources', 'order', 'develop', 'services', 'car', 'education', 'help', 'someone', 'basis', 'Travel', 'always', 'connected', 'much', 'information', 'add', 'knowledge', 'travel', 'think', 'professor', 'tell', 'fact', 'story', 'support', 'main', 'concept', 'idea', 'using', 'fact', 'story', 'remember', 'important', 'understand', 'povide', 'stability', 'famillies', 'financial', 'psychological', 'people', 'never', 'goes', 'outside', 'work', 'many', 'cisrcustances', 'funding', 'issue', 'many', 'organization', 'available', 'help', 'fund', 'communities', 'need', 'lacking', 'human', 'helping', 'hand', 'kind', 'job', 'want', 'study', 'lot', 'everywhere', 'really', 'healpful', 'make', 'life', 'going', 'well', 'enjoy', 'life', 'lot', 'thing', 'older', 'people', 'necessarely', 'maintain', 'sort', 'proportion', 'efforts', 'forces', 'dispose', 'case', 'like', 'make', 'product', 'worse', 'addition', 'christmas', 'vacation', 'visited', 'NY', 'study', 'excited', 'enjoy', 'studying', 'beleive', 'time', 'ultimate', 'value', 'life', 'plan', 'advance', 'exactly', 'going', 'receive', 'something', 'nt', 'know', 'yet', 'better', 'position', 'anyone', 'nt', 'studied', 'studied', 'thing', 'Successful', 'ambitions', 'stop', 'particular', 'point', 'always', 'ambitions', 'always', 'want', 'achieve', 'matter', 'much', 'risk', 'cause', 'professors', 'explain', 'concepts', 'difficult', 'understand', 'important', 'remember', 'exam', 'high', 'shool', 'student', 'interested', 'buying', 'inter', 'net', 'entered', 'soccer', 'team', 'like', 'soccer', 'shoose', 'spare', 'time', 'avilability', 'money', 'abscence', 'limitaions', 'dought', 'older', 'people', 'enjoy', 'life', 'much', 'youn', 'ones', 'believe', 'utopistic', 'theory', 'communism', 'show', 'situation', 'facts', 'extremely', 'releated', 'knowledge', 'concept', 'history', 'classroom', 'teacher', 'elementery', 'school', 'told', 'student', 'second', 'world', 'war', 'horrorfy', 'event', 'thing', 'people', 'really', 'careful', 'information', 'provided', 'many', 'ads', 'days', 'Moreover', 'answer', 'question', 'different', 'brain', 'structure', 'everyone', 'course', 'make', 'plan', 'trip', 'especially', 'according', 'time', 'budget', 'available', 'always', 'important', 'opportunity', 'change', 'find', 'something', 'nt', 'enjoy', 'think', 'position', 'easily', 'supported', 'numerous', 'current', 'TV', 'programs', 'backpaking', 'traveling', 'alone', 'seeking', 'so-called', 'adventure', 'traveling', 'Agreeing', 'desagreeing', 'depends', 'personality', 'person', 'personality', 'environement', 'responsibilities', 'get', 'good', 'score', 'tests', 'glad', 'study', 'hard', 'm', 'sure', 'people', 'enjoy', 'better', 'life', 'getting', 'old', 'thant', 'yonger', 'generation', 'product', 'opnion', 'statement', 'needs', 'ways', 'people', 'tranport', 'feel', 'comfortable', 'convenient', 'cars', 'Nowadays', 'life', 'tough', 'expensive', 'young', 'people', 'lot', 'responsibilies', 'life', 'bring', 'situation', 'school', 'say', 'leader', 'successful', 'person', 'brave', 'turned', 'reaults', 'experiences', 'method', 'time', 'brings', 'result', 'example', 'happened', 'went', 'germany', 'family', 'tour', 'company', 'want', 'advertise', 'product', 'making', 'effort', 'make', 'look', 'better', 'People', 'feel', 'comforatable', 'travel', 'group', 'people', 'probably', 'first', 'time', 'see', 'places', 'gradually', 'helping', 'communities', 'make', 'better', 'oving', 'university', 'start', 'choosing', 'major', 'number', 'people', 'increasing', 'world', 'wide', 'lots', 'countries', 'population', 'control', 'problem', 'leader', 'Many', 'surround', 'product', 'brand', 'fantastic', 'characteristics', 'implying', 'people', 'wear', 'buy', 'cool', 'special', 'people', 'different', 'trucks', 'life', 'Ideas', 'concepts', 'base', 'theory', 'sociological', 'movement', 'remember', 'facts', 'date', 'names', 'expose', 'discussion', 'explain', 'make', 'people', 'ideas', 'changing', 'fully', 'aware', 'problems', 'occur', 'live', 'denial', 'life', 'visit', 'famouse', 'Japanes', 'places', 'local', 'people', 'able', 'schedule', 'journey', 'depending', 'group', 'plans', 'stay', 'bed', 'late', 'wake', 'early', 'morning', 'enjoy', 'sunrise', 'summarize', 'students', 'opinion', 'important', 'understand', 'reason', 'concepts', 'ideas', 'rather', 'memorize', 'mechanically', 'facts', 'dates', 'numbers', 'shopping', 'golfing', 'maybe', 'cruise', 'yacht', 'suggest', 'prefer', 'ecological', 'means', 'transport', 'order', 'respect', 'planet', 'defend', 'pollution', 'hard', 'think', 'human', 'race', 'diminish', 'entire', 'part', 'culture', 'lives', 'short', 'period', 'years', 'work', 'biggest', 'banking', 'groups', 'Japan', 'includes', 'permanent', 'employees', 'part-time', 'employees', 'seems', 'ways', 'equally', 'valued', 'fact', 'value', 'example', 'young', 'woman', 'pursuing', 'career', 'acting', 'attending', 'theater', 'classes', 'struck', 'sudden', 'revelation', 'decides', 'true', 'vocation', 'marine', 'biology', 'simply', 'quits', 'theater', 'studies', 'enrolls', 'science', 'school', 'suffering', 'sleeping', 'problems', 'liked', 'advertisement', 'music', 'color', 'sleeping', 'pill', 'nice', 'shiny', 'pink', 'color', 'way', 'say', 'forced', 'becuase', 'say', 'right', 'refuse', 'know', 'somehow', 'part', 'services', 'least', 'think', 'broad', 'knowledge', 'general', 'field', 'also', 'specialized', 'particular', 'subject', 'field', 'opposite', 'also', 'true', 'new', 'ideas', 'change', 'behavior', 'people', 'resulting', 'new', 'events', 'human', 'history', 'citizen', 'case', 'kind', 'products', 'cause', 'accident', 'user', 'using', 'cars', 'make', 'people', 'less', 'oppotunities', 'exercise', 'mean', 'young', 'people', 'study', 'takes', 'enough', 'lot', 'time', 'opinion', 'stongly', 'agree', 'successful', 'create', 'new', 'things', 'take', 'risks', 'several', 'reasons', 'base', 'everything', 'someone', 'learns', 'concidered', 'learning', 'young', 'people', 'come', 'wealthy', 'families', 'depending', 'family', 'education', 'maybe', 'conditions', 'allow', 'helpful', 'communities', 'improve', 'community', 'living', 'help', 'needy', 'people', 'young', 'person', 'participate', 'personnal', 'skillls', 'possibility', 'best', 'community', 'members', 'want', 'waste', 'time', 'helping', 'communities', 'still', 'remember', 'went', 'Thailand', 'family', 'tour', 'guide', 'basically', 'always', 'showing', 'cultural', 'events', 'shows', 'far', 'authentic', 'expressions', 'local', 'habits', 'time', 'like', 'travell', 'alot', 'tendency', 'explains', 'better', 'focus', 'specific', 'subject', 'broad', 'knowledge', 'wider', 'subjects', 'lives', 'alone', 'husband', 'died', 'energetic', 'vigorous', 'seems', 'enjoy', 'life', 'much', 'always', 'suggests', 'new', 'things', 'trys', 'new', 'things', 'company', 'never', 'working', 'older', 'people', 'working', 'much', 'longer', 'father', 'mentioned', 'official', 'estimate', 'uncontrollable', 'population', 'growth', 'world', 'getting', 'young', 'people', 'educated', 'something', 'impotant', 'person', 'community', 'Younger', 'people', 'work', 'harder', 'olders', 'often', 'retirement', 'younger', 'less', 'time', 'spend', 'enjoyment', 'depending', 'retirement', 'system', 'also', 'less', 'money', 'media', 'industry', 'playing', 'people', 'trust', 'order', 'sell', 'products', 'diffrent', 'companies', 'pay', 'alot', 'make', 'attractive', 'advertisements', 'conclusion', 'better', 'spend', 'efforts', 'topic', 'study', 'much', 'subjects', 'always', 'enjoyed', 'traveling', 'knowledge', 'anything', 'else', 'strongly', 'hope', 'First', 'people', 'feel', 'comfortable', 'group', 'alone', 'course', 'places', 'world', 'example', 'Tokyo', 'subways', 'well', 'developed', 'people', 'nt', 'need', 'cars', 'get', 'around', 'future', 'car', 'moves', 'electricities', 'gasoline', 'speacilize', 'major', 'find', 'different', 'smaller', 'topic', 'buisness', 'shows', 'speacilized', 'OK', 'people', 'others', 'think', 'satisfied', 'reason', 'chinese', 'man', 'doughter', 'kills', 'chinese', 'government', 'nt', 'want', 'families', 'persons', 'women', 'decreased', 'opinion', 'people', 'curiocity', 'old-men', 'Even', 'conditions', 'getting', 'better', 'far', 'away', 'discussing', 'point', 'prevent', 'green-house', 'effect', 'really', 'sad', 'fact', 'leard', 'deal', 'company', 'advertisement', 'brand', 'well', 'known', 'country', 'Oman', 'complete', 'opinion', 'agree', 'spend', 'part', 'study', 'stage', 'important', 'study', 'work', 'Think', 'fast', 'food', 'industry', 'Italy', '80s', 'buy', 'want', 'go', 'want', 'eat', 'want', 'opinion', 'number', 'cars', 'going', 'increase', 'repidly', 'many', 'cars', 'cityes', 'm', 'thinking', 'time', 'blocked', 'traffic', 'm', 'thinking', 'stress', 'produce', 'situation', 'jungle', 'clacson', 'sound', 'peolpe', 'insult', 'others', 'reason', 'important', 'appointed', 'posticipated', 'Many', 'people', 'pearsonal', 'computer', 'use', 'inter', 'net', 'traveling', 'tour', 'guide', 'always', 'things', 'lose', 'opportunities', 'vaction', 'plan', 'wanted', 'go', 'wanted', 'see', 'much', 'cost', 'addition', 'older', 'people', 'money', 'enjoy', 'life', 'younger', 'people', 'seeing', 'grand', 'mother', 'well', 'convinced', 'older', 'people', 'live', 'life', 'many', 'enjoyments', 'First', 'people', 'like', 'new', 'things', 'involve', 'risky', 'things', 'call', 'risky', 'man', 'difficult', 'change', 'something', 'interessed', 'much', 'powerfull', 'person', 'world', 'world', 'huge', 'stage', 'nearly', 'everybody', 'actor', 'Specialized', 'knowledge', 'also', 'brings', 'higher', 'incomes', 'true', 'nice', 'looking', 'advertisement', 'make', 'people', 'feel', 'good', 'Nowadays', 'graduated', 'good', 'wide', 'knoledge', 'graduated', 'good', 'specialization', 'field', 'studies', 'needless', 'say', 'infrastructures', 'facilities', 'still', 'prepared', 'developing', 'countries', 'Folowing', 'take', 'specific', 'reasons', 'dislike', 'trabeling', 'tour', 'guide', 'doctor', 'instance', 'Chinese', 'law', 'states', 'family', 'child', 'think', 'fascinating', 'interesting', 'thing', 'visiting', 'new', 'country', 'call', 'taste', 'vacation', 'come', 'desire', 'discover', 'beauties', 'Even', 'sometimes', 'particular', 'traveling', 'short', 'amount', 'time', 'organized', 'group', 'guide', 'effective', 'generally', 'prefer', 'travel', 'kind', 'giving', 'kind', 'culture', 'addition', 'customer', 'like', 'real', 'product', 'wasted', 'money', 'advertisement', 'different', 'Second', 'ruch', 'hour', 'commuting', 'time', 'day', 'think', 'right', 'beleve', 'parents', 'willing', 'anything', 'kids', 'nt', 'chaildhood', 'addition', 'seames', 'everything', 'availible', 'young', 'people', 'days', 'old', 'days', 'Cars', 'first', 'modern', 'kind', 'way', 'use', 'long', 'time', 'consider', 'people', 'travel', 'important', 'issue', 'plan', 'journey', 'take', 'part', 'non-profit', 'group', 'keeping', 'environment', 'good', 'condition', 'gorvenment', 'need', 'spend', 'extra', 'money', 'order', 'improve', 'environment', 'example', 'tool', 'box', 'set', 'looks', 'great', 'shiny', 'made', 'cheap', 'materials', 'deform', 'easily', 'medium', 'mechanical', 'stress', 'Thirdly', 'many', 'people', 'know', 'also', 'leave', 'home', 'eary', 'morning', 'come', 'back', 'home', 'late', 'night', 'hand', 'subjects', 'learning', 'facts', 'essential', 'generally', 'speaking', 'due', 'life', 'experiences', 'older', 'people', 'plan', 'well', 'established', 'fields', 'financially', 'sound', 'younger', 'people', 'give', 'life', 'example', 'statments', 'give', 'example', 'personal', 'field', 'pharmacy', 'example', 'years', 'ago', 'trade', 'company', 'called', 'Suzuki', 'Shoten', 'Japan', 'nomal', 'rubber', 'shoes', 'dies', 'stay', 'long', 'said', 'time', 'however', 'probably', 'choose', 'something', 'general', 'People', 'spend', 'lot', 'money', 'misleading', 'advertisements', 'Next', 'summer', 'going', 'Japan', 'wife', 'spent', 'whole', 'year', 'learning', 'Japanes', 'international', 'exchange', 'program', 'great', 'ambition', 'strongly', 'desired', 'help', 'people', 'loss', 'mobility', 'However', 'middle', 'later', 'stage', 'focus', 'refocus', 'subjects', 'love', 'subjects', 'give', 'satisfactions', 'Limiting', 'use', 'kind', 'private', 'transportation', 'help', 'alot', 'mentaining', 'good', 'balance', 'usage', 'energy', 'sourses', 'fact', 'true', 'maybe', 'older', 'people', 'different', 'way', 'approaching', 'life', 'allows', 'get', 'best', 'situation', 'enjoy', 'simple', 'things', 'addition', 'old', 'people', 'job', 'career', 'care', 'Usually', 'young', 'people', 'go', 'school', 'opportunity', 'meet', 'people', 'age', 'sum', 'agree', 'idea', 'planes', 'ships', 'less', 'expensive', 'example', 'students', 'want', 'help', 'wipe', 'snow', 'deep-snow', 'city', 'checked', 'name', 'school', 'going', 'help', 'difficulties', 'incounter', 'vacation', 'experiences', 'described', 'seen', 'advertisements', 'make', 'products', 'seem', 'much', 'better', 'really', 'essay', 'm', 'going', 'write', 'opinion', 'best', 'way', 'travel', 'group', 'leader', 'tour', 'guide', 'think', 'best', 'way', 'travel', 'travel', 'alone', 'city', 'know', 'well', 'first', 'time', 'nt', 'places', 'city', 'tour', 'guide', 'true', 'keep', 'mind', 'open', 'good', 'thing', 'giving', 'wide', 'range', 'knowledge', 'question', 'knowledge', 'useful', 'future', 'process', 'tough', 'lifelong', 'many', 'people', 'know', 'cars', 'convinient', 'usefull', 'machine', 'Overtime', 'toshiba', 'laptops', 'become', 'expensive', 'read', 'written', 'topic', 'able', 'start', 'studying', 'different', 'subject', 'contrary', 'nt', 'Becasue', 'bad', 'economy', 'political', 'mess', 'untrustable', 'politicians', 'strange', 'teachers', 'etc', 'several', 'years', 'think', 'cars', 'nt', 'use', 'gasoline', 'using', 'car', 'harm', 'earth', 'CO2', 'car', 'produce', 'young', 'used', 'think', 'Aliens', 'existed', 'well', 'actually', 'think', 'exist', 'thought', 'first', 'thing', 'll', 'see', 'arriving', 'earth', 'roads', 'cars', 'moving', 'time', 'day', 'night', 'instance', 'man', 'like', 'claim', 'mountains', 'sailing', 'round', 'world', 'risky', 'swiming', 'country', 'others', 'depends', 'family', 'friends', 'social', 'background', 'ladder', 'success', 'changes', 'people', 'many', 'ways', 'take', 'first', 'step', 'people', 'willing', 'take', 'risks', 'try', 'new', 'things', 'journey', 'progresses', 'develope', 'new', 'mentality', 'built', 'past', 'innovative', 'dynamic', 'fruitfull', 'experiences', 'thus', 'paving', 'way', 'conservative', 'limited', 'mentality', 'reasons', 'thought', 'thinking', 'issue', 'Particuarly', 'firmly', 'convinced', 'good', 'education', 'provide', 'enough', 'information', 'learned', 'enough', 'concepts', 'understood', 'way', 'see', 'order', 'leesen', 'number', 'cars', 'use', 'come', 'ways', 'make', 'less', 'dependent', 'use', 'meaning', 'come', 'many', 'new', 'trasportation', 'way', 'systems', 'suffitient', 'time', 'efficent', 'enough', 'surve', 'public', 'people', 'climb', 'ladder', 'success', 'ideas', 'tend', 'change', 'dynamic', 'innovative', 'static', 'conservative', 'nt', 'use', 'car', 'transport', 'alternative', 'transportation', 'Everyone', 'life', 'successful', 'person', 'easy', 'successful', 'dissapointed', 'spray', 'work', 'summary', 'experience', 'different', 'culture', 'morning', 'evening', 'people', 'commuting', 'cars', 'including', 'privaite', 'vehicles', 'buses', 'spend', 'lot', 'time', 'really', 'wast', 'time', 'individuals', 'country', 'development', 'cutting', 'edge', 'technologies', 'arts', 'bring', 'development', 'human', 'lives', 'Passing', 'law', 'requires', 'lot', 'time', 'However', 'experience', 'United', 'States', 'say', 'people', 'nt', 'think', 'people', 'try', 'new', 'things', 'take', 'risks', 'success', 'really', 'like', 'understand', 'becouse', 'read', 'statements', 'child', 'lots', 'young', 'people', 'big', 'responsibilites', 'depend', 'others', 'help', 'work', 'support', 'themself', 'sometimes', 'support', 'famillies', 'enjoying', 'life', 'high', 'school', 'always', 'chosen', 'different', 'electives', 'music', 'french', 'also', 'computer', 'lessons', 'also', 'able', 'learn', 'many', 'things', 'traveling', 'alone', 'However', 'problems', 'remains', 'little', 'cities', 'car', 'necessary', 'winter', 'rainy', 'day', 'founding', 'company', 'owner', 'small', 'cycleshop', 'focus', 'problems', 'related', 'specialization', 'example', 'know', 'sometimes', 'water', 'comes', 'home', 'sink', 'use', 'drink', 'day', 'said', 'pure', 'big', 'advertisements', 'city', 'Finally', 'people', 'like', 'organize', 'follow', 'schuale', 'responsible', 'However', 'said', 'Chinese', 'Indian', 'population', 'increase', 'drastically', 'However', 'young', 'people', 'nt', 'lot', 'time', 'case', 'better', 'travel', 'group', 'tour', 'guide', 'totally', 'agree', 'statement', 'rather', 'simplistic', 'saw', 'life', 'everything', 'pass', 'practice', 'really', 'understand', 'value', 'importance', 'lots', 'theories', 'studied', 'past', 'world', 'changed', 'drastically', 'invention', 'cars', 'group', 'tour', 'guide', 'less', 'likely', 'kidnapped', 'rubbed', 'particular', 'trhere', 'elementse', 'important', 'used', 'advetisement', 'price', 'quality', 'goods', 'Students', 'likely', 'understand', 'phenomena', 'short', 'experiment', 'rather', 'long', 'perhaps', 'boring', 'lecture', 'mean', 'student', 'entered', 'subject', 'know', 'subject', 'requires', 'important', 'aspects', 'able', 'organise', 'studies', 'best', 'way', 'parents', 'recommended', 'go', 'place', 'study', 'math', 'like', 'focus', 'reasons', 'detail', 'need', 'read', 'keep', 'educating', 'kinds', 'products', 'try', 'much', 'posible', 'select', 'suitable', 'use', 'health', 'Second', 'feel', 'crucial', 'students', 'comprehend', 'ideas', 'concepts', 'learn', 'facts', 'understanding', 'ideas', 'concepts', 'help', 'students', 'improve', 'imagination', 'creativity', 'arguement', 'proposed', 'women', 'days', 'choosing', 'marry', 'job', 'opportunities', 'live', 'independantly', 'healthy', 'everything', 'want', 'opinion', 'better', 'first', 'year', 'study', 'broad', 'knowledge', 'generic', 'materials', 'specialized', 'specific', 'subject', 'method', 'advertisement', 'consumers', 'acutually', 'use', 'products', 'make', 'decision', 'buy', 'everybody', 'rides', 'car', 'goes', 'surely', 'going', 'shape', 'get', 'diseases', 'heart', 'attack', 'diabetes', 'things', 'think', 'm', 'helping', 'communitie', 'life', 'student', 'full', 'surprising', 'experiments', 'someone', 'get', 'discover', 'day', 'day', 'know', 'want', 'Typically', 'purse', 'expensive', 'watch', 'basic', 'functions', 'regarding', 'original', 'purpose', 'objects', 'mostly', 'considered', 'look', 'sensation', 'give', 'due', 'esthetic', 'values', 'determine', 'quality', 'image', 'fact', 'even', 'functional', 'still', 'used', 'Ever', 'commercials', 'promise', 'customers', 'greater', 'benefit', 'products', 'misleading', 'real', 'wants', 'needs', 'living', 'United', 'States', 'short', 'period', 'time', 'week', 'nt', 'car', 'Even', 'pediatritions', 'speacilized', 'doctor', 'concerned', 'part', 'human', 'body', 'think', 'people', 'obstacle', 'others', 'stop', 'harming', 'people', 'destroying', 'public', 'property', 'first', 'Broad', 'knowledge', 'gives', 'people', 'lot', 'ideas', 'topic', 'enables', 'communicate', 'show', 'course', 'analisys', 'foresee', 'eventual', 'tecnological', 'revolution', 'render', 'car', 'useless', 'car', 'horses', 'twentieth', 'century', 'major', 'economic', 'breakdown', 'render', 'cars', 'expensive', 'useful', 'trend', 'breaking', 'events', 'unpredictable', 'agree', 'best', 'way', 'travel', 'agroup', 'led', 'tour', 'guide', 'important', 'factor', 'concerns', 'goals', 'goal', 'find', 'good', 'well', 'retributed', 'job', 'specialize', 'subject', 'needed', 'asked', 'job', 'world', 'example', 'also', 'represents', 'better', 'gain', 'specialized', 'knowledge', 'broader', 'knowledge', 'many', 'academic', 'topics', 'make', 'look', 'better', 'make', 'look', 'different', 'say', 'something', 'different', 'guess', 'lerning', 'personal', 'experiance', 'way', 'valiable', 'nice', 'things', 'see', 'hear', 'products', 'advertisements', 'recently', 'joined', 'club', 'school', 'called', 'Sok', 'Sabay', 'supports', 'cambodian', 'orphanages', 'provide', 'home', 'food', 'supply', 'technologies', 'responds', 'particular', 'need', 'possibility', 'moving', 'faster', 'town', 'short', 'period', 'time', 'famous', 'example', 'program', 'called', 'global', 'trekkers', 'Young', 'people', 'unsually', 'keep', 'touch', 'friends', 'hometown', 'school', 'think', 'future', 'go', 'direction', 'safe', 'life', 'future', 'generations', 'instance', 'bought', 'washing', 'liquid', 'seeing', 'tv', 'products', 'gives', 'garanttee', 'take', 'away', 'marks', 'matter', 'deep', 'using', 'product', 'satisfied', 'Nowadays', 'common', 'young', 'people', 'always', 'away', 'responsibility', 'self', 'management', 'self', 'motivation', 'beeing', 'caretaker', 'young', 'person', 'dedicate', 'time', 'gave', 'helping', 'community', 'summer', 'whole', 'year', 'dentist', 'knew', 'nt', 'make', 'sense', 'successful', 'weeks', 'Toshiba', 'company', 'withdraw', 'laptop', 'batteries', 'market', 'specific', 'toshiba', 'laptop', 'word', 'nobody', 'stand', 'crowd', 'new', 'challengings', 'make', 'person', 'distinguished', 'others', 'Advertisements', 'branding', 'important', 'key', 'today', 'world', 'business', 'fact', 'become', 'essential', 'selling', 'product', 'item', 'understand', 'real', 'meaning', 'facts', 'agree', 'statement', 'successful', 'people', 'try', 'new', 'things', 'take', 'risks', 'rather', 'already', 'know', 'well', 'believe', 'people', 'strong', 'wish', 'successful', 'likely', 'successful', 'COMPLETE', 'ISOLATION', 'society', 'lead', 'public', 'danger', 'suicide', 'also', 'remember', 'parents', 'teaching', 'interact', 'community', 'spend', 'time', 'learned', 'something', 'specific', 'subject', 'say', 'subject', 'advertiser', 'showed', 'anyone', 'remove', 'hair', 'spraying', 'hair', 'simply', 'wiping', 'towel', 'CPA', 'broke', 'change', 'business', 'work', 'completely', 'changed', 'nowadays', 'even', 'become', 'sum', 'involved', 'subject', 'much', 'better', 'involved', 'many', 'reasons', 'economic', 'reasons', 'personal', 'reasons', 'going', 'grandpa', 'improve', 'knowledge', 'add', 'ideas', 'concept', 'array', 'clear', 'facts', 'hand', 'goal', 'general', 'knowledge', 'different', 'aspects', 'help', 'understand', 'single', 'sector', 'life', 'istance', 'political', 'science', 'spend', 'years', 'different', 'academic', 'subjects', 'studying', 'bit', 'everything', 'quiting', 'successful', 'job', 'Japan', 'leaving', 'life', 'Japan', 'family', 'friends', 'pleasure', 'learning', 'abig', 'part', 'civilization', 'always', 'believe', 'something', 'God', 'politic', 'values', 'needed', 'lots', 'patience', 'create', 'computers', 'telephones', 'make', 'really', 'convenient', 'also', 'people', 'drives', 'airoplanes', 'maybe', 'ships', 'think', 'true', 'young', 'people', 'students', 'much', 'time', 'going', 'friends', 'word', 'going', 'face', 'limitation', 'sourses', 'energy', 'new', 'decesions', 'control', 'consuming', 'gas', 'trasportation', 'always', 'think', 'better', 'way', 'help', 'communities', 'find', 'position', 'worker', 'system', 'opinion', 'broad', 'knowledge', 'change', 'person', 'going', 'think', 'important', 'broad', 'knowledge', 'many', 'academics', 'subjects', 'reasons', 'opinion', 'global', 'knowledge', 'lot', 'possibility', 'choise', 'work', 'difficult', 'able', 'know', 'better', 'problem', 'possibility', 'resolving', 'problem', 'type', 'problem', 'ready', 'resolve', 'Cars', 'change', 'way', 'move', 'people', 'society', 'progres', 'constantly', 'increase', 'importance', 'objects', 'real', 'lots', 'reasons', 'Moreover', 'people', 'world', 'got', 'idea', 'stick', 'mind', 'toshiba', 'laptops', 'best', 'hand', 'idea', 'never', 'find', 'way', 'communicate', 'second', 'reason', 'strongly', 'think', 'innovative', 'things', 'fundamental', 'basis', 'success', 'things', 'represent', 'norm', 'usual', 'market', 'market', 'unlikely', 'increase', 'reached', 'established', 'balanced', 'steady', 'state', 'born', 'parents', 'often', 'take', 'brother', 'vacation', 'Even', 'though', 'cooked', 'exactly', 'direction', 'says', 'looked', 'defferent', 'nice', 'Habitat', 'Humanity', 'Phillipine', 'Relief', 'Organization', 'UNICEF', 'Image', 'man', 'specialized', 'complexe', 'physics', 'complexe', 'physics', 'draw', 'life', 'kind', 'people', 'example', 'hobby', 'used', 'skiing', 'feel', 'start', 'losing', 'enogh', 'physical', 'toughness', 'recently', 'keep', 'high', 'speed', 'big', 'snow', 'slope', 'keep', 'moving', 'mountain', 'montain', 'Usually', 'teachers', 'tend', 'show', 'answer', 'students', 'students', 'know', 'answer', 'think', 'better', 'student', 'understand', 'easy', 'teach', 'teachers', 'Lets', 'say', 'example', 'person', 'takes', 'biology', 'history', 'phsycology', 'However', 'factors', 'promoting', 'use', 'cars', 'thus', 'result', 'number', 'cars', 'future', 'advertisements', 'make', 'products', 'seem', 'much', 'better', 'really', 'students', 'understand', 'ideas', 'become', 'productive', 'accomplished', 'grasping', 'analizing', 'ideas', 'leads', 'creativety', 'leads', 'creation', 'Universities', 'considerably', 'different', 'educational', 'systems', 'taking', 'trip', 'great', 'opportunity', 'talk', 'local', 'residents', 'able', 'tell', 'good', 'restaurants', 'nice', 'places', 'local', 'people', 'know', 'favorite', 'subject', 'always', 'Math', 'subjects', 'History', 'Literature', 'based', 'logic', 'also', 'think', 'high', 'level', 'specialization', 'reached', 'years', 'years', 'study', 'work', 'school', 'nt', 'give', 'opportunity', 'everybody', 'result', 'tend', 'less', 'responsible', 'person', 'enjoy', 'life', 'first', 'thing', 'realize', 'precious', 'lives', 'question', 'remains', 'effect', 'environment', 'Concluding', 'think', 'situations', 'nt', 'important', 'work', 'hard', 'important', 'know', 'someone', 'help', 'permit', 'job', 'success', 'According', 'school', 'provide', 'give', 'basical', 'instruction', 'teaching', 'many', 'different', 'subjects', 'agree', 'statement', 'believe', 'adverstisements', 'make', 'products', 'seem', 'much', 'better', 'really', 'even', 'important', 'number', 'strongly', 'increase', 'young', 'people', 'free', 'time', 'reasons', 'certain', 'need', 'make', 'young', 'people', 'help', 'comunities', 'Knowing', 'wide', 'range', 'things', 'helps', 'socialize', 'people', 'addition', 'newspapers', 'specified', 'number', 'pages', 'products', 'advertisements', 'boths', 'way', 'give', 'primises', 'successful', 'life', 'choose', 'success', 'based', 'time', 'saved', 'method', 'easy', 'say', 'better', 'approach', 'personally', 'agree', 'statement', 'think', 'broad', 'knowledge', 'many', 'academic', 'subjects', 'good', 'specializing', 'specific', 'subject', 'Even', 'frindship', 'continue', 'trip', 'Furthermore', 'people', 'disagree', 'idea', 'learning', 'facts', 'prefer', 'understanding', 'concepts', 'think', 'student', 'able', 'understand', 'ideas', 'ideas', 'unreal', 'many', 'students', 'hate', 'learn', 'fake', 'things', 'science', 'fiction', 'terror', 'stories', 'Today', 'world', 'obliges', 'invest', 'time', 'education', 'affect', 'living', 'conditions', 'nt', 'trust', 'success', 'Secondly', 'community', 'systematically', 'organized', 'young', 'people', 'participate', 'gauranttee', 'effecinecy', 'quality', 'product', 'big', 'company', 'brand', 'name', 'means', 'lot', 'specefic', 'company', 'conclusion', 'suggest', 'abandon', 'cars', 'start', 'taking', 'buses', 'simple', 'reasons', 'first', 'contribute', 'save', 'planet', 'pollution', 'secondly', 'buses', 'cheaper', 'cars', 'finally', 'enjoy', 'atmosphere', 'city', 'advertisements', 'gave', 'customers', 'valuable', 'information', 'product', 'intend', 'buy', 'neccessary', 'give', 'full', 'information', 'need', 'nessessary', 'ture', 'percent', 'many', 'reasons', 'Firstly', 'advertisement', 'prepared', 'specilaized', 'staff', 'expert', 'professionally', 'prepared', 'attact', 'customers', 'buy', 'products', 'Concernig', 'reasons', 'support', 'idea', 'restrict', 'fields', 'interest', 'Depending', 'class', 'study', 'sector', 'aspects', 'prevalent', 'm', 'sure', 'present', 'probably', 'reason', 'nt', 'see', 'successful', 'people', 'try', 'new', 'things', 'nt', 'see', 'way', 'using', 'word', 'successful', 'conclusion', 'young', 'people', 'well', 'raised', 'good', 'friend', 'selected', 'spending', 'free', 'useful', 'productive', 'works', 'iam', 'sure', 'really', 'helpful', 'community', 'far', 'body', 'see', 'happenning', 'Nice', 'beautiful', 'advertisement', 'give', 'people', 'dream', 'true', 'cheating', 'appears', 'however', 'broader', 'knowledge', 'many', 'academic', 'subjects', 'called', 'generalist', 'getting', 'important', 'realized', 'days', 'bad', 'idea', 'reason', 'going', 'trip', 'think', 'want', 'get', 'away', 'day', 'life', 'situation', 'understand', 'little', 'community', 'catch', 'attention', 'young', 'people', 'sons', 'world', 'find', 'difficult', 'look', 'perspective', 'little', 'town', 'beginning', 'travel', 'group', 'led', 'tour', 'guid', 'know', 'make', 'plan', 'trip', 'also', 'speak', 'English', 'enough', 'travel', 'abroad', 'Firstly', 'transportation', 'systems', 'train', 'plane', 'developing', 'matter', 'time', 'also', 'matter', 'money', 'Travering', 'individually', 'flexible', 'economical', 'Last', 'least', 'trying', 'new', 'things', 'helps', 'get', 'expeirnce', 'self-cofidence', 'example', 'last', 'week', 'coming', 'back', 'home', 'met', 'Giovanni', 'Sartori', 'Italian', 'writer', 'list', 'reasons', 'think', 'say', 'young', 'people', 'enjoy', 'life', 'older', 'Poeple', 'give', 'enough', 'time', 'communities', 'busy', 'ignorant', 'benefits', 'going', 'reap', 'difference', 'going', 'make', 'Many', 'homes', 'lead', 'example', 'embed', 'sence', 'community', 'sharing', 'education', 'children', 'Thus', 'time', 'help', 'community', 'way', 'enjoy', 'aspects', 'vacation', 'miss', 'important', 'events', 'sightings', 'However', 'nt', 'thing', 'make', 'advertisement', 'make', 'products', 'seem', 'better', 'really', 'reasons', 'tour', 'guide', 'provide', 'traveller', 'detailed', 'additional', 'information', 'place', 'believe', 'best', 'way', 'traveling', 'group', 'people', 'self', 'manage', 'moment', 'behavior', 'companies', 'corporations', 'nearly', 'criminal', 'pursued', 'legally', 'point', 'mentioned', 'health', 'athlete', 'enjoy', 'sport', 'gathering', 'friends', 'soccer', 'game', 'unfornately', 'anymore', 'speacilizing', 'subject', 'find', 'easier', 'find', 'job', 'university', 'start', 'working', 'motivating', 'self', 'fullfilling', 'feel', 'know', 'major', 'well', 'makes', 'job', 'appreciate', 'Third', 'people', 'use', 'facts', 'writing', 'research', 'make', 'writing', 'research', 'strong', 'show', 'people', 'wrote', 'article', 'reasearch', 'knows', 'talking', 'writing', 'reasearch', 'rich', 'right', 'instead', 'hypothesis', 'made', 'life', 'lot', 'easier', 'used', 'learn', 'different', 'facts', 'everyday', 'gives', 'color', 'mind', 'Sometimes', 'specialists', 'produce', 'strange', 'things', 'specialists', 'divisions', 'point', 'problems', 'products', 'strongly', 'believe', 'students', 'understanding', 'ieas', 'concepts', 'important', 'learning', 'facts', 'promote', 'academic', 'performance', 'effectively', 'quickly', 'also', 'understanding', 'concepts', 'ideas', 'beneficilal', 'students', 'improve', 'imagination', 'creativity', 'calmy', 'man', 'ussually', 'job', 'loving', 'partners', 'genuine', 'curiosity', 'also', 'characterizes', 'brave', 'people', 'often', 'Europe', 'found', 'government', 'try', 'protect', 'people', 'lives', 'people', 'independent', 'thier', 'lives', 'think', 'mean', 'fully', 'enjoy', 'thier', 'life', 'need', 'walk', 'station', 'airports', 'illustration', 'makes', 'clear', 'young', 'people', 'concerns', 'pensions', 'receive', 'future', 'exemple', 'meet', 'really', 'cool', '60-years-old', 'man', 'everything', 'power', 'fun', 'make', 'life', 'worth', 'lived', 'boring', '20-years-old', 'boy', 'never', 'step', 'house', 'go', 'school', 'way', 'mentione', 'new', 'researches', 'genetic', 'field', 'surely', 'new', 'ideas', 'change', 'world', 'tomorrow', 'give', 'true', 'prospective', 'throught', 'read', 'future', 'facts', 'Taking', 'trips', 'learning', 'place', 'also', 'old', 'people', 'financial', 'security', 'stability', 'category', 'tend', 'enjoy', 'life', 'Life', 'becomes', 'enjoyable', 'long', 'people', 'appriciate', 'example', 'planet', 'becoming', 'warmer', 'warmer', 'sea', 'level', 'increased', 'rapidly', 'last', 'years', 'life', 'quite', 'boring', 'say', 'good', 'things', 'prodoct', 'think', 'positive', 'way', 'process', 'good', 'product', 'lot', 'visibility', 'wih', 'advirtisement', 'social', 'worker', 'think', 'empowering', 'work', 'life', 'broad', 'knowledge', 'addition', 'got', 'involved', 'troubles', 'fighting', 'robbery', 'getting', 'lost', 'mamage', 'situation', 'little', 'skills', 'langage', 'Trying', 'new', 'things', 'make', 'optimistic', 'give', 'lot', 'confidence', 'people', 'move', 'location', 'lost', 'many', 'desires', 'work', 'study', 'Europe', 'many', 'people', 'easy', 'going', 'life', 'thier', 'lives', 'protected', 'government', 'Nowadays', 'live', 'world', 'economically', 'driven', 'requires', 'good', 'planning', 'wise', 'decision', 'making', 'specific', 'reason', 'comes', 'readily', 'mind', 'able', 'go', 'anywhere', 'whomever', 'want', 'also', 'change', 'schedule', 'travel', 'flexiblly', 'go', 'travel', 'individually', 'person', 'general', 'broad', 'knowledge', 'free', 'happy', 'person', 'well', 'think', 'person', 'beautiful', 'broad', 'knowledge', 'many', 'academic', 'subjects', 'specialize', 'specific', 'subject', 'knowledge', 'speak', 'people', 'meet', 'However', 'guide', 'usually', 'knows', 'languge', 'uses', 'place', 'well', 'languge', 'group', 'travelers', 'problems', 'face', 'issue', 'spring', 'semester', 'llives', 'still', 'green', 'growing', 'fast', 'general', 'reasonable', 'richness', 'horizental', 'knowled', 'said', 'deep', 'knowledge', 'subject', 'based', 'focus', 'certain', 'subject', 'none', 'born', 'direction', 'goal', 'ready', 'accomplished', 'day', 'birth', 'Thier', 'behaviors', 'problem', 'want', 'succeed', 'need', 'try', 'new', 'things', 'positive', 'accidents', 'mean', 'opprotunity', 'meet', 'people', 'find', 'great', 'shop', 'street', 'accident', 'find', 'new', 'things', 'place', 'marketed', 'mainstream', 'tourism', 'hand', 'never', 'pluck', 'courage', 'measure', 'challenging', 'situations', 'possibilities', 'enlarge', 'skills', 'think', 'many', 'functions', 'cars', 'changed', 'well', 'hand', 'sometimes', 'useful', 'students', 'learn', 'basic', 'ideas', 'concepts', 'understood', 'lectures', 'studying', 'textbook', 'First', 'nowadays', 'young', 'people', 'lot', 'things', 'school', 'instance', 'make', 'schedule', 'want', 'hang', 'people', 'get', 'know', 'believed', 'Japan', 'need', 'adapt', 'policy', 'socil', 'democracy', 'many', 'European', 'countries', 'recently', 'employment', 'Japan', 'unstable', 'Japanese', 'MNCs', 'increased', 'thier', 'sales', 'government', 'decreased', 'cooporation', 'tax', 'alot', 'free', 'time', 'spend', 'selfpleasing', 'activity', 'brings', 'happiness', 'joy', 'young', 'lot', 'time', 'enjoy', 'lot', 'things', 'together', 'conclusion', 'statement', 'nt', 'simple', 'YES', 'answer', 'reasons', 'useing', 'car', 'nt', 'want', 'reapeat', 'things', 'someone', 'Unfortunately', 'mean', 'advertisements', 'nt', 'provide', 'enough', 'information', 'took', 'risk', 'achieve', 'professional', 'qualfication', 'US', 'Generally', 'speaking', 'products', 'services', 'bank', 'provides', 'require', 'high-level', 'specialized', 'knowledge', 'particulary', 'stage', 'products', 'services', 'developed', 'organised', 'opinion', 'plannning', 'travel', 'also', 'enjoyable', 'thing', 'travel', 'impossilbe', 'use', 'station', 'forever', 'even', 'healthy', 'example', 'Japan', 'chance', 'increase', 'many', 'cars', 'due', 'traffic', 'circumstances', 'mind', 'open', 'outside', 'topic', 'find', 'diffent', 'approach', 'problems', 'help', 'instance', 'learning', 'foreign', 'language', 'challenging', 'sure', 'pains', 'experience', 'turn', 'courage', 'learn', 'confident', 'successful', 'trying', 'new', 'things', 'takes', 'risks', 'amount', 'young', 'people', 'involved', 'volunteering', 'activies', 'big', 'number', 'young', 'people', 'involved', 'activities', 'big', 'Furthermore', 'car', 'always', 'expensive', 'taxation', 'insurance', 'costs', 'also', 'high', 'fact', 'cause', 'troubles', 'provide', 'untrue', 'information', 'However', 'cases', 'fact', 'senior', 'managers', 'need', 'cover', 'extremely', 'wide', 'range', 'business', 'area', 'fully', 'agree', 'people', 'nowadays', 'give', 'enough', 'time', 'helping', 'communities', 'think', 'time', 'money-oriented', 'think', 'going', 'able', 'make', 'drastic', 'changes', 'also', 'liked', 'eat', 'advertisement', 'fact', 'think', 'cars', 'future', 'today', 'Even', 'difficult', 'time', 'succeeded', 'learn', 'things', 'time', 'sure', 'success', 'even', 'valuable', 'friend', 'learned', 'never', 'order', 'anything', 'magazines', 'statments', 'acceptable', 'disagree', 'witth', 'particular', 'statment', 'accepted', 'stereotypes', 'means', 'well', 'accept', 'stereotypes', 'ask', 'questions', 'time', 'Old', 'poeple', 'calculate', 'steps', 'take', 'risks', 'false', 'step', 'bad', 'consequences', 'dependent', 'decision', 'trial', 'never', 'practiced', 'way', 'almost', 'exact', 'opposite', 'looking', 'travel', 'Young', 'people', 'engine', 'build', 'communities', 'Thi', 'means', 'persons', 'never', 'courage', 'try', 'something', 'hard', 'different', 'new', 'possibilities', 'succeed', 'falling', 'ground', 'Modern', 'advertisment', 'able', 'manipulate', 'customer', 'often', 'convince', 'himher', 'buy', 'products', 'really', 'wanted', 'listening', 'native', 'speaker', 'conversations', 'enough', 'master', 'English', 'chirdlen', 'grow', 'become', 'young', 'adult', 'vision', 'future', 'Scientific', 'aspect', 'product', 'true', 'real', 'data', 'think', 'number', 'cars', 'reduced', 'lot', 'reason', 'kind', 'Due', 'wide', 'experiences', 'life', 'older', 'people', 'able', 'plan', 'wisely', 'order', 'enjoy', 'lives', 'people', 'feel', 'important', 'students', 'learn', 'facts', 'rather', 'understad', 'ideas', 'concepts', 'Sometimes', 'product', 'advertisement', 'succeed', 'making', 'product', 'look', 'good', 'better', 'others', 'advertisements', 'made', 'look', 'much', 'better', 'reality', 'nt', 'believe', 'order', 'successful', 'people', 'take', 'risks', 'try', 'new', 'experiences', 'Old', 'people', 'money', 'time', 'people', 'young', 'generation', 'people', 'country', 'Japan', 'live', 'years', 'leads', 'person', 'knowledgable', 'aware', 'lots', 'things', 'also', 'gives', 'sense', 'fun', 'Actually', 'tend', 'change', 'schedule', 'many', 'times', 'trip', 'inherently', 'think', 'nature', 'nt', 'fit', 'trip', 'tour', 'group', 'words', 'deep', 'need', 'go', 'field', 'speciality', 'drink', 'water', 'bottles', 'even', 'm', 'sure', 'one', 'etter', 'Interior', 'design', 'virtual', 'design', 'graphic', 'design', 'much', 'think', 'answering', 'question', 'affected', 'expected', 'gains', 'answer', 'well', 'personality', 'individual', 'answer', 'reasons', 'pointed', 'sure', 'specialized', 'knowledge', 'leads', 'better', 'human', 'life', 'respected', 'broad', 'knowledge', 'disagree', 'idea', 'young', 'people', 'enjoy', 'life', 'older', 'people', 'nt', 'completely', 'agree', 'statement', 'opinion', 'understanding', 'ideas', 'concepts', 'learing', 'facts', 'important', 'cultural', 'growth', 'student', 'media', 'played', 'important', 'role', 'misleading', 'people', 'made', 'people', 'believe', 'true', 'however', 'always', 'exceptions', 'Otherwise', 'loose', 'costomers', 'Infact', 'student', 'get', 'trouble', 'understand', 'facts', 'full', 'concepts', 'ideas', 'didn', 'study', 'hear', 'fact', 'extremely', 'important', 'move', 'want', 'convenient', 'time', 'Thus', 'really', 'intimacy', 'romantic', 'trip', 'girlfriend', 'eventually', 'consider', 'options', 'll', 'older', 'example', 'city', 'live', 'keep', 'seeing', 'advertisement', 'TV', 'talks', 'wounderful', 'chain', 'resturants', 'think', 'lot', 'exemples', 'industrial', 'men', 'writers', 'teachers', 'opinionists', 'Considering', 'facts', 'mentioned', 'doubt', 'disagree', 'statement', 'successful', 'people', 'try', 'new', 'things', 'take', 'risks', 'rather', 'already', 'know', 'well', 'think', 'start', 'learning', 'something', 'new', 'useful', 'begin', 'facts', 'easy', 'remember', 'useful', 'fixing', 'important', 'data', 'Second', 'travel', 'group', 'led', 'tour', 'guide', 'golden', 'opportunity', 'know', 'different', 'people', 'different', 'places', 'led', 'make', 'friendship', 'tour', 'guide', 'time', 'kind', 'relationship', 'younger', 'people', 'run', 'money', 'usually', 'regret', 'things', 'see', 'vacation', 'lawyer', 'able', 'spend', 'past', 'years', 'assisting', 'poor', 'clients', 'involved', 'various', 'kinds', 'litigations', 'charging', 'result', 'good', 'corelationship', 'others', 'core', 'idea', 'helping', 'community', 'hard', 'task', 'think', 'Furthermore', 'indivudual', 'trip', 'trip', 'gide', 'offer', 'lots', 'opportunity', 'talk', 'locals', 'lecture', 'useful', 'boring', 'way', 'teach', 'person', 'country', 'city', 'engineering', 'faculty', 'indeed', 'student', 'probably', 'give', 'importance', 'concept', 'understanding', 'medicine', 'faculty', 'information', 'facts', 'important', 'agree', 'successful', 'people', 'try', 'new', 'things', 'take', 'risks', 'rather', 'already', 'know', 'well', 'Therefore', 'believe', 'people', 'often', 'needed', 'understaning', 'ideas', 'concepts', 'business', 'situation', 'met', 'life', 'lot', 'interesting', 'young', 'people', 'help', 'day', 'friends', 'people', 'need', 'Learning', 'ideas', 'concepts', 'enable', 'students', 'solve', 'problem', 'quickly', 'people', 'enjoy', 'moment', 'life', 'something', 'funny', 'stimulas', 'impression', 'fun', 'temporary', 'result', 'say', 'even', 'young', 'people', 'want', 'help', 'society', 'society', 'reject', 'watching', 'TV', 'show', 'person', 'interupting', 'advertisement', 'period', 'TV', 'Facts', 'still', 'important', 'forgotten', 'nt', 'depend', 'young', 'people', 'education', 'hand', 'young', 'people', 'enough', 'time', 'help', 'comunities', 'even', 'people', 'get', 'convenced', 'problem', 'sleeping', 'nt', 'medication', 'effective', 'safe', 'surronded', 'many', 'ads', 'many', 'really', 'see', 'read', 'examine', 'carefully', 'opinion', 'successful', 'people', 'challenging', 'spirits', 'doubt', 'complicated', 'perhaps', 'boring', 'study', 'students', 'pay', 'attention', 'check', 'wether', 'get', 'correctly', 'economy', 'grows', 'country', 'people', 'able', 'purchase', 'private', 'cars', 'important', 'thearies', 'ideals', 'strategies', 'well', 'dates', 'wars', 'started', 'ended', 'example', 'takes', 'time', 'organize', 'event', 'community', 'prepared', 'report', 'trip', 'accorded', 'explanation', 'document', 'prepared', 'explanation', 'tour', 'guide', 'sometime', 'confused', 'trouble', 'write', 'reports', 'method', 'students', 'increasing', 'culture', 'material', 'rapidly', 'strenght', 'ideas', 'Even', 'music', 'different', 'worlds', 'young', 'generation', 'enjoy', 'fast', 'laud', 'music', 'dance', 'drop', 'floor', 'method', 'say', 'consumer', 'hisher', 'life', 'complete', 'surely', 'better', 'many', 'car', 'companys', 'triing', 'make', 'new', 'type', 'car', 'Secondly', 'people', 'like', 'normal', 'ussual', 'things', 'call', 'calmy', 'man', 'life', 'meaningful', 'try', 'new', 'things', 'take', 'risks', 'totally', 'agree', 'idea', 'young', 'people', 'enjoy', 'life', 'older', 'people', 'Today', 'world', 'offers', 'chances', 'fun', 'people', 'ages', 'lot', 'parks', 'resorts', 'child', 'go', 'enjoy', 'days', 'parents', 'great', 'time', 'First', 'expensive', 'tour', 'guide', 'compared', 'taking', 'trip', 'group', 'Moreover', 'jobs', 'required', 'high', 'level', 'specialization', 'case', 'better', 'little', 'good', 'knowledge', 'many', 'poor', 'skills', 'second', 'reasons', 'make', 'agree', 'statement', 'richest', 'man', 'world', 'microsoft', 'owner', 'number', 'size', 'problems', 'lives', 'communities', 'horrifying', 'required', 'help', 'quantneeded', 'world', 'agree', 'statement', 'learning', 'facts', 'based', 'understanding', 'ideas', 'However', 'currently', 'happy', 'new', 'life', 'knowing', 'new', 'things', 'new', 'people', 'new', 'country', 'new', 'culture', 'matter', 'fact', 'nt', 'become', 'successful', 'work', 'hard', 'want', 'achieve', 'Viceversa', 'medical', 'doctor', 'make', 'good', 'diagnosis', 'understand', 'actually', 'causes', 'certain', 'deseas', 'heshe', 'learn', 'related', 'sympthoms', 'books', 'nothing', 'interesting', 'simple', 'student', 'responsabilty', 'studying', 'little', 'spending', 'free', 'time', 'getting', 'meet', 'new', 'friends', 'partying', 'often', 'Moreover', 'see', 'changes', 'culture', 'cause', 'people', 'buy', 'fewer', 'cars', 'childrens', 'understand', 'core', 'statement', 'nt', 'know', 'really', 'understand', 'thing', 'aunt', 'Mongolia', 'weeks', 'living', 'nomades', 'tent', 'drinking', 'acidic', 'milk', 'traveling', 'companions', 'back', 'assured', 'repeat', 'trip', 'guide', 'example', 'company', 'provide', 'samples', 'products', 'allow', 'consumers', 'experience', 'young', 'people', 'enjoy', 'life', 'older', 'people', 'example', 'went', 'place', 'learn', 'math', 'child', 'people', 'say', 'broad', 'knowledge', 'better', 'believe', 'tha', 'specialize', 'specific', 'subject', 'better', 'human', 'lives', 'bring', 'simple', 'example', 'mean', 'difficult', 'agree', 'disagree', 'statement', 'differences', 'learning', 'facts', 'understanding', 'concepts', 'sum', 'say', 'people', 'enjoy', 'life', 'regerdless', 'thier', 'age', 'point', 'makes', 'oppose', 'ignoring', 'broad', 'knowledge', 'sake', 'specializing', 'related', 'personality', 'individual', 'Secondly', 'let', 'introduce', 'experience', 'grand', 'mother', 'want', 'Travel', 'alone', 'also', 'cheeper', 'choose', 'combination', 'failures', 'successes', 'makes', 'feel', 'part', 'place', 'visiting', 'time', 'gives', 'incredibile', 'opportunity', 'get', 'touch', 'talk', 'many', 'people', 'initelligent', 'people', 'specialists', 'opinion', 'try', 'traveling', 'ina', 'group', 'led', 'tour', 'guide', 'travel', 'alon', 'family', 'experience', 'adventure', 'keep', 'wonderfull', 'memorise', 'mindes', 'like', 'day', 'visit', 'lovley', 'places', 'heard', 'people', 'First', 'specialization', 'brings', 'deep', 'knowledge', 'better', 'comprehension', 'opinion', 'better', 'broad', 'knowledge', 'many', 'academic', 'subjects', 'instead', 'specialization', 'offers', 'much', 'flexibility', 'traveling', 'group', 'tour', 'guide', 'always', 'known', 'history', 'places', 'tour', 'visit', 'tour', 'get', 'information', 'places', 'visit', 'learning', 'anew', 'stuff', 'place', 'Transportation', 'Crowded', 'huge', 'number', 'cars', 'truks', 'nowdays', 'truth', 'reveals', 'buy', 'First', 'advertising', 'companys', 'create', 'new', 'product', 'see', 'react', 'even', 'loose', 'money', 'producing', 'agree', 'better', 'student', 'understand', 'ideas', 'concepts', 'learn', 'facts', 'student', 'understand', 'idea', 'cocept', 'never', 'forget', 'learn', 'sake', 'exam', 'example', 'forget', 'faster', 'fact', 'think', 'lot', 'people', 'successful', 'nt', 'different', 'people', 'exemple', 'intelligence', 'possibility', 'normal', 'person', 'successfful', 'becouse', 'put', 'energy', 'work', 'generally', 'things', 'resons', 'say', 'helping', 'society', 'really', 'important', 'Even', 'little', 'action', 'help', 'someone', 'school', 'builds', 'sense', 'service', 'others', 'advertisements', 'makes', 'products', 'seem', 'much', 'better', 'realy', 'Considering', 'bad', 'experience', 'decided', 'organize', 'next', 'travel', 'ourself', 'asked', 'question', 'latest', 'work', 'called', 'La', 'mala', 'costituzione', 'fact', 'help', 'students', 'understand', 'theorical', 'concepts', 'contact', 'locals', 'crucial', 'discovery', 'process', 'travel', 'presence', 'tour', 'guide', 'undermine', 'lot', 'ability', 'interact', 'people', 'According', 'experience', 'past', 'strong', 'ly', 'agree', 'statement', 'understanding', 'ideas', 'concepts', 'important', 'learning', 'facts', 'students', 'perfectly', 'agree', 'statement', 'obviously', 'young', 'people', 'course', 'including', 'help', 'comunities', 'Traveling', 'group', 'takes', 'away', 'freedom', 'time', 'space', 'find', 'easier', 'safer', 'move', 'around', 'group', 'reality', 'wish', 'go', 'stay', 'certain', 'place', 'certain', 'time', 'choice', 'possible', 'group', 'different', 'agenda', 'demand', 'people', 'Especially', 'old', 'people', 'war-experience', 'know', 'appriciate', 'First', 'time', 'changeing', 'course', 'advantages', 'traveling', 'group', 'satisfied', 'knowledge', 'trying', 'new', 'things', 'example', 'new', 'ideas', 'world', 'Physic', 'followed', 'Atomic', 'Bomb', 'use', 'World', 'War', 'II', 'category', 'youth', 'enjoy', 'life', 'others', 'months', 'ago', 'convinced', 'advertisment', 'Assets', 'air', 'conditionars', 'good', 'quality', 'much', 'better', 'broad', 'knowledge', 'many', 'academics', 'subjects', 'specialize', 'specific', 'subject', 'willing', 'take', 'risk', 'wondering', 'around', 'asking', 'local', 'people', 'show', 'good', 'restaurant', 'experience', 'give', 'many', 'episodes', 'Brave', 'people', 'frighten', 'events', 'occur', 'approach', 'opinion', 'right', 'order', 'lead', 'situations', 'scared', 'travel', 'alone', 'however', 'many', 'things', 'learn', 'taking', 'trips', 'remember', 'young', 'person', 'best', 'time', 'life', 'meet', 'friends', 'true', 'still', 'contact', 'thing', 'young', 'see', 'often', 'use', 'time', 'want', 'meet', 'schedule', 'meetings', 'advance', 'even', 'meet', 'fun', 'use', 'However', 'become', 'far', 'humane', 'bny', 'Surely', 'food', 'good', 'pricy', 'part', 'needed', 'discussed', 'friends', 'offered', 'pay', 'prior', 'seing', 'bill', 'go', 'field', 'necessary', 'knowledge', 'skills', 'well', 'attitudes', 'compromise', 'field', 'able', 'use', 'analogy', 'resolve', 'problems', 'powerful', 'method', 'example', 'advertisement', 'food', 'chalenge', 'prove', 'product', 'unnatural', 'products', 'peoples', 'tests', 'product', 'say', 'true', 'product', 'contain', 'unnatural', 'products', 'parent', 'said', 'remember', 'parent', 'tell', 'care', 'community', 'help', 'parent', 'grew', 'parent', 'said', 'never', 'really', 'understood', 'Less', 'responsabilities', 'young', 'people', 'means', 'time', 'available', 'time', 'generally', 'use', 'enjoy', 'life', 'b', 'less', 'available', 'time', 'thoughts', 'consequence', 'responsabilities', 'parents', 'benefit', 'decesion', 'help', 'alot', 'reducing', 'traffic', 'problems', 'crowded', 'streets', 'school', 'gives', 'first', 'opportunity', 'learn', 'different', 'tipes', 'design', 'second', 'understand', 'best', 'believe', 'people', 'successful', 'try', 'lot', 'new', 'things', 'even', 'high', 'risks', 'following', 'reasons', 'changeing', 'time', 'improve', 'enjoying', 'First', 'think', 'many', 'things', 'changing', 'rapidly', 'everyday', 'example', 'people', 'demands', 'preferences', 'different', 'yesterday', 'learn', 'cultures', 'intresting', 'find', 'beleives', 'forbbiden', 'cultures', 'allowed', 'others', 'therefore', 'people', 'visit', 'countries', 'knoe', 'react', 'people', 'However', 'many', 'apartment', 'houses', 'many', 'people', 'live', 'cities', 'grow', 'needs', 'go', 'back', 'first', 'stage', 'choice', 'also', 'disagree', 'statement', 'personally', 'think', 'weak', 'statment', 'becaue', 'supported', 'kind', 'eveidence', 'survey', 'statistics', 'meaning', 'full', 'numbers', 'Increasing', 'number', 'cram', 'school', 'especially', 'one', 'young', 'people', 'crealy', 'shows', 'fact', 'many', 'young', 'pepople', 'spenting', 'time', 'study', 'Engeneer', 'studied', 'lot', 'theory', 'important', 'understand', 'concepts', 'learning', 'facts', 'personal', 'experience', 'provides', 'society', 'strong', 'tendency', 'observe', 'negative', 'examples', 'provided', 'young', 'people', 'really', 'hard', 'find', 'free', 'time', 'dedicate', 'others', 'usually', 'get', 'really', 'bored', 'studing', 'tired', 'endless', 'working', 'hours', 'grandfather', 'even', 'father', 'getting', 'ready', 'go', 'sort', 'selfpleasing', 'activity', 'strongly', 'believe', 'extremely', 'dangerous', 'young', 'spectators', 'particularly', 'sensitive', 'aspects', 'defined', 'personality', 'yet', 'easily', 'convinceable', 'believe', 'student', 'take', 'care', 'understanding', 'concepts', 'lerning', 'facts', 'Successful', 'people', 'worked', 'hard', 'accomplimish', 'achieve', 'goals', 'First', 'higher', 'authority', 'places', 'elderly', 'experienced', 'persons', 'community', 'Finally', 'think', 'students', 'want', 'want', 'First', 'cities', 'trying', 'improve', 'public', 'transports', 'always', 'projects', 'new', 'faster', 'metropolitan', 'lines', 'link', 'different', 'city', 'zones', 'real', 'short', 'time', 'Even', 'minutes', 'day', 'benefit', 'community', 'significantley', 'future', 'thought', 'really', 'passive', 'way', 'leaning', 'traveling', 'several', 'days', 'Germany', 'went', 'small', 'church', 'father', 'early', 'morning', 'waste', 'time', 'waiting', 'decision'], 'input_ids': [0, 937, 3552, 2340, 24, 21999, 284, 6878, 7905, 1300, 2382, 44960, 927, 935, 1737, 146, 3013, 1110, 3478, 6925, 512, 1806, 1532, 383, 3553, 906, 6160, 645, 1800, 652, 92, 13143, 6647, 1195, 216, 8079, 932, 7385, 224, 82, 393, 120, 778, 1282, 12769, 1538, 393, 236, 185, 2476, 3370, 383, 169, 2188, 2801, 679, 4703, 7280, 346, 1677, 304, 452, 107, 3790, 666, 22375, 10455, 13733, 2978, 1532, 2136, 301, 169, 2157, 1311, 78, 352, 5151, 3359, 885, 493, 4560, 82, 631, 1800, 5151, 236, 240, 1346, 1532, 12956, 14263, 1648, 664, 1294, 558, 1138, 1202, 9160, 5350, 30639, 620, 5332, 621, 2655, 10638, 2370, 2074, 1339, 2477, 2313, 1302, 657, 3120, 1099, 7721, 664, 82, 9574, 44941, 2333, 3291, 670, 7745, 664, 82, 937, 332, 2305, 2854, 664, 82, 25708, 492, 615, 86, 1903, 1822, 985, 460, 224, 22414, 2706, 12888, 206, 5894, 14267, 14612, 5894, 2731, 1980, 1246, 356, 1377, 2388, 8610, 15050, 173, 92, 1677, 1421, 92, 12418, 3055, 24240, 9779, 1715, 645, 2179, 518, 512, 1265, 244, 951, 1453, 8696, 460, 3665, 203, 335, 1606, 2655, 1504, 206, 3097, 1137, 754, 527, 323, 1049, 4286, 1114, 634, 754, 527, 2145, 505, 1346, 181, 1417, 1949, 5443, 13403, 1873, 918, 613, 10947, 82, 393, 1411, 751, 173, 171, 39307, 22393, 4193, 5332, 1435, 696, 171, 1651, 577, 244, 1391, 1822, 240, 12622, 1050, 1903, 865, 761, 633, 236, 892, 319, 6128, 269, 14384, 642, 2650, 146, 301, 164, 157, 2254, 301, 319, 631, 2530, 82, 25071, 1322, 352, 3014, 2345, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'pad_mask': [-100, 0, 0, 0, 0, -100, 0, 0, 0, 0, 0, 0, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, 0, 0, 0, -100, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, 0, 0, -100, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, 0, 0, -100]}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2888: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtapaninaho-joonas\u001b[0m (\u001b[33mtapaninaho-joonas-university-of-oulu\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/MetaphorFrame/wandb/run-20241108_092843-9zbfk93k\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtmp_trainer\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/tapaninaho-joonas-university-of-oulu/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/tapaninaho-joonas-university-of-oulu/huggingface/runs/9zbfk93k\u001b[0m\n",
            "100% 1/1 [00:01<00:00,  1.24s/it]\n",
            "&&& Assuming tagging predictions:\n",
            "Map: 100% 1/1 [00:00<00:00, 19.00 examples/s]\n",
            "{'tokens': ['general', 'scheme', 'normal', 'italian', 'family', 'dynamic', 'Moreover', 'source', 'clean', 'pollutant', 'air', 'environment', 'make', 'easier', 'terms', 'regulations', 'obtain', 'car', 'People', 'learn', 'things', 'thier', 'mistakes', 'order', 'successful', 'face', 'new', 'obstacles', 'overcome', 'rather', 'know', 'gaining', 'anything', 'safely', 'say', 'people', 'never', 'get', 'chance', 'success', 'manualized', 'never', 'want', 'take', 'risks', 'everybody', 'things', 'way', 'reasons', 'mentioned', 'believe', 'impossible', 'decrease', 'number', 'cars', 'use', 'today', 'years', 'visited', 'India', 'Egipt', 'Morocco', 'Instead', 'learn', 'word', 'life', 'way', 'feeling', 'giving', 'firstly', 'persons', 'stood', 'wiaited', 'people', 'thing', 'successful', 'persons', 'want', 'need', 'understand', 'learn', 'implicate', 'Even', 'young', 'student', 'office', 'workers', 'difficult', 'adjust', 'curcumstances', 'person', 'knowledge', 'math', 'English', 'laws', 'pick', 'Today', 'society', 'seems', 'love', 'notice', 'bad', 'examples', 'young', 'people', 'unfortunately', 'phenomen', 'usually', 'brings', 'strong', 'critic', 'young', 'people', 'general', 'points', 'stated', 'agree', 'young', 'people', 'nowadays', 'give', 'enough', 'time', 'helping', 'communities', 'mother', 'always', 'say', 'lazy', 'generation', 'Nevertheless', 'think', 'aspects', 'justified', 'marginal', 'aspects', 'core', 'ones', 'example', 'look', 'projects', 'greater', 'engineers', 'undertaken', 'work', 'new', 'cars', 'model', 'new', 'mechanical', 'tecnological', 'sources', 'order', 'develop', 'services', 'car', 'education', 'help', 'someone', 'basis', 'Travel', 'always', 'connected', 'much', 'information', 'add', 'knowledge', 'travel', 'think', 'professor', 'tell', 'fact', 'story', 'support', 'main', 'concept', 'idea', 'using', 'fact', 'story', 'remember', 'important', 'understand', 'povide', 'stability', 'famillies', 'financial', 'psychological', 'people', 'never', 'goes', 'outside', 'work', 'many', 'cisrcustances', 'funding', 'issue', 'many', 'organization', 'available', 'help', 'fund', 'communities', 'need', 'lacking', 'human', 'helping', 'hand', 'kind', 'job', 'want', 'study', 'lot', 'everywhere', 'really', 'healpful', 'make', 'life', 'going', 'well', 'enjoy', 'life', 'lot', 'thing', 'older', 'people', 'necessarely', 'maintain', 'sort', 'proportion', 'efforts', 'forces', 'dispose', 'case', 'like', 'make', 'product', 'worse', 'addition', 'christmas', 'vacation', 'visited', 'NY', 'study', 'excited', 'enjoy', 'studying', 'beleive', 'time', 'ultimate', 'value', 'life', 'plan', 'advance', 'exactly', 'going', 'receive', 'something', 'nt', 'know', 'yet', 'better', 'position', 'anyone', 'nt', 'studied', 'studied', 'thing', 'Successful', 'ambitions', 'stop', 'particular', 'point', 'always', 'ambitions', 'always', 'want', 'achieve', 'matter', 'much', 'risk', 'cause', 'professors', 'explain', 'concepts', 'difficult', 'understand', 'important', 'remember', 'exam', 'high', 'shool', 'student', 'interested', 'buying', 'inter', 'net', 'entered', 'soccer', 'team', 'like', 'soccer', 'shoose', 'spare', 'time', 'avilability', 'money', 'abscence', 'limitaions', 'dought', 'older', 'people', 'enjoy', 'life', 'much', 'youn', 'ones', 'believe', 'utopistic', 'theory', 'communism', 'show', 'situation', 'facts', 'extremely', 'releated', 'knowledge', 'concept', 'history', 'classroom', 'teacher', 'elementery', 'school', 'told', 'student', 'second', 'world', 'war', 'horrorfy', 'event', 'thing', 'people', 'really', 'careful', 'information', 'provided', 'many', 'ads', 'days', 'Moreover', 'answer', 'question', 'different', 'brain', 'structure', 'everyone', 'course', 'make', 'plan', 'trip', 'especially', 'according', 'time', 'budget', 'available', 'always', 'important', 'opportunity', 'change', 'find', 'something', 'nt', 'enjoy', 'think', 'position', 'easily', 'supported', 'numerous', 'current', 'TV', 'programs', 'backpaking', 'traveling', 'alone', 'seeking', 'so-called', 'adventure', 'traveling', 'Agreeing', 'desagreeing', 'depends', 'personality', 'person', 'personality', 'environement', 'responsibilities', 'get', 'good', 'score', 'tests', 'glad', 'study', 'hard', 'm', 'sure', 'people', 'enjoy', 'better', 'life', 'getting', 'old', 'thant', 'yonger', 'generation', 'product', 'opnion', 'statement', 'needs', 'ways', 'people', 'tranport', 'feel', 'comfortable', 'convenient', 'cars', 'Nowadays', 'life', 'tough', 'expensive', 'young', 'people', 'lot', 'responsibilies', 'life', 'bring', 'situation', 'school', 'say', 'leader', 'successful', 'person', 'brave', 'turned', 'reaults', 'experiences', 'method', 'time', 'brings', 'result', 'example', 'happened', 'went', 'germany', 'family', 'tour', 'company', 'want', 'advertise', 'product', 'making', 'effort', 'make', 'look', 'better', 'People', 'feel', 'comforatable', 'travel', 'group', 'people', 'probably', 'first', 'time', 'see', 'places', 'gradually', 'helping', 'communities', 'make', 'better', 'oving', 'university', 'start', 'choosing', 'major', 'number', 'people', 'increasing', 'world', 'wide', 'lots', 'countries', 'population', 'control', 'problem', 'leader', 'Many', 'surround', 'product', 'brand', 'fantastic', 'characteristics', 'implying', 'people', 'wear', 'buy', 'cool', 'special', 'people', 'different', 'trucks', 'life', 'Ideas', 'concepts', 'base', 'theory', 'sociological', 'movement', 'remember', 'facts', 'date', 'names', 'expose', 'discussion', 'explain', 'make', 'people', 'ideas', 'changing', 'fully', 'aware', 'problems', 'occur', 'live', 'denial', 'life', 'visit', 'famouse', 'Japanes', 'places', 'local', 'people', 'able', 'schedule', 'journey', 'depending', 'group', 'plans', 'stay', 'bed', 'late', 'wake', 'early', 'morning', 'enjoy', 'sunrise', 'summarize', 'students', 'opinion', 'important', 'understand', 'reason', 'concepts', 'ideas', 'rather', 'memorize', 'mechanically', 'facts', 'dates', 'numbers', 'shopping', 'golfing', 'maybe', 'cruise', 'yacht', 'suggest', 'prefer', 'ecological', 'means', 'transport', 'order', 'respect', 'planet', 'defend', 'pollution', 'hard', 'think', 'human', 'race', 'diminish', 'entire', 'part', 'culture', 'lives', 'short', 'period', 'years', 'work', 'biggest', 'banking', 'groups', 'Japan', 'includes', 'permanent', 'employees', 'part-time', 'employees', 'seems', 'ways', 'equally', 'valued', 'fact', 'value', 'example', 'young', 'woman', 'pursuing', 'career', 'acting', 'attending', 'theater', 'classes', 'struck', 'sudden', 'revelation', 'decides', 'true', 'vocation', 'marine', 'biology', 'simply', 'quits', 'theater', 'studies', 'enrolls', 'science', 'school', 'suffering', 'sleeping', 'problems', 'liked', 'advertisement', 'music', 'color', 'sleeping', 'pill', 'nice', 'shiny', 'pink', 'color', 'way', 'say', 'forced', 'becuase', 'say', 'right', 'refuse', 'know', 'somehow', 'part', 'services', 'least', 'think', 'broad', 'knowledge', 'general', 'field', 'also', 'specialized', 'particular', 'subject', 'field', 'opposite', 'also', 'true', 'new', 'ideas', 'change', 'behavior', 'people', 'resulting', 'new', 'events', 'human', 'history', 'citizen', 'case', 'kind', 'products', 'cause', 'accident', 'user', 'using', 'cars', 'make', 'people', 'less', 'oppotunities', 'exercise', 'mean', 'young', 'people', 'study', 'takes', 'enough', 'lot', 'time', 'opinion', 'stongly', 'agree', 'successful', 'create', 'new', 'things', 'take', 'risks', 'several', 'reasons', 'base', 'everything', 'someone', 'learns', 'concidered', 'learning', 'young', 'people', 'come', 'wealthy', 'families', 'depending', 'family', 'education', 'maybe', 'conditions', 'allow', 'helpful', 'communities', 'improve', 'community', 'living', 'help', 'needy', 'people', 'young', 'person', 'participate', 'personnal', 'skillls', 'possibility', 'best', 'community', 'members', 'want', 'waste', 'time', 'helping', 'communities', 'still', 'remember', 'went', 'Thailand', 'family', 'tour', 'guide', 'basically', 'always', 'showing', 'cultural', 'events', 'shows', 'far', 'authentic', 'expressions', 'local', 'habits', 'time', 'like', 'travell', 'alot', 'tendency', 'explains', 'better', 'focus', 'specific', 'subject', 'broad', 'knowledge', 'wider', 'subjects', 'lives', 'alone', 'husband', 'died', 'energetic', 'vigorous', 'seems', 'enjoy', 'life', 'much', 'always', 'suggests', 'new', 'things', 'trys', 'new', 'things', 'company', 'never', 'working', 'older', 'people', 'working', 'much', 'longer', 'father', 'mentioned', 'official', 'estimate', 'uncontrollable', 'population', 'growth', 'world', 'getting', 'young', 'people', 'educated', 'something', 'impotant', 'person', 'community', 'Younger', 'people', 'work', 'harder', 'olders', 'often', 'retirement', 'younger', 'less', 'time', 'spend', 'enjoyment', 'depending', 'retirement', 'system', 'also', 'less', 'money', 'media', 'industry', 'playing', 'people', 'trust', 'order', 'sell', 'products', 'diffrent', 'companies', 'pay', 'alot', 'make', 'attractive', 'advertisements', 'conclusion', 'better', 'spend', 'efforts', 'topic', 'study', 'much', 'subjects', 'always', 'enjoyed', 'traveling', 'knowledge', 'anything', 'else', 'strongly', 'hope', 'First', 'people', 'feel', 'comfortable', 'group', 'alone', 'course', 'places', 'world', 'example', 'Tokyo', 'subways', 'well', 'developed', 'people', 'nt', 'need', 'cars', 'get', 'around', 'future', 'car', 'moves', 'electricities', 'gasoline', 'speacilize', 'major', 'find', 'different', 'smaller', 'topic', 'buisness', 'shows', 'speacilized', 'OK', 'people', 'others', 'think', 'satisfied', 'reason', 'chinese', 'man', 'doughter', 'kills', 'chinese', 'government', 'nt', 'want', 'families', 'persons', 'women', 'decreased', 'opinion', 'people', 'curiocity', 'old-men', 'Even', 'conditions', 'getting', 'better', 'far', 'away', 'discussing', 'point', 'prevent', 'green-house', 'effect', 'really', 'sad', 'fact', 'leard', 'deal', 'company', 'advertisement', 'brand', 'well', 'known', 'country', 'Oman', 'complete', 'opinion', 'agree', 'spend', 'part', 'study', 'stage', 'important', 'study', 'work', 'Think', 'fast', 'food', 'industry', 'Italy', '80s', 'buy', 'want', 'go', 'want', 'eat', 'want', 'opinion', 'number', 'cars', 'going', 'increase', 'repidly', 'many', 'cars', 'cityes', 'm', 'thinking', 'time', 'blocked', 'traffic', 'm', 'thinking', 'stress', 'produce', 'situation', 'jungle', 'clacson', 'sound', 'peolpe', 'insult', 'others', 'reason', 'important', 'appointed', 'posticipated', 'Many', 'people', 'pearsonal', 'computer', 'use', 'inter', 'net', 'traveling', 'tour', 'guide', 'always', 'things', 'lose', 'opportunities', 'vaction', 'plan', 'wanted', 'go', 'wanted', 'see', 'much', 'cost', 'addition', 'older', 'people', 'money', 'enjoy', 'life', 'younger', 'people', 'seeing', 'grand', 'mother', 'well', 'convinced', 'older', 'people', 'live', 'life', 'many', 'enjoyments', 'First', 'people', 'like', 'new', 'things', 'involve', 'risky', 'things', 'call', 'risky', 'man', 'difficult', 'change', 'something', 'interessed', 'much', 'powerfull', 'person', 'world', 'world', 'huge', 'stage', 'nearly', 'everybody', 'actor', 'Specialized', 'knowledge', 'also', 'brings', 'higher', 'incomes', 'true', 'nice', 'looking', 'advertisement', 'make', 'people', 'feel', 'good', 'Nowadays', 'graduated', 'good', 'wide', 'knoledge', 'graduated', 'good', 'specialization', 'field', 'studies', 'needless', 'say', 'infrastructures', 'facilities', 'still', 'prepared', 'developing', 'countries', 'Folowing', 'take', 'specific', 'reasons', 'dislike', 'trabeling', 'tour', 'guide', 'doctor', 'instance', 'Chinese', 'law', 'states', 'family', 'child', 'think', 'fascinating', 'interesting', 'thing', 'visiting', 'new', 'country', 'call', 'taste', 'vacation', 'come', 'desire', 'discover', 'beauties', 'Even', 'sometimes', 'particular', 'traveling', 'short', 'amount', 'time', 'organized', 'group', 'guide', 'effective', 'generally', 'prefer', 'travel', 'kind', 'giving', 'kind', 'culture', 'addition', 'customer', 'like', 'real', 'product', 'wasted', 'money', 'advertisement', 'different', 'Second', 'ruch', 'hour', 'commuting', 'time', 'day', 'think', 'right', 'beleve', 'parents', 'willing', 'anything', 'kids', 'nt', 'chaildhood', 'addition', 'seames', 'everything', 'availible', 'young', 'people', 'days', 'old', 'days', 'Cars', 'first', 'modern', 'kind', 'way', 'use', 'long', 'time', 'consider', 'people', 'travel', 'important', 'issue', 'plan', 'journey', 'take', 'part', 'non-profit', 'group', 'keeping', 'environment', 'good', 'condition', 'gorvenment', 'need', 'spend', 'extra', 'money', 'order', 'improve', 'environment', 'example', 'tool', 'box', 'set', 'looks', 'great', 'shiny', 'made', 'cheap', 'materials', 'deform', 'easily', 'medium', 'mechanical', 'stress', 'Thirdly', 'many', 'people', 'know', 'also', 'leave', 'home', 'eary', 'morning', 'come', 'back', 'home', 'late', 'night', 'hand', 'subjects', 'learning', 'facts', 'essential', 'generally', 'speaking', 'due', 'life', 'experiences', 'older', 'people', 'plan', 'well', 'established', 'fields', 'financially', 'sound', 'younger', 'people', 'give', 'life', 'example', 'statments', 'give', 'example', 'personal', 'field', 'pharmacy', 'example', 'years', 'ago', 'trade', 'company', 'called', 'Suzuki', 'Shoten', 'Japan', 'nomal', 'rubber', 'shoes', 'dies', 'stay', 'long', 'said', 'time', 'however', 'probably', 'choose', 'something', 'general', 'People', 'spend', 'lot', 'money', 'misleading', 'advertisements', 'Next', 'summer', 'going', 'Japan', 'wife', 'spent', 'whole', 'year', 'learning', 'Japanes', 'international', 'exchange', 'program', 'great', 'ambition', 'strongly', 'desired', 'help', 'people', 'loss', 'mobility', 'However', 'middle', 'later', 'stage', 'focus', 'refocus', 'subjects', 'love', 'subjects', 'give', 'satisfactions', 'Limiting', 'use', 'kind', 'private', 'transportation', 'help', 'alot', 'mentaining', 'good', 'balance', 'usage', 'energy', 'sourses', 'fact', 'true', 'maybe', 'older', 'people', 'different', 'way', 'approaching', 'life', 'allows', 'get', 'best', 'situation', 'enjoy', 'simple', 'things', 'addition', 'old', 'people', 'job', 'career', 'care', 'Usually', 'young', 'people', 'go', 'school', 'opportunity', 'meet', 'people', 'age', 'sum', 'agree', 'idea', 'planes', 'ships', 'less', 'expensive', 'example', 'students', 'want', 'help', 'wipe', 'snow', 'deep-snow', 'city', 'checked', 'name', 'school', 'going', 'help', 'difficulties', 'incounter', 'vacation', 'experiences', 'described', 'seen', 'advertisements', 'make', 'products', 'seem', 'much', 'better', 'really', 'essay', 'm', 'going', 'write', 'opinion', 'best', 'way', 'travel', 'group', 'leader', 'tour', 'guide', 'think', 'best', 'way', 'travel', 'travel', 'alone', 'city', 'know', 'well', 'first', 'time', 'nt', 'places', 'city', 'tour', 'guide', 'true', 'keep', 'mind', 'open', 'good', 'thing', 'giving', 'wide', 'range', 'knowledge', 'question', 'knowledge', 'useful', 'future', 'process', 'tough', 'lifelong', 'many', 'people', 'know', 'cars', 'convinient', 'usefull', 'machine', 'Overtime', 'toshiba', 'laptops', 'become', 'expensive', 'read', 'written', 'topic', 'able', 'start', 'studying', 'different', 'subject', 'contrary', 'nt', 'Becasue', 'bad', 'economy', 'political', 'mess', 'untrustable', 'politicians', 'strange', 'teachers', 'etc', 'several', 'years', 'think', 'cars', 'nt', 'use', 'gasoline', 'using', 'car', 'harm', 'earth', 'CO2', 'car', 'produce', 'young', 'used', 'think', 'Aliens', 'existed', 'well', 'actually', 'think', 'exist', 'thought', 'first', 'thing', 'll', 'see', 'arriving', 'earth', 'roads', 'cars', 'moving', 'time', 'day', 'night', 'instance', 'man', 'like', 'claim', 'mountains', 'sailing', 'round', 'world', 'risky', 'swiming', 'country', 'others', 'depends', 'family', 'friends', 'social', 'background', 'ladder', 'success', 'changes', 'people', 'many', 'ways', 'take', 'first', 'step', 'people', 'willing', 'take', 'risks', 'try', 'new', 'things', 'journey', 'progresses', 'develope', 'new', 'mentality', 'built', 'past', 'innovative', 'dynamic', 'fruitfull', 'experiences', 'thus', 'paving', 'way', 'conservative', 'limited', 'mentality', 'reasons', 'thought', 'thinking', 'issue', 'Particuarly', 'firmly', 'convinced', 'good', 'education', 'provide', 'enough', 'information', 'learned', 'enough', 'concepts', 'understood', 'way', 'see', 'order', 'leesen', 'number', 'cars', 'use', 'come', 'ways', 'make', 'less', 'dependent', 'use', 'meaning', 'come', 'many', 'new', 'trasportation', 'way', 'systems', 'suffitient', 'time', 'efficent', 'enough', 'surve', 'public', 'people', 'climb', 'ladder', 'success', 'ideas', 'tend', 'change', 'dynamic', 'innovative', 'static', 'conservative', 'nt', 'use', 'car', 'transport', 'alternative', 'transportation', 'Everyone', 'life', 'successful', 'person', 'easy', 'successful', 'dissapointed', 'spray', 'work', 'summary', 'experience', 'different', 'culture', 'morning', 'evening', 'people', 'commuting', 'cars', 'including', 'privaite', 'vehicles', 'buses', 'spend', 'lot', 'time', 'really', 'wast', 'time', 'individuals', 'country', 'development', 'cutting', 'edge', 'technologies', 'arts', 'bring', 'development', 'human', 'lives', 'Passing', 'law', 'requires', 'lot', 'time', 'However', 'experience', 'United', 'States', 'say', 'people', 'nt', 'think', 'people', 'try', 'new', 'things', 'take', 'risks', 'success', 'really', 'like', 'understand', 'becouse', 'read', 'statements', 'child', 'lots', 'young', 'people', 'big', 'responsibilites', 'depend', 'others', 'help', 'work', 'support', 'themself', 'sometimes', 'support', 'famillies', 'enjoying', 'life', 'high', 'school', 'always', 'chosen', 'different', 'electives', 'music', 'french', 'also', 'computer', 'lessons', 'also', 'able', 'learn', 'many', 'things', 'traveling', 'alone', 'However', 'problems', 'remains', 'little', 'cities', 'car', 'necessary', 'winter', 'rainy', 'day', 'founding', 'company', 'owner', 'small', 'cycleshop', 'focus', 'problems', 'related', 'specialization', 'example', 'know', 'sometimes', 'water', 'comes', 'home', 'sink', 'use', 'drink', 'day', 'said', 'pure', 'big', 'advertisements', 'city', 'Finally', 'people', 'like', 'organize', 'follow', 'schuale', 'responsible', 'However', 'said', 'Chinese', 'Indian', 'population', 'increase', 'drastically', 'However', 'young', 'people', 'nt', 'lot', 'time', 'case', 'better', 'travel', 'group', 'tour', 'guide', 'totally', 'agree', 'statement', 'rather', 'simplistic', 'saw', 'life', 'everything', 'pass', 'practice', 'really', 'understand', 'value', 'importance', 'lots', 'theories', 'studied', 'past', 'world', 'changed', 'drastically', 'invention', 'cars', 'group', 'tour', 'guide', 'less', 'likely', 'kidnapped', 'rubbed', 'particular', 'trhere', 'elementse', 'important', 'used', 'advetisement', 'price', 'quality', 'goods', 'Students', 'likely', 'understand', 'phenomena', 'short', 'experiment', 'rather', 'long', 'perhaps', 'boring', 'lecture', 'mean', 'student', 'entered', 'subject', 'know', 'subject', 'requires', 'important', 'aspects', 'able', 'organise', 'studies', 'best', 'way', 'parents', 'recommended', 'go', 'place', 'study', 'math', 'like', 'focus', 'reasons', 'detail', 'need', 'read', 'keep', 'educating', 'kinds', 'products', 'try', 'much', 'posible', 'select', 'suitable', 'use', 'health', 'Second', 'feel', 'crucial', 'students', 'comprehend', 'ideas', 'concepts', 'learn', 'facts', 'understanding', 'ideas', 'concepts', 'help', 'students', 'improve', 'imagination', 'creativity', 'arguement', 'proposed', 'women', 'days', 'choosing', 'marry', 'job', 'opportunities', 'live', 'independantly', 'healthy', 'everything', 'want', 'opinion', 'better', 'first', 'year', 'study', 'broad', 'knowledge', 'generic', 'materials', 'specialized', 'specific', 'subject', 'method', 'advertisement', 'consumers', 'acutually', 'use', 'products', 'make', 'decision', 'buy', 'everybody', 'rides', 'car', 'goes', 'surely', 'going', 'shape', 'get', 'diseases', 'heart', 'attack', 'diabetes', 'things', 'think', 'm', 'helping', 'communitie', 'life', 'student', 'full', 'surprising', 'experiments', 'someone', 'get', 'discover', 'day', 'day', 'know', 'want', 'Typically', 'purse', 'expensive', 'watch', 'basic', 'functions', 'regarding', 'original', 'purpose', 'objects', 'mostly', 'considered', 'look', 'sensation', 'give', 'due', 'esthetic', 'values', 'determine', 'quality', 'image', 'fact', 'even', 'functional', 'still', 'used', 'Ever', 'commercials', 'promise', 'customers', 'greater', 'benefit', 'products', 'misleading', 'real', 'wants', 'needs', 'living', 'United', 'States', 'short', 'period', 'time', 'week', 'nt', 'car', 'Even', 'pediatritions', 'speacilized', 'doctor', 'concerned', 'part', 'human', 'body', 'think', 'people', 'obstacle', 'others', 'stop', 'harming', 'people', 'destroying', 'public', 'property', 'first', 'Broad', 'knowledge', 'gives', 'people', 'lot', 'ideas', 'topic', 'enables', 'communicate', 'show', 'course', 'analisys', 'foresee', 'eventual', 'tecnological', 'revolution', 'render', 'car', 'useless', 'car', 'horses', 'twentieth', 'century', 'major', 'economic', 'breakdown', 'render', 'cars', 'expensive', 'useful', 'trend', 'breaking', 'events', 'unpredictable', 'agree', 'best', 'way', 'travel', 'agroup', 'led', 'tour', 'guide', 'important', 'factor', 'concerns', 'goals', 'goal', 'find', 'good', 'well', 'retributed', 'job', 'specialize', 'subject', 'needed', 'asked', 'job', 'world', 'example', 'also', 'represents', 'better', 'gain', 'specialized', 'knowledge', 'broader', 'knowledge', 'many', 'academic', 'topics', 'make', 'look', 'better', 'make', 'look', 'different', 'say', 'something', 'different', 'guess', 'lerning', 'personal', 'experiance', 'way', 'valiable', 'nice', 'things', 'see', 'hear', 'products', 'advertisements', 'recently', 'joined', 'club', 'school', 'called', 'Sok', 'Sabay', 'supports', 'cambodian', 'orphanages', 'provide', 'home', 'food', 'supply', 'technologies', 'responds', 'particular', 'need', 'possibility', 'moving', 'faster', 'town', 'short', 'period', 'time', 'famous', 'example', 'program', 'called', 'global', 'trekkers', 'Young', 'people', 'unsually', 'keep', 'touch', 'friends', 'hometown', 'school', 'think', 'future', 'go', 'direction', 'safe', 'life', 'future', 'generations', 'instance', 'bought', 'washing', 'liquid', 'seeing', 'tv', 'products', 'gives', 'garanttee', 'take', 'away', 'marks', 'matter', 'deep', 'using', 'product', 'satisfied', 'Nowadays', 'common', 'young', 'people', 'always', 'away', 'responsibility', 'self', 'management', 'self', 'motivation', 'beeing', 'caretaker', 'young', 'person', 'dedicate', 'time', 'gave', 'helping', 'community', 'summer', 'whole', 'year', 'dentist', 'knew', 'nt', 'make', 'sense', 'successful', 'weeks', 'Toshiba', 'company', 'withdraw', 'laptop', 'batteries', 'market', 'specific', 'toshiba', 'laptop', 'word', 'nobody', 'stand', 'crowd', 'new', 'challengings', 'make', 'person', 'distinguished', 'others', 'Advertisements', 'branding', 'important', 'key', 'today', 'world', 'business', 'fact', 'become', 'essential', 'selling', 'product', 'item', 'understand', 'real', 'meaning', 'facts', 'agree', 'statement', 'successful', 'people', 'try', 'new', 'things', 'take', 'risks', 'rather', 'already', 'know', 'well', 'believe', 'people', 'strong', 'wish', 'successful', 'likely', 'successful', 'COMPLETE', 'ISOLATION', 'society', 'lead', 'public', 'danger', 'suicide', 'also', 'remember', 'parents', 'teaching', 'interact', 'community', 'spend', 'time', 'learned', 'something', 'specific', 'subject', 'say', 'subject', 'advertiser', 'showed', 'anyone', 'remove', 'hair', 'spraying', 'hair', 'simply', 'wiping', 'towel', 'CPA', 'broke', 'change', 'business', 'work', 'completely', 'changed', 'nowadays', 'even', 'become', 'sum', 'involved', 'subject', 'much', 'better', 'involved', 'many', 'reasons', 'economic', 'reasons', 'personal', 'reasons', 'going', 'grandpa', 'improve', 'knowledge', 'add', 'ideas', 'concept', 'array', 'clear', 'facts', 'hand', 'goal', 'general', 'knowledge', 'different', 'aspects', 'help', 'understand', 'single', 'sector', 'life', 'istance', 'political', 'science', 'spend', 'years', 'different', 'academic', 'subjects', 'studying', 'bit', 'everything', 'quiting', 'successful', 'job', 'Japan', 'leaving', 'life', 'Japan', 'family', 'friends', 'pleasure', 'learning', 'abig', 'part', 'civilization', 'always', 'believe', 'something', 'God', 'politic', 'values', 'needed', 'lots', 'patience', 'create', 'computers', 'telephones', 'make', 'really', 'convenient', 'also', 'people', 'drives', 'airoplanes', 'maybe', 'ships', 'think', 'true', 'young', 'people', 'students', 'much', 'time', 'going', 'friends', 'word', 'going', 'face', 'limitation', 'sourses', 'energy', 'new', 'decesions', 'control', 'consuming', 'gas', 'trasportation', 'always', 'think', 'better', 'way', 'help', 'communities', 'find', 'position', 'worker', 'system', 'opinion', 'broad', 'knowledge', 'change', 'person', 'going', 'think', 'important', 'broad', 'knowledge', 'many', 'academics', 'subjects', 'reasons', 'opinion', 'global', 'knowledge', 'lot', 'possibility', 'choise', 'work', 'difficult', 'able', 'know', 'better', 'problem', 'possibility', 'resolving', 'problem', 'type', 'problem', 'ready', 'resolve', 'Cars', 'change', 'way', 'move', 'people', 'society', 'progres', 'constantly', 'increase', 'importance', 'objects', 'real', 'lots', 'reasons', 'Moreover', 'people', 'world', 'got', 'idea', 'stick', 'mind', 'toshiba', 'laptops', 'best', 'hand', 'idea', 'never', 'find', 'way', 'communicate', 'second', 'reason', 'strongly', 'think', 'innovative', 'things', 'fundamental', 'basis', 'success', 'things', 'represent', 'norm', 'usual', 'market', 'market', 'unlikely', 'increase', 'reached', 'established', 'balanced', 'steady', 'state', 'born', 'parents', 'often', 'take', 'brother', 'vacation', 'Even', 'though', 'cooked', 'exactly', 'direction', 'says', 'looked', 'defferent', 'nice', 'Habitat', 'Humanity', 'Phillipine', 'Relief', 'Organization', 'UNICEF', 'Image', 'man', 'specialized', 'complexe', 'physics', 'complexe', 'physics', 'draw', 'life', 'kind', 'people', 'example', 'hobby', 'used', 'skiing', 'feel', 'start', 'losing', 'enogh', 'physical', 'toughness', 'recently', 'keep', 'high', 'speed', 'big', 'snow', 'slope', 'keep', 'moving', 'mountain', 'montain', 'Usually', 'teachers', 'tend', 'show', 'answer', 'students', 'students', 'know', 'answer', 'think', 'better', 'student', 'understand', 'easy', 'teach', 'teachers', 'Lets', 'say', 'example', 'person', 'takes', 'biology', 'history', 'phsycology', 'However', 'factors', 'promoting', 'use', 'cars', 'thus', 'result', 'number', 'cars', 'future', 'advertisements', 'make', 'products', 'seem', 'much', 'better', 'really', 'students', 'understand', 'ideas', 'become', 'productive', 'accomplished', 'grasping', 'analizing', 'ideas', 'leads', 'creativety', 'leads', 'creation', 'Universities', 'considerably', 'different', 'educational', 'systems', 'taking', 'trip', 'great', 'opportunity', 'talk', 'local', 'residents', 'able', 'tell', 'good', 'restaurants', 'nice', 'places', 'local', 'people', 'know', 'favorite', 'subject', 'always', 'Math', 'subjects', 'History', 'Literature', 'based', 'logic', 'also', 'think', 'high', 'level', 'specialization', 'reached', 'years', 'years', 'study', 'work', 'school', 'nt', 'give', 'opportunity', 'everybody', 'result', 'tend', 'less', 'responsible', 'person', 'enjoy', 'life', 'first', 'thing', 'realize', 'precious', 'lives', 'question', 'remains', 'effect', 'environment', 'Concluding', 'think', 'situations', 'nt', 'important', 'work', 'hard', 'important', 'know', 'someone', 'help', 'permit', 'job', 'success', 'According', 'school', 'provide', 'give', 'basical', 'instruction', 'teaching', 'many', 'different', 'subjects', 'agree', 'statement', 'believe', 'adverstisements', 'make', 'products', 'seem', 'much', 'better', 'really', 'even', 'important', 'number', 'strongly', 'increase', 'young', 'people', 'free', 'time', 'reasons', 'certain', 'need', 'make', 'young', 'people', 'help', 'comunities', 'Knowing', 'wide', 'range', 'things', 'helps', 'socialize', 'people', 'addition', 'newspapers', 'specified', 'number', 'pages', 'products', 'advertisements', 'boths', 'way', 'give', 'primises', 'successful', 'life', 'choose', 'success', 'based', 'time', 'saved', 'method', 'easy', 'say', 'better', 'approach', 'personally', 'agree', 'statement', 'think', 'broad', 'knowledge', 'many', 'academic', 'subjects', 'good', 'specializing', 'specific', 'subject', 'Even', 'frindship', 'continue', 'trip', 'Furthermore', 'people', 'disagree', 'idea', 'learning', 'facts', 'prefer', 'understanding', 'concepts', 'think', 'student', 'able', 'understand', 'ideas', 'ideas', 'unreal', 'many', 'students', 'hate', 'learn', 'fake', 'things', 'science', 'fiction', 'terror', 'stories', 'Today', 'world', 'obliges', 'invest', 'time', 'education', 'affect', 'living', 'conditions', 'nt', 'trust', 'success', 'Secondly', 'community', 'systematically', 'organized', 'young', 'people', 'participate', 'gauranttee', 'effecinecy', 'quality', 'product', 'big', 'company', 'brand', 'name', 'means', 'lot', 'specefic', 'company', 'conclusion', 'suggest', 'abandon', 'cars', 'start', 'taking', 'buses', 'simple', 'reasons', 'first', 'contribute', 'save', 'planet', 'pollution', 'secondly', 'buses', 'cheaper', 'cars', 'finally', 'enjoy', 'atmosphere', 'city', 'advertisements', 'gave', 'customers', 'valuable', 'information', 'product', 'intend', 'buy', 'neccessary', 'give', 'full', 'information', 'need', 'nessessary', 'ture', 'percent', 'many', 'reasons', 'Firstly', 'advertisement', 'prepared', 'specilaized', 'staff', 'expert', 'professionally', 'prepared', 'attact', 'customers', 'buy', 'products', 'Concernig', 'reasons', 'support', 'idea', 'restrict', 'fields', 'interest', 'Depending', 'class', 'study', 'sector', 'aspects', 'prevalent', 'm', 'sure', 'present', 'probably', 'reason', 'nt', 'see', 'successful', 'people', 'try', 'new', 'things', 'nt', 'see', 'way', 'using', 'word', 'successful', 'conclusion', 'young', 'people', 'well', 'raised', 'good', 'friend', 'selected', 'spending', 'free', 'useful', 'productive', 'works', 'iam', 'sure', 'really', 'helpful', 'community', 'far', 'body', 'see', 'happenning', 'Nice', 'beautiful', 'advertisement', 'give', 'people', 'dream', 'true', 'cheating', 'appears', 'however', 'broader', 'knowledge', 'many', 'academic', 'subjects', 'called', 'generalist', 'getting', 'important', 'realized', 'days', 'bad', 'idea', 'reason', 'going', 'trip', 'think', 'want', 'get', 'away', 'day', 'life', 'situation', 'understand', 'little', 'community', 'catch', 'attention', 'young', 'people', 'sons', 'world', 'find', 'difficult', 'look', 'perspective', 'little', 'town', 'beginning', 'travel', 'group', 'led', 'tour', 'guid', 'know', 'make', 'plan', 'trip', 'also', 'speak', 'English', 'enough', 'travel', 'abroad', 'Firstly', 'transportation', 'systems', 'train', 'plane', 'developing', 'matter', 'time', 'also', 'matter', 'money', 'Travering', 'individually', 'flexible', 'economical', 'Last', 'least', 'trying', 'new', 'things', 'helps', 'get', 'expeirnce', 'self-cofidence', 'example', 'last', 'week', 'coming', 'back', 'home', 'met', 'Giovanni', 'Sartori', 'Italian', 'writer', 'list', 'reasons', 'think', 'say', 'young', 'people', 'enjoy', 'life', 'older', 'Poeple', 'give', 'enough', 'time', 'communities', 'busy', 'ignorant', 'benefits', 'going', 'reap', 'difference', 'going', 'make', 'Many', 'homes', 'lead', 'example', 'embed', 'sence', 'community', 'sharing', 'education', 'children', 'Thus', 'time', 'help', 'community', 'way', 'enjoy', 'aspects', 'vacation', 'miss', 'important', 'events', 'sightings', 'However', 'nt', 'thing', 'make', 'advertisement', 'make', 'products', 'seem', 'better', 'really', 'reasons', 'tour', 'guide', 'provide', 'traveller', 'detailed', 'additional', 'information', 'place', 'believe', 'best', 'way', 'traveling', 'group', 'people', 'self', 'manage', 'moment', 'behavior', 'companies', 'corporations', 'nearly', 'criminal', 'pursued', 'legally', 'point', 'mentioned', 'health', 'athlete', 'enjoy', 'sport', 'gathering', 'friends', 'soccer', 'game', 'unfornately', 'anymore', 'speacilizing', 'subject', 'find', 'easier', 'find', 'job', 'university', 'start', 'working', 'motivating', 'self', 'fullfilling', 'feel', 'know', 'major', 'well', 'makes', 'job', 'appreciate', 'Third', 'people', 'use', 'facts', 'writing', 'research', 'make', 'writing', 'research', 'strong', 'show', 'people', 'wrote', 'article', 'reasearch', 'knows', 'talking', 'writing', 'reasearch', 'rich', 'right', 'instead', 'hypothesis', 'made', 'life', 'lot', 'easier', 'used', 'learn', 'different', 'facts', 'everyday', 'gives', 'color', 'mind', 'Sometimes', 'specialists', 'produce', 'strange', 'things', 'specialists', 'divisions', 'point', 'problems', 'products', 'strongly', 'believe', 'students', 'understanding', 'ieas', 'concepts', 'important', 'learning', 'facts', 'promote', 'academic', 'performance', 'effectively', 'quickly', 'also', 'understanding', 'concepts', 'ideas', 'beneficilal', 'students', 'improve', 'imagination', 'creativity', 'calmy', 'man', 'ussually', 'job', 'loving', 'partners', 'genuine', 'curiosity', 'also', 'characterizes', 'brave', 'people', 'often', 'Europe', 'found', 'government', 'try', 'protect', 'people', 'lives', 'people', 'independent', 'thier', 'lives', 'think', 'mean', 'fully', 'enjoy', 'thier', 'life', 'need', 'walk', 'station', 'airports', 'illustration', 'makes', 'clear', 'young', 'people', 'concerns', 'pensions', 'receive', 'future', 'exemple', 'meet', 'really', 'cool', '60-years-old', 'man', 'everything', 'power', 'fun', 'make', 'life', 'worth', 'lived', 'boring', '20-years-old', 'boy', 'never', 'step', 'house', 'go', 'school', 'way', 'mentione', 'new', 'researches', 'genetic', 'field', 'surely', 'new', 'ideas', 'change', 'world', 'tomorrow', 'give', 'true', 'prospective', 'throught', 'read', 'future', 'facts', 'Taking', 'trips', 'learning', 'place', 'also', 'old', 'people', 'financial', 'security', 'stability', 'category', 'tend', 'enjoy', 'life', 'Life', 'becomes', 'enjoyable', 'long', 'people', 'appriciate', 'example', 'planet', 'becoming', 'warmer', 'warmer', 'sea', 'level', 'increased', 'rapidly', 'last', 'years', 'life', 'quite', 'boring', 'say', 'good', 'things', 'prodoct', 'think', 'positive', 'way', 'process', 'good', 'product', 'lot', 'visibility', 'wih', 'advirtisement', 'social', 'worker', 'think', 'empowering', 'work', 'life', 'broad', 'knowledge', 'addition', 'got', 'involved', 'troubles', 'fighting', 'robbery', 'getting', 'lost', 'mamage', 'situation', 'little', 'skills', 'langage', 'Trying', 'new', 'things', 'make', 'optimistic', 'give', 'lot', 'confidence', 'people', 'move', 'location', 'lost', 'many', 'desires', 'work', 'study', 'Europe', 'many', 'people', 'easy', 'going', 'life', 'thier', 'lives', 'protected', 'government', 'Nowadays', 'live', 'world', 'economically', 'driven', 'requires', 'good', 'planning', 'wise', 'decision', 'making', 'specific', 'reason', 'comes', 'readily', 'mind', 'able', 'go', 'anywhere', 'whomever', 'want', 'also', 'change', 'schedule', 'travel', 'flexiblly', 'go', 'travel', 'individually', 'person', 'general', 'broad', 'knowledge', 'free', 'happy', 'person', 'well', 'think', 'person', 'beautiful', 'broad', 'knowledge', 'many', 'academic', 'subjects', 'specialize', 'specific', 'subject', 'knowledge', 'speak', 'people', 'meet', 'However', 'guide', 'usually', 'knows', 'languge', 'uses', 'place', 'well', 'languge', 'group', 'travelers', 'problems', 'face', 'issue', 'spring', 'semester', 'llives', 'still', 'green', 'growing', 'fast', 'general', 'reasonable', 'richness', 'horizental', 'knowled', 'said', 'deep', 'knowledge', 'subject', 'based', 'focus', 'certain', 'subject', 'none', 'born', 'direction', 'goal', 'ready', 'accomplished', 'day', 'birth', 'Thier', 'behaviors', 'problem', 'want', 'succeed', 'need', 'try', 'new', 'things', 'positive', 'accidents', 'mean', 'opprotunity', 'meet', 'people', 'find', 'great', 'shop', 'street', 'accident', 'find', 'new', 'things', 'place', 'marketed', 'mainstream', 'tourism', 'hand', 'never', 'pluck', 'courage', 'measure', 'challenging', 'situations', 'possibilities', 'enlarge', 'skills', 'think', 'many', 'functions', 'cars', 'changed', 'well', 'hand', 'sometimes', 'useful', 'students', 'learn', 'basic', 'ideas', 'concepts', 'understood', 'lectures', 'studying', 'textbook', 'First', 'nowadays', 'young', 'people', 'lot', 'things', 'school', 'instance', 'make', 'schedule', 'want', 'hang', 'people', 'get', 'know', 'believed', 'Japan', 'need', 'adapt', 'policy', 'socil', 'democracy', 'many', 'European', 'countries', 'recently', 'employment', 'Japan', 'unstable', 'Japanese', 'MNCs', 'increased', 'thier', 'sales', 'government', 'decreased', 'cooporation', 'tax', 'alot', 'free', 'time', 'spend', 'selfpleasing', 'activity', 'brings', 'happiness', 'joy', 'young', 'lot', 'time', 'enjoy', 'lot', 'things', 'together', 'conclusion', 'statement', 'nt', 'simple', 'YES', 'answer', 'reasons', 'useing', 'car', 'nt', 'want', 'reapeat', 'things', 'someone', 'Unfortunately', 'mean', 'advertisements', 'nt', 'provide', 'enough', 'information', 'took', 'risk', 'achieve', 'professional', 'qualfication', 'US', 'Generally', 'speaking', 'products', 'services', 'bank', 'provides', 'require', 'high-level', 'specialized', 'knowledge', 'particulary', 'stage', 'products', 'services', 'developed', 'organised', 'opinion', 'plannning', 'travel', 'also', 'enjoyable', 'thing', 'travel', 'impossilbe', 'use', 'station', 'forever', 'even', 'healthy', 'example', 'Japan', 'chance', 'increase', 'many', 'cars', 'due', 'traffic', 'circumstances', 'mind', 'open', 'outside', 'topic', 'find', 'diffent', 'approach', 'problems', 'help', 'instance', 'learning', 'foreign', 'language', 'challenging', 'sure', 'pains', 'experience', 'turn', 'courage', 'learn', 'confident', 'successful', 'trying', 'new', 'things', 'takes', 'risks', 'amount', 'young', 'people', 'involved', 'volunteering', 'activies', 'big', 'number', 'young', 'people', 'involved', 'activities', 'big', 'Furthermore', 'car', 'always', 'expensive', 'taxation', 'insurance', 'costs', 'also', 'high', 'fact', 'cause', 'troubles', 'provide', 'untrue', 'information', 'However', 'cases', 'fact', 'senior', 'managers', 'need', 'cover', 'extremely', 'wide', 'range', 'business', 'area', 'fully', 'agree', 'people', 'nowadays', 'give', 'enough', 'time', 'helping', 'communities', 'think', 'time', 'money-oriented', 'think', 'going', 'able', 'make', 'drastic', 'changes', 'also', 'liked', 'eat', 'advertisement', 'fact', 'think', 'cars', 'future', 'today', 'Even', 'difficult', 'time', 'succeeded', 'learn', 'things', 'time', 'sure', 'success', 'even', 'valuable', 'friend', 'learned', 'never', 'order', 'anything', 'magazines', 'statments', 'acceptable', 'disagree', 'witth', 'particular', 'statment', 'accepted', 'stereotypes', 'means', 'well', 'accept', 'stereotypes', 'ask', 'questions', 'time', 'Old', 'poeple', 'calculate', 'steps', 'take', 'risks', 'false', 'step', 'bad', 'consequences', 'dependent', 'decision', 'trial', 'never', 'practiced', 'way', 'almost', 'exact', 'opposite', 'looking', 'travel', 'Young', 'people', 'engine', 'build', 'communities', 'Thi', 'means', 'persons', 'never', 'courage', 'try', 'something', 'hard', 'different', 'new', 'possibilities', 'succeed', 'falling', 'ground', 'Modern', 'advertisment', 'able', 'manipulate', 'customer', 'often', 'convince', 'himher', 'buy', 'products', 'really', 'wanted', 'listening', 'native', 'speaker', 'conversations', 'enough', 'master', 'English', 'chirdlen', 'grow', 'become', 'young', 'adult', 'vision', 'future', 'Scientific', 'aspect', 'product', 'true', 'real', 'data', 'think', 'number', 'cars', 'reduced', 'lot', 'reason', 'kind', 'Due', 'wide', 'experiences', 'life', 'older', 'people', 'able', 'plan', 'wisely', 'order', 'enjoy', 'lives', 'people', 'feel', 'important', 'students', 'learn', 'facts', 'rather', 'understad', 'ideas', 'concepts', 'Sometimes', 'product', 'advertisement', 'succeed', 'making', 'product', 'look', 'good', 'better', 'others', 'advertisements', 'made', 'look', 'much', 'better', 'reality', 'nt', 'believe', 'order', 'successful', 'people', 'take', 'risks', 'try', 'new', 'experiences', 'Old', 'people', 'money', 'time', 'people', 'young', 'generation', 'people', 'country', 'Japan', 'live', 'years', 'leads', 'person', 'knowledgable', 'aware', 'lots', 'things', 'also', 'gives', 'sense', 'fun', 'Actually', 'tend', 'change', 'schedule', 'many', 'times', 'trip', 'inherently', 'think', 'nature', 'nt', 'fit', 'trip', 'tour', 'group', 'words', 'deep', 'need', 'go', 'field', 'speciality', 'drink', 'water', 'bottles', 'even', 'm', 'sure', 'one', 'etter', 'Interior', 'design', 'virtual', 'design', 'graphic', 'design', 'much', 'think', 'answering', 'question', 'affected', 'expected', 'gains', 'answer', 'well', 'personality', 'individual', 'answer', 'reasons', 'pointed', 'sure', 'specialized', 'knowledge', 'leads', 'better', 'human', 'life', 'respected', 'broad', 'knowledge', 'disagree', 'idea', 'young', 'people', 'enjoy', 'life', 'older', 'people', 'nt', 'completely', 'agree', 'statement', 'opinion', 'understanding', 'ideas', 'concepts', 'learing', 'facts', 'important', 'cultural', 'growth', 'student', 'media', 'played', 'important', 'role', 'misleading', 'people', 'made', 'people', 'believe', 'true', 'however', 'always', 'exceptions', 'Otherwise', 'loose', 'costomers', 'Infact', 'student', 'get', 'trouble', 'understand', 'facts', 'full', 'concepts', 'ideas', 'didn', 'study', 'hear', 'fact', 'extremely', 'important', 'move', 'want', 'convenient', 'time', 'Thus', 'really', 'intimacy', 'romantic', 'trip', 'girlfriend', 'eventually', 'consider', 'options', 'll', 'older', 'example', 'city', 'live', 'keep', 'seeing', 'advertisement', 'TV', 'talks', 'wounderful', 'chain', 'resturants', 'think', 'lot', 'exemples', 'industrial', 'men', 'writers', 'teachers', 'opinionists', 'Considering', 'facts', 'mentioned', 'doubt', 'disagree', 'statement', 'successful', 'people', 'try', 'new', 'things', 'take', 'risks', 'rather', 'already', 'know', 'well', 'think', 'start', 'learning', 'something', 'new', 'useful', 'begin', 'facts', 'easy', 'remember', 'useful', 'fixing', 'important', 'data', 'Second', 'travel', 'group', 'led', 'tour', 'guide', 'golden', 'opportunity', 'know', 'different', 'people', 'different', 'places', 'led', 'make', 'friendship', 'tour', 'guide', 'time', 'kind', 'relationship', 'younger', 'people', 'run', 'money', 'usually', 'regret', 'things', 'see', 'vacation', 'lawyer', 'able', 'spend', 'past', 'years', 'assisting', 'poor', 'clients', 'involved', 'various', 'kinds', 'litigations', 'charging', 'result', 'good', 'corelationship', 'others', 'core', 'idea', 'helping', 'community', 'hard', 'task', 'think', 'Furthermore', 'indivudual', 'trip', 'trip', 'gide', 'offer', 'lots', 'opportunity', 'talk', 'locals', 'lecture', 'useful', 'boring', 'way', 'teach', 'person', 'country', 'city', 'engineering', 'faculty', 'indeed', 'student', 'probably', 'give', 'importance', 'concept', 'understanding', 'medicine', 'faculty', 'information', 'facts', 'important', 'agree', 'successful', 'people', 'try', 'new', 'things', 'take', 'risks', 'rather', 'already', 'know', 'well', 'Therefore', 'believe', 'people', 'often', 'needed', 'understaning', 'ideas', 'concepts', 'business', 'situation', 'met', 'life', 'lot', 'interesting', 'young', 'people', 'help', 'day', 'friends', 'people', 'need', 'Learning', 'ideas', 'concepts', 'enable', 'students', 'solve', 'problem', 'quickly', 'people', 'enjoy', 'moment', 'life', 'something', 'funny', 'stimulas', 'impression', 'fun', 'temporary', 'result', 'say', 'even', 'young', 'people', 'want', 'help', 'society', 'society', 'reject', 'watching', 'TV', 'show', 'person', 'interupting', 'advertisement', 'period', 'TV', 'Facts', 'still', 'important', 'forgotten', 'nt', 'depend', 'young', 'people', 'education', 'hand', 'young', 'people', 'enough', 'time', 'help', 'comunities', 'even', 'people', 'get', 'convenced', 'problem', 'sleeping', 'nt', 'medication', 'effective', 'safe', 'surronded', 'many', 'ads', 'many', 'really', 'see', 'read', 'examine', 'carefully', 'opinion', 'successful', 'people', 'challenging', 'spirits', 'doubt', 'complicated', 'perhaps', 'boring', 'study', 'students', 'pay', 'attention', 'check', 'wether', 'get', 'correctly', 'economy', 'grows', 'country', 'people', 'able', 'purchase', 'private', 'cars', 'important', 'thearies', 'ideals', 'strategies', 'well', 'dates', 'wars', 'started', 'ended', 'example', 'takes', 'time', 'organize', 'event', 'community', 'prepared', 'report', 'trip', 'accorded', 'explanation', 'document', 'prepared', 'explanation', 'tour', 'guide', 'sometime', 'confused', 'trouble', 'write', 'reports', 'method', 'students', 'increasing', 'culture', 'material', 'rapidly', 'strenght', 'ideas', 'Even', 'music', 'different', 'worlds', 'young', 'generation', 'enjoy', 'fast', 'laud', 'music', 'dance', 'drop', 'floor', 'method', 'say', 'consumer', 'hisher', 'life', 'complete', 'surely', 'better', 'many', 'car', 'companys', 'triing', 'make', 'new', 'type', 'car', 'Secondly', 'people', 'like', 'normal', 'ussual', 'things', 'call', 'calmy', 'man', 'life', 'meaningful', 'try', 'new', 'things', 'take', 'risks', 'totally', 'agree', 'idea', 'young', 'people', 'enjoy', 'life', 'older', 'people', 'Today', 'world', 'offers', 'chances', 'fun', 'people', 'ages', 'lot', 'parks', 'resorts', 'child', 'go', 'enjoy', 'days', 'parents', 'great', 'time', 'First', 'expensive', 'tour', 'guide', 'compared', 'taking', 'trip', 'group', 'Moreover', 'jobs', 'required', 'high', 'level', 'specialization', 'case', 'better', 'little', 'good', 'knowledge', 'many', 'poor', 'skills', 'second', 'reasons', 'make', 'agree', 'statement', 'richest', 'man', 'world', 'microsoft', 'owner', 'number', 'size', 'problems', 'lives', 'communities', 'horrifying', 'required', 'help', 'quantneeded', 'world', 'agree', 'statement', 'learning', 'facts', 'based', 'understanding', 'ideas', 'However', 'currently', 'happy', 'new', 'life', 'knowing', 'new', 'things', 'new', 'people', 'new', 'country', 'new', 'culture', 'matter', 'fact', 'nt', 'become', 'successful', 'work', 'hard', 'want', 'achieve', 'Viceversa', 'medical', 'doctor', 'make', 'good', 'diagnosis', 'understand', 'actually', 'causes', 'certain', 'deseas', 'heshe', 'learn', 'related', 'sympthoms', 'books', 'nothing', 'interesting', 'simple', 'student', 'responsabilty', 'studying', 'little', 'spending', 'free', 'time', 'getting', 'meet', 'new', 'friends', 'partying', 'often', 'Moreover', 'see', 'changes', 'culture', 'cause', 'people', 'buy', 'fewer', 'cars', 'childrens', 'understand', 'core', 'statement', 'nt', 'know', 'really', 'understand', 'thing', 'aunt', 'Mongolia', 'weeks', 'living', 'nomades', 'tent', 'drinking', 'acidic', 'milk', 'traveling', 'companions', 'back', 'assured', 'repeat', 'trip', 'guide', 'example', 'company', 'provide', 'samples', 'products', 'allow', 'consumers', 'experience', 'young', 'people', 'enjoy', 'life', 'older', 'people', 'example', 'went', 'place', 'learn', 'math', 'child', 'people', 'say', 'broad', 'knowledge', 'better', 'believe', 'tha', 'specialize', 'specific', 'subject', 'better', 'human', 'lives', 'bring', 'simple', 'example', 'mean', 'difficult', 'agree', 'disagree', 'statement', 'differences', 'learning', 'facts', 'understanding', 'concepts', 'sum', 'say', 'people', 'enjoy', 'life', 'regerdless', 'thier', 'age', 'point', 'makes', 'oppose', 'ignoring', 'broad', 'knowledge', 'sake', 'specializing', 'related', 'personality', 'individual', 'Secondly', 'let', 'introduce', 'experience', 'grand', 'mother', 'want', 'Travel', 'alone', 'also', 'cheeper', 'choose', 'combination', 'failures', 'successes', 'makes', 'feel', 'part', 'place', 'visiting', 'time', 'gives', 'incredibile', 'opportunity', 'get', 'touch', 'talk', 'many', 'people', 'initelligent', 'people', 'specialists', 'opinion', 'try', 'traveling', 'ina', 'group', 'led', 'tour', 'guide', 'travel', 'alon', 'family', 'experience', 'adventure', 'keep', 'wonderfull', 'memorise', 'mindes', 'like', 'day', 'visit', 'lovley', 'places', 'heard', 'people', 'First', 'specialization', 'brings', 'deep', 'knowledge', 'better', 'comprehension', 'opinion', 'better', 'broad', 'knowledge', 'many', 'academic', 'subjects', 'instead', 'specialization', 'offers', 'much', 'flexibility', 'traveling', 'group', 'tour', 'guide', 'always', 'known', 'history', 'places', 'tour', 'visit', 'tour', 'get', 'information', 'places', 'visit', 'learning', 'anew', 'stuff', 'place', 'Transportation', 'Crowded', 'huge', 'number', 'cars', 'truks', 'nowdays', 'truth', 'reveals', 'buy', 'First', 'advertising', 'companys', 'create', 'new', 'product', 'see', 'react', 'even', 'loose', 'money', 'producing', 'agree', 'better', 'student', 'understand', 'ideas', 'concepts', 'learn', 'facts', 'student', 'understand', 'idea', 'cocept', 'never', 'forget', 'learn', 'sake', 'exam', 'example', 'forget', 'faster', 'fact', 'think', 'lot', 'people', 'successful', 'nt', 'different', 'people', 'exemple', 'intelligence', 'possibility', 'normal', 'person', 'successfful', 'becouse', 'put', 'energy', 'work', 'generally', 'things', 'resons', 'say', 'helping', 'society', 'really', 'important', 'Even', 'little', 'action', 'help', 'someone', 'school', 'builds', 'sense', 'service', 'others', 'advertisements', 'makes', 'products', 'seem', 'much', 'better', 'realy', 'Considering', 'bad', 'experience', 'decided', 'organize', 'next', 'travel', 'ourself', 'asked', 'question', 'latest', 'work', 'called', 'La', 'mala', 'costituzione', 'fact', 'help', 'students', 'understand', 'theorical', 'concepts', 'contact', 'locals', 'crucial', 'discovery', 'process', 'travel', 'presence', 'tour', 'guide', 'undermine', 'lot', 'ability', 'interact', 'people', 'According', 'experience', 'past', 'strong', 'ly', 'agree', 'statement', 'understanding', 'ideas', 'concepts', 'important', 'learning', 'facts', 'students', 'perfectly', 'agree', 'statement', 'obviously', 'young', 'people', 'course', 'including', 'help', 'comunities', 'Traveling', 'group', 'takes', 'away', 'freedom', 'time', 'space', 'find', 'easier', 'safer', 'move', 'around', 'group', 'reality', 'wish', 'go', 'stay', 'certain', 'place', 'certain', 'time', 'choice', 'possible', 'group', 'different', 'agenda', 'demand', 'people', 'Especially', 'old', 'people', 'war-experience', 'know', 'appriciate', 'First', 'time', 'changeing', 'course', 'advantages', 'traveling', 'group', 'satisfied', 'knowledge', 'trying', 'new', 'things', 'example', 'new', 'ideas', 'world', 'Physic', 'followed', 'Atomic', 'Bomb', 'use', 'World', 'War', 'II', 'category', 'youth', 'enjoy', 'life', 'others', 'months', 'ago', 'convinced', 'advertisment', 'Assets', 'air', 'conditionars', 'good', 'quality', 'much', 'better', 'broad', 'knowledge', 'many', 'academics', 'subjects', 'specialize', 'specific', 'subject', 'willing', 'take', 'risk', 'wondering', 'around', 'asking', 'local', 'people', 'show', 'good', 'restaurant', 'experience', 'give', 'many', 'episodes', 'Brave', 'people', 'frighten', 'events', 'occur', 'approach', 'opinion', 'right', 'order', 'lead', 'situations', 'scared', 'travel', 'alone', 'however', 'many', 'things', 'learn', 'taking', 'trips', 'remember', 'young', 'person', 'best', 'time', 'life', 'meet', 'friends', 'true', 'still', 'contact', 'thing', 'young', 'see', 'often', 'use', 'time', 'want', 'meet', 'schedule', 'meetings', 'advance', 'even', 'meet', 'fun', 'use', 'However', 'become', 'far', 'humane', 'bny', 'Surely', 'food', 'good', 'pricy', 'part', 'needed', 'discussed', 'friends', 'offered', 'pay', 'prior', 'seing', 'bill', 'go', 'field', 'necessary', 'knowledge', 'skills', 'well', 'attitudes', 'compromise', 'field', 'able', 'use', 'analogy', 'resolve', 'problems', 'powerful', 'method', 'example', 'advertisement', 'food', 'chalenge', 'prove', 'product', 'unnatural', 'products', 'peoples', 'tests', 'product', 'say', 'true', 'product', 'contain', 'unnatural', 'products', 'parent', 'said', 'remember', 'parent', 'tell', 'care', 'community', 'help', 'parent', 'grew', 'parent', 'said', 'never', 'really', 'understood', 'Less', 'responsabilities', 'young', 'people', 'means', 'time', 'available', 'time', 'generally', 'use', 'enjoy', 'life', 'b', 'less', 'available', 'time', 'thoughts', 'consequence', 'responsabilities', 'parents', 'benefit', 'decesion', 'help', 'alot', 'reducing', 'traffic', 'problems', 'crowded', 'streets', 'school', 'gives', 'first', 'opportunity', 'learn', 'different', 'tipes', 'design', 'second', 'understand', 'best', 'believe', 'people', 'successful', 'try', 'lot', 'new', 'things', 'even', 'high', 'risks', 'following', 'reasons', 'changeing', 'time', 'improve', 'enjoying', 'First', 'think', 'many', 'things', 'changing', 'rapidly', 'everyday', 'example', 'people', 'demands', 'preferences', 'different', 'yesterday', 'learn', 'cultures', 'intresting', 'find', 'beleives', 'forbbiden', 'cultures', 'allowed', 'others', 'therefore', 'people', 'visit', 'countries', 'knoe', 'react', 'people', 'However', 'many', 'apartment', 'houses', 'many', 'people', 'live', 'cities', 'grow', 'needs', 'go', 'back', 'first', 'stage', 'choice', 'also', 'disagree', 'statement', 'personally', 'think', 'weak', 'statment', 'becaue', 'supported', 'kind', 'eveidence', 'survey', 'statistics', 'meaning', 'full', 'numbers', 'Increasing', 'number', 'cram', 'school', 'especially', 'one', 'young', 'people', 'crealy', 'shows', 'fact', 'many', 'young', 'pepople', 'spenting', 'time', 'study', 'Engeneer', 'studied', 'lot', 'theory', 'important', 'understand', 'concepts', 'learning', 'facts', 'personal', 'experience', 'provides', 'society', 'strong', 'tendency', 'observe', 'negative', 'examples', 'provided', 'young', 'people', 'really', 'hard', 'find', 'free', 'time', 'dedicate', 'others', 'usually', 'get', 'really', 'bored', 'studing', 'tired', 'endless', 'working', 'hours', 'grandfather', 'even', 'father', 'getting', 'ready', 'go', 'sort', 'selfpleasing', 'activity', 'strongly', 'believe', 'extremely', 'dangerous', 'young', 'spectators', 'particularly', 'sensitive', 'aspects', 'defined', 'personality', 'yet', 'easily', 'convinceable', 'believe', 'student', 'take', 'care', 'understanding', 'concepts', 'lerning', 'facts', 'Successful', 'people', 'worked', 'hard', 'accomplimish', 'achieve', 'goals', 'First', 'higher', 'authority', 'places', 'elderly', 'experienced', 'persons', 'community', 'Finally', 'think', 'students', 'want', 'want', 'First', 'cities', 'trying', 'improve', 'public', 'transports', 'always', 'projects', 'new', 'faster', 'metropolitan', 'lines', 'link', 'different', 'city', 'zones', 'real', 'short', 'time', 'Even', 'minutes', 'day', 'benefit', 'community', 'significantley', 'future', 'thought', 'really', 'passive', 'way', 'leaning', 'traveling', 'several', 'days', 'Germany', 'went', 'small', 'church', 'father', 'early', 'morning', 'waste', 'time', 'waiting', 'decision'], 'input_ids': [0, 937, 3552, 2340, 24, 21999, 284, 6878, 7905, 1300, 2382, 44960, 927, 935, 1737, 146, 3013, 1110, 3478, 6925, 512, 1806, 1532, 383, 3553, 906, 6160, 645, 1800, 652, 92, 13143, 6647, 1195, 216, 8079, 932, 7385, 224, 82, 393, 120, 778, 1282, 12769, 1538, 393, 236, 185, 2476, 3370, 383, 169, 2188, 2801, 679, 4703, 7280, 346, 1677, 304, 452, 107, 3790, 666, 22375, 10455, 13733, 2978, 1532, 2136, 301, 169, 2157, 1311, 78, 352, 5151, 3359, 885, 493, 4560, 82, 631, 1800, 5151, 236, 240, 1346, 1532, 12956, 14263, 1648, 664, 1294, 558, 1138, 1202, 9160, 5350, 30639, 620, 5332, 621, 2655, 10638, 2370, 2074, 1339, 2477, 2313, 1302, 657, 3120, 1099, 7721, 664, 82, 9574, 44941, 2333, 3291, 670, 7745, 664, 82, 937, 332, 2305, 2854, 664, 82, 25708, 492, 615, 86, 1903, 1822, 985, 460, 224, 22414, 2706, 12888, 206, 5894, 14267, 14612, 5894, 2731, 1980, 1246, 356, 1377, 2388, 8610, 15050, 173, 92, 1677, 1421, 92, 12418, 3055, 24240, 9779, 1715, 645, 2179, 518, 512, 1265, 244, 951, 1453, 8696, 460, 3665, 203, 335, 1606, 2655, 1504, 206, 3097, 1137, 754, 527, 323, 1049, 4286, 1114, 634, 754, 527, 2145, 505, 1346, 181, 1417, 1949, 5443, 13403, 1873, 918, 613, 10947, 82, 393, 1411, 751, 173, 171, 39307, 22393, 4193, 5332, 1435, 696, 171, 1651, 577, 244, 1391, 1822, 240, 12622, 1050, 1903, 865, 761, 633, 236, 892, 319, 6128, 269, 14384, 642, 2650, 146, 301, 164, 157, 2254, 301, 319, 631, 2530, 82, 25071, 1322, 352, 3014, 2345, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'pad_mask': [-100, 0, 0, 0, 0, -100, 0, 0, 0, 0, 0, 0, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, 0, 0, 0, -100, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, 0, 0, -100, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, 0, 0, -100], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2888: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "100% 1/1 [00:00<00:00, 90.43it/s]\n",
            "&&& Assuming tagging predictions:\n",
            "100% 1/1 [00:00<00:00, 42.02it/s]\n",
            "&&& Assuming tagging predictions:\n",
            "Save to conll file predictions.tsv.\n",
            "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mtmp_trainer\u001b[0m at: \u001b[34mhttps://wandb.ai/tapaninaho-joonas-university-of-oulu/huggingface/runs/9zbfk93k\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241108_092843-9zbfk93k/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_predictions_df = pd.read_csv(\"predictions.tsv\", sep=\"\\t\")\n",
        "predicted_metaphors_bert = bert_predictions_df[\"Real_metaphors\"]\n",
        "print(bert_predictions_df)\n",
        "\n",
        "bert_metaphor_df = bert_predictions_df.loc[bert_predictions_df['Real_metaphors'] == 1]\n",
        "bert_metaphoras = bert_metaphor_df['Tokens']\n",
        "bert_metaphoras = bert_metaphoras.values.tolist()\n",
        "\n",
        "# FrameBert Result to predictions\n",
        "\n",
        "bert_predictions = []\n",
        "\n",
        "for test_sentence in test_sentences_toelf_b:\n",
        "  metaphora = 0\n",
        "  for token in test_sentence:\n",
        "    if token in bert_metaphoras:\n",
        "      metaphora = 1\n",
        "  bert_predictions.append(metaphora)\n",
        "\n",
        "print(len(bert_predictions))\n",
        "print(len(labels_test_b))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6s4mKyf9Thq",
        "outputId": "597779db-657f-4de5-90eb-793ba160d8de"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Tokens  Borderline_metaphor  Real_metaphors       Frame_label\n",
            "0        general                    0               0                 _\n",
            "1         scheme                    0               0                 _\n",
            "2         normal                    0               0                 _\n",
            "3        italian                    0               0                 _\n",
            "4         family                    0               0           Kinship\n",
            "..           ...                  ...             ...               ...\n",
            "224        older                    0               0               Age\n",
            "225       people                    0               0            People\n",
            "226  necessarely                    0               0                 _\n",
            "227     maintain                    1               1  Activity_ongoing\n",
            "228         sort                    0               0              Type\n",
            "\n",
            "[229 rows x 4 columns]\n",
            "548\n",
            "3241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate evaluation metrics for FrameBERT\n",
        "accuracy = accuracy_score(labels_test_toelf_b, bert_predictions)\n",
        "precision = precision_score(labels_test_toelf_b, bert_predictions)\n",
        "recall = recall_score(labels_test_toelf_b, bert_predictions)\n",
        "f1 = f1_score(labels_test_toelf_b, bert_predictions)\n",
        "\n",
        "# Print the results\n",
        "print(\"Evaluation Metrics for Metaphor Detection:\")\n",
        "print(f\"Accuracy: {accuracy*100:.4f} %\")\n",
        "print(f\"Precision: {precision*100:.4f} %\")\n",
        "print(f\"Recall: {recall*100:.4f} %\")\n",
        "print(f\"F1-Score: {f1*100:.4f} %\")\n",
        "\n",
        "model_bert_new_row_toelf = {'Dataset': 'TOEFL', 'Feature Length': 0, 'Model': 'BERT', 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-Score': f1}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6w8eYhZ6icQs",
        "outputId": "f8316f45-7ea8-4ce8-ab12-f8e64b966b7f"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics for Metaphor Detection:\n",
            "Accuracy: 58.2117 %\n",
            "Precision: 70.0000 %\n",
            "Recall: 3.0043 %\n",
            "F1-Score: 5.7613 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. We want to test the model on other datasets,\n",
        "https://www.eecs.uottawa.ca/~diana/resources/metaphor/type1_metaphor_annotated.txt. In the\n",
        "above, the annotation at the end of the sentence i.e., @1@y indicates whether it is a metaphor (y) or\n",
        "not (n). Here the presence of ‘y’ indicates that it is a metaphor, whereas “1” indicates the first head\n",
        "word of the sentence, which is “poise”, in the part of speech tag sequence. Write a script that translates\n",
        "the dataset into a format that can be utilized by the classifier / machine learning model.**"
      ],
      "metadata": {
        "id": "FL4-HNBrlClT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "r_otw = requests.get('https://www.eecs.uottawa.ca/~diana/resources/metaphor/type1_metaphor_annotated.txt')\n",
        "\n",
        "decoded_content_otw = r_otw.content.decode(\"utf-8\").split('\\r')\n",
        "decoded_content_otw = [c.replace('\\n', ' ') for c in decoded_content_otw]\n",
        "\n",
        "strings_otw = []\n",
        "nums_otw = []\n",
        "labels_otw = []\n",
        "\n",
        "pattern_otw = r'@\\d+@[a-zA-Z]'\n",
        "\n",
        "for c in decoded_content_otw:\n",
        "  matches = re.findall(pattern_otw, c)\n",
        "  num = re.findall('\\d+', matches[0])\n",
        "  lab = re.findall('[a-zA-Z]', matches[0])\n",
        "  string = c.replace(matches[0], '')\n",
        "  strings_otw.append(string)\n",
        "  nums_otw.append(num)\n",
        "  labels_otw.append(lab)\n",
        "\n",
        "data_otw = {\n",
        "  \"strings\": strings_otw,\n",
        "  \"numbers\": nums_otw,\n",
        "  \"labes\" : labels_otw\n",
        "}\n",
        "\n",
        "ottawa_df = pd.DataFrame(data_otw)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "iZhgIyC6mrO3"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ottawa_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3ePbWDqraek",
        "outputId": "563114b2-9315-4ba8-dd86-a89daea4bdaf",
        "collapsed": true
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               strings numbers labes\n",
            "0                                   poise is a club .      [1]   [y]\n",
            "1         destroying alexandria . sunlight is silence      [4]   [y]\n",
            "2      feet are no anchor . gravity sucks at the mind      [1]   [y]\n",
            "3         on the day 's horizon is a gesture of earth      [5]   [y]\n",
            "4         he said good-by as if good-by is a number .      [6]   [y]\n",
            "..                                                 ...     ...   ...\n",
            "714   as the season of cold is the season of darkness      [5]   [n]\n",
            "715                     else all beasts were tigers ,      [3]   [y]\n",
            "716                       without which earth is sand      [3]   [n]\n",
            "717                         the sky is cloud on cloud      [2]   [n]\n",
            "718                                 the sky is cloudy      [2]   [n]\n",
            "\n",
            "[719 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens_otw = []\n",
        "tokenize_sentences_otw = []\n",
        "tokens_sum_otw = 0\n",
        "\n",
        "for s in strings_otw:\n",
        "  tokens = word_tokenize(s)\n",
        "  tokens = [token.lower() for token in tokens if token.lower() not in stopwords and token not in chars]\n",
        "  tokens_sum_otw += len(tokens)\n",
        "  for token in tokens:\n",
        "    if token not in all_tokens:\n",
        "      all_tokens_otw.append(token)\n",
        "  tokenize_sentences_otw.append(tokens)"
      ],
      "metadata": {
        "id": "2uO_sKuOltYw"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "otw_sent_count = len(tokenize_sentences_otw)\n",
        "otw_avg = tokens_sum_otw / otw_sent_count"
      ],
      "metadata": {
        "id": "zqKROiTbCJXU"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ottawa_df_2 = ottawa_df.assign(Tokenized_sentences=tokenize_sentences_otw)"
      ],
      "metadata": {
        "id": "g2QQHe67wO3q"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "xGlrYZyyS3Om"
      },
      "outputs": [],
      "source": [
        "otw_sentences = ottawa_df_2['Tokenized_sentences'].values.tolist()\n",
        "otw_labes = ottawa_df_2['labes'].values.tolist()\n",
        "otw_labes = [1 if l[0] == 'y' else 0 for l in otw_labes]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "otw_sent_with_methapor = 0\n",
        "\n",
        "for l in otw_labes:\n",
        "  if l == 1:\n",
        "    otw_sent_with_methapor += 1\n",
        "\n",
        "print(otw_sent_with_methapor)\n",
        "print(len(otw_labes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR2te4VDCv4X",
        "outputId": "1f032739-8c62-4898-eff1-d16d94457fc0"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "358\n",
            "719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_for_tf_idf_otw = []\n",
        "for i in range(0,len(otw_sentences)):\n",
        "  tokens = tokenize_sentences_otw[i]\n",
        "  sentence = \"\"\n",
        "  for t in range(0,len(tokens)):\n",
        "    sentence += tokens[t] + \" \"\n",
        "  sentences_for_tf_idf_otw.append(str(sentence))"
      ],
      "metadata": {
        "id": "Dr6XfrMao9KX"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzx40oXKS3hE"
      },
      "source": [
        "**7. Accommodate the programs in FrameBERT and machine learning model in 2) and 3) to test the\n",
        "performance of the models on uottawa dataset.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2 models with Ottawa data**"
      ],
      "metadata": {
        "id": "zSte59F8ro4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_lengths = [250, 500, 1000, 3000]\n",
        "\n",
        "results_2_otw = {'Dataset': [], 'Feature Length': [], 'Model': [], 'Accuracy': [], 'Precision': [], 'Recall': [], 'F1-Score': []}\n",
        "\n",
        "for length in feature_lengths:\n",
        "\n",
        "    vectorizer = TfidfVectorizer(max_features=length)\n",
        "    X = vectorizer.fit_transform(sentences_for_tf_idf_otw)\n",
        "    names = vectorizer.get_feature_names_out()\n",
        "\n",
        "    train_sentences, test_sentences, labels_train, labels_test = train_test_split(X, otw_labes, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train and eval Naive Bayes\n",
        "    nb_model = MultinomialNB()\n",
        "    nb_model.fit(train_sentences, labels_train)\n",
        "    nb_predictions = nb_model.predict(test_sentences)\n",
        "    nb_accuracy = accuracy_score(labels_test, nb_predictions)\n",
        "    nb_precision = precision_score(labels_test, nb_predictions)\n",
        "    nb_recall = recall_score(labels_test, nb_predictions)\n",
        "    nb_f1 = f1_score(labels_test, nb_predictions)\n",
        "\n",
        "\n",
        "    results_2_otw['Feature Length'].append(length)\n",
        "    results_2_otw['Model'].append('Naive Bayes')\n",
        "    results_2_otw['Accuracy'].append(nb_accuracy)\n",
        "    results_2_otw['Precision'].append(nb_precision)\n",
        "    results_2_otw['Recall'].append(nb_recall)\n",
        "    results_2_otw['F1-Score'].append(nb_f1)\n",
        "    results_2_otw['Dataset'].append('Ottawa')\n",
        "    highestacc = nb_accuracy\n",
        "    bestmodel = 'NB'\n",
        "\n",
        "    # Train and eval SVM\n",
        "    svm_model = SVC(kernel='linear', random_state=42)\n",
        "    svm_model.fit(train_sentences, labels_train)\n",
        "    svm_predictions = svm_model.predict(test_sentences)\n",
        "    svm_accuracy = accuracy_score(labels_test, svm_predictions)\n",
        "    svm_precision = precision_score(labels_test, svm_predictions)\n",
        "    svm_recall = recall_score(labels_test, svm_predictions)\n",
        "    svm_f1 = f1_score(labels_test, svm_predictions)\n",
        "\n",
        "    results_2_otw['Feature Length'].append(length)\n",
        "    results_2_otw['Model'].append('SVM')\n",
        "    results_2_otw['Accuracy'].append(svm_accuracy)\n",
        "    results_2_otw['Precision'].append(svm_precision)\n",
        "    results_2_otw['Recall'].append(svm_recall)\n",
        "    results_2_otw['F1-Score'].append(svm_f1)\n",
        "    results_2_otw['Dataset'].append('Ottawa')\n",
        "    if svm_accuracy > highestacc:\n",
        "        highestacc = svm_accuracy\n",
        "        bestmodel = 'SVM'\n",
        "\n",
        "    # Train and eval Logistic Regression\n",
        "    logreg = LogisticRegression(random_state=16)\n",
        "    logreg.fit(train_sentences, labels_train)\n",
        "    logreg_pred = logreg.predict(test_sentences)\n",
        "    logreg_acc = accuracy_score(labels_test, logreg_pred)\n",
        "    logreg_precision = precision_score(labels_test, logreg_pred)\n",
        "    logreg_recall = recall_score(labels_test, logreg_pred)\n",
        "    logreg_f1 = f1_score(labels_test, logreg_pred)\n",
        "\n",
        "    results_2_otw['Feature Length'].append(length)\n",
        "    results_2_otw['Model'].append('Logistic Reg.')\n",
        "    results_2_otw['Accuracy'].append(logreg_acc)\n",
        "    results_2_otw['Precision'].append(logreg_precision)\n",
        "    results_2_otw['Recall'].append(logreg_recall)\n",
        "    results_2_otw['F1-Score'].append(logreg_f1)\n",
        "    results_2_otw['Dataset'].append('Ottawa')\n",
        "    if logreg_acc > highestacc:\n",
        "        highestacc = logreg_acc\n",
        "        bestmodel = 'LogReg'\n",
        "\n",
        "    # Train and eval Multi-Layer-Perceptron classifier\n",
        "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
        "                        hidden_layer_sizes=(5, 2), max_iter=100, random_state=1)\n",
        "    clf.fit(train_sentences, labels_train)\n",
        "    mlp_pred = clf.predict(test_sentences)\n",
        "    mlp_acc = accuracy_score(labels_test, mlp_pred)\n",
        "    mlp_precision = precision_score(labels_test, mlp_pred)\n",
        "    mlp_recall = recall_score(labels_test, mlp_pred)\n",
        "    mlp_f1 = f1_score(labels_test, mlp_pred)\n",
        "\n",
        "    results_2_otw['Feature Length'].append(length)\n",
        "    results_2_otw['Model'].append('MLP')\n",
        "    results_2_otw['Accuracy'].append(mlp_acc)\n",
        "    results_2_otw['Precision'].append(mlp_precision)\n",
        "    results_2_otw['Recall'].append(mlp_recall)\n",
        "    results_2_otw['F1-Score'].append(mlp_f1)\n",
        "    results_2_otw['Dataset'].append('Ottawa')\n",
        "    if mlp_acc > highestacc:\n",
        "        highestacc = mlp_acc\n",
        "        bestmodel = 'MLP'\n",
        "\n",
        "    average = (nb_predictions + svm_predictions + logreg_pred + mlp_pred) / 4\n",
        "    averageacc = (nb_accuracy + svm_accuracy + logreg_acc + mlp_acc) / 4\n",
        "    print('Average accuracy', round(averageacc, 5))\n",
        "    print('RMSE: ', round(mean_squared_error(labels_test, average), 5))\n",
        "\n",
        "    if averageacc > highestacc:\n",
        "        highestacc = averageacc\n",
        "        bestmodel = 'Ensemble'\n",
        "\n",
        "    print('Best model: ', bestmodel + '    Model Accuracy: ', round(highestacc, 5))\n",
        "    print('------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ODrYLRvJrdrD",
        "outputId": "cb712f26-750e-45ca-9ef8-fc73ef772a6d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracy 0.58507\n",
            "RMSE:  0.31033\n",
            "Best model:  MLP    Model Accuracy:  0.60417\n",
            "------\n",
            "Average accuracy 0.55903\n",
            "RMSE:  0.36198\n",
            "Best model:  LogReg    Model Accuracy:  0.57639\n",
            "------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracy 0.56076\n",
            "RMSE:  0.37023\n",
            "Best model:  NB    Model Accuracy:  0.58333\n",
            "------\n",
            "Average accuracy 0.53299\n",
            "RMSE:  0.34852\n",
            "Best model:  NB    Model Accuracy:  0.5625\n",
            "------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df_otw = pd.DataFrame(results_2_otw)\n",
        "print(results_df_otw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_69PHuisVyH",
        "outputId": "5ea201a9-051e-443b-99a1-0816a15c3089"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Dataset  Feature Length          Model  Accuracy  Precision    Recall  \\\n",
            "0   Ottawa             250    Naive Bayes  0.576389   0.625000  0.410959   \n",
            "1   Ottawa             250            SVM  0.576389   0.563830  0.726027   \n",
            "2   Ottawa             250  Logistic Reg.  0.583333   0.573034  0.698630   \n",
            "3   Ottawa             250            MLP  0.604167   0.700000  0.383562   \n",
            "4   Ottawa             500    Naive Bayes  0.555556   0.571429  0.493151   \n",
            "5   Ottawa             500            SVM  0.569444   0.560440  0.698630   \n",
            "6   Ottawa             500  Logistic Reg.  0.576389   0.569767  0.671233   \n",
            "7   Ottawa             500            MLP  0.534722   0.537500  0.589041   \n",
            "8   Ottawa            1000    Naive Bayes  0.583333   0.600000  0.534247   \n",
            "9   Ottawa            1000            SVM  0.541667   0.541176  0.630137   \n",
            "10  Ottawa            1000  Logistic Reg.  0.541667   0.542169  0.616438   \n",
            "11  Ottawa            1000            MLP  0.576389   0.583333  0.575342   \n",
            "12  Ottawa            3000    Naive Bayes  0.562500   0.565789  0.589041   \n",
            "13  Ottawa            3000            SVM  0.534722   0.536585  0.602740   \n",
            "14  Ottawa            3000  Logistic Reg.  0.541667   0.543210  0.602740   \n",
            "15  Ottawa            3000            MLP  0.493056   0.000000  0.000000   \n",
            "\n",
            "    F1-Score  \n",
            "0   0.495868  \n",
            "1   0.634731  \n",
            "2   0.629630  \n",
            "3   0.495575  \n",
            "4   0.529412  \n",
            "5   0.621951  \n",
            "6   0.616352  \n",
            "7   0.562092  \n",
            "8   0.565217  \n",
            "9   0.582278  \n",
            "10  0.576923  \n",
            "11  0.579310  \n",
            "12  0.577181  \n",
            "13  0.567742  \n",
            "14  0.571429  \n",
            "15  0.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3 ensemble model with Ottawa data**"
      ],
      "metadata": {
        "id": "1uLLkr2UsgGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# note this time max_features = 1000, because it performed best\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X = vectorizer.fit_transform(sentences_for_tf_idf_otw)\n",
        "names = vectorizer.get_feature_names_out()\n",
        "\n",
        "train_sentences_otw_3, test_sentences_otw_3, labels_train_otw_3, labels_test_otw_3 = train_test_split(X, otw_labes, test_size=0.2, random_state=42)\n",
        "\n",
        "# initializing all the base model objects with default parameters\n",
        "\n",
        "model_1_otw_3 = LogisticRegression(random_state=16)\n",
        "model_2_otw_3 = MultinomialNB()\n",
        "model_3_otw_3 = SVC(kernel='linear', random_state=42)\n",
        "\n",
        "# putting all base model objects in one list\n",
        "all_models_otw_3 = [model_1_otw_3, model_2_otw_3, model_3_otw_3]\n",
        "\n",
        "# computing the stack features\n",
        "s_train_otw_3, s_test_otw_3 = stacking(all_models_otw_3, train_sentences_otw_3, labels_train_otw_3, test_sentences_otw_3, regression=True, shuffle=True, n_folds=4)\n",
        "\n",
        "# initializing the second-level model\n",
        "final_model_otw_3 = model_1_otw_3\n",
        "\n",
        "# fitting the second level model with stack features\n",
        "final_model_otw_3 = final_model.fit(s_train_otw_3, labels_train_otw_3)\n",
        "\n",
        "# predicting the final output using stacking\n",
        "pred_final_otw_3 = final_model_otw_3.predict(s_test_otw_3)"
      ],
      "metadata": {
        "id": "wILz5JYCsrHN"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate evaluation metrics\n",
        "accuracy_otw_3 = accuracy_score(labels_test_otw_3, pred_final_otw_3)\n",
        "precision_otw_3 = precision_score(labels_test_otw_3, pred_final_otw_3)\n",
        "recall_otw_3 = recall_score(labels_test_otw_3, pred_final_otw_3)\n",
        "f1_otw_3 = f1_score(labels_test_otw_3, pred_final_otw_3)\n",
        "\n",
        "# Print the results\n",
        "print(\"Evaluation Metrics for Metaphor Detection:\")\n",
        "print(f\"Accuracy: {accuracy_otw_3*100:.4f} %\")\n",
        "print(f\"Precision: {precision_otw_3*100:.4f} %\")\n",
        "print(f\"Recall: {recall_otw_3*100:.4f} %\")\n",
        "print(f\"F1-Score: {f1_otw_3*100:.4f} %\")\n",
        "\n",
        "model_3_new_row_otw = {'Dataset': 'Ottawa', 'Feature Length': 3000, 'Model': 'Ensemble', 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-Score': f1}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8RCWLQBtZJo",
        "outputId": "c7aed6cc-d5fa-4ceb-859b-17937b4946d0"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics for Metaphor Detection:\n",
            "Accuracy: 54.8611 %\n",
            "Precision: 55.8824 %\n",
            "Recall: 52.0548 %\n",
            "F1-Score: 53.9007 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_true_otw = 0\n",
        "\n",
        "for num in labels_test_otw_3:\n",
        "  if num == 1:\n",
        "    labels_true_otw += 1\n",
        "\n",
        "labels_true_otw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQzXZi1IDLeM",
        "outputId": "e5614615-11a0-4be9-a307-17541ae3a5ca"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "otw_data = {'Dataset': 'Ottawa',\n",
        "            'Measurement' : ['Sent. count', 'Tokens', 'Unique tokens', 'Avg token per sent', 'sent with methapor', 'Testing sent count', 'How many with metaphor'],\n",
        "            'Values' : [otw_sent_count, tokens_sum_otw, len(all_tokens_otw), otw_avg, otw_sent_with_methapor, len(labels_test_otw_3), labels_true_otw]\n",
        "            }"
      ],
      "metadata": {
        "id": "EqqIB4FMDESy"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FrameBERT ensemble model with Ottawa data**"
      ],
      "metadata": {
        "id": "asSUG5uUuqEw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "lXaWYFv7S5h-"
      },
      "outputs": [],
      "source": [
        "# Modifying Ottawa data for FrameBert testing\n",
        "\n",
        "train_sentences_otw_b, test_sentences_otw_b, labels_train_otw_b, labels_test_otw_b = train_test_split(otw_sentences, otw_labes, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "string_otw = ''\n",
        "\n",
        "for sentence in test_sentences_otw_b:\n",
        "  for index, s in enumerate(sentence):\n",
        "    if index == len(sentence) - 1:\n",
        "      string_otw += s + \"\\n\"\n",
        "    else:\n",
        "      string_otw += s + \" \"\n",
        "\n",
        "temp = { \"articles\": string_otw }\n",
        "\n",
        "json_sentences_otw = json.dumps(temp)\n",
        "\n",
        "with open('sentences_otw.json', 'w') as writefile:\n",
        "    writefile.write(json_sentences_otw)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run Bert with ottawa data\n",
        "!python inference.py sentences_otw.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fRnmRm2brWDn",
        "outputId": "2d8e0d1b-2c01-4c01-ab43-5feaee99388c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-08 09:30:16.560637: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-08 09:30:16.600762: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-08 09:30:16.613988: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-08 09:30:16.641190: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-08 09:30:18.759385: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Map: 100% 49/49 [00:00<00:00, 1343.99 examples/s]\n",
            "{'tokens': ['love', '?'], 'input_ids': [0, 657, 17487, 2], 'attention_mask': [1, 1, 1, 1], 'pad_mask': [-100, 0, 0, -100]}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2888: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "100% 7/7 [00:18<00:00,  2.44s/it]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtapaninaho-joonas\u001b[0m (\u001b[33mtapaninaho-joonas-university-of-oulu\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/MetaphorFrame/wandb/run-20241108_093046-51mb7hvz\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtmp_trainer\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/tapaninaho-joonas-university-of-oulu/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/tapaninaho-joonas-university-of-oulu/huggingface/runs/51mb7hvz\u001b[0m\n",
            "100% 7/7 [00:19<00:00,  2.83s/it]\n",
            "&&& Assuming tagging predictions:\n",
            "Map: 100% 49/49 [00:00<00:00, 703.20 examples/s]\n",
            "{'tokens': ['love', '?'], 'input_ids': [0, 657, 17487, 2], 'attention_mask': [1, 1, 1, 1], 'pad_mask': [-100, 0, 0, -100], 'token_type_ids': [0, 0, 0, 0]}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2888: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "100% 7/7 [00:18<00:00,  2.64s/it]\n",
            "&&& Assuming tagging predictions:\n",
            "100% 7/7 [00:19<00:00,  2.78s/it]\n",
            "&&& Assuming tagging predictions:\n",
            "Save to conll file predictions.tsv.\n",
            "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mtmp_trainer\u001b[0m at: \u001b[34mhttps://wandb.ai/tapaninaho-joonas-university-of-oulu/huggingface/runs/51mb7hvz\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241108_093046-51mb7hvz/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_otw_predictions = pd.read_csv(\"predictions.tsv\", sep=\"\\t\")\n",
        "predicted_metaphors_Bert = bert_otw_predictions[\"Real_metaphors\"]\n",
        "\n",
        "bert_metaphor_otw_df = bert_otw_predictions.loc[bert_otw_predictions['Real_metaphors'] == 1]\n",
        "bert_metaphoras_otw = bert_metaphor_otw_df['Tokens'].values.tolist()\n",
        "\n",
        "\n",
        "# FrameBert Result to predictions\n",
        "\n",
        "bert_predictions_otw = []\n",
        "\n",
        "for test_sentence in test_sentences_otw_b:\n",
        "  metaphora = 0\n",
        "  for token in test_sentence:\n",
        "    if token in bert_metaphoras_otw:\n",
        "      metaphora = 1\n",
        "  bert_predictions_otw.append(metaphora)\n",
        "\n",
        "print(len(bert_predictions_otw))\n",
        "print(len(labels_test_otw_b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48zKkM5KwlFJ",
        "outputId": "2ab5bdb5-f81e-4b29-eff4-e1f2a9c74f2e"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "144\n",
            "144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate evaluation metrics for FrameBert in Ottawa data\n",
        "accuracy_otw_b = accuracy_score(labels_test_otw_b, bert_predictions_otw)\n",
        "precision_otw_b = precision_score(labels_test_otw_b, bert_predictions_otw)\n",
        "recall_otw_b = recall_score(labels_test_otw_b, bert_predictions_otw)\n",
        "f1_otw_b = f1_score(labels_test_otw_b, bert_predictions_otw)\n",
        "\n",
        "# Print the results\n",
        "print(\"Evaluation Metrics for Metaphor Detection:\")\n",
        "print(f\"Accuracy: {accuracy_otw_b*100:.4f} %\")\n",
        "print(f\"Precision: {precision_otw_b*100:.4f} %\")\n",
        "print(f\"Recall: {recall_otw_b*100:.4f} %\")\n",
        "print(f\"F1-Score: {f1_otw_b*100:.4f} %\")\n",
        "\n",
        "model_bert_new_row_otw = {'Dataset': 'Ottawa', 'Feature Length': 0, 'Model': 'BERT', 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-Score': f1}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Vy73LC7xmAS",
        "outputId": "09b118b2-0bca-4e41-8b2b-63121f8ca967"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics for Metaphor Detection:\n",
            "Accuracy: 47.9167 %\n",
            "Precision: 48.0769 %\n",
            "Recall: 34.2466 %\n",
            "F1-Score: 40.0000 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_oOigvRS6E2"
      },
      "source": [
        "8. Use appropriate literature to comment on the findings. Also, identify any additional input that would\n",
        "allow you to further elucidate any of the preceding, and use appropriate literature of corpus linguistic\n",
        "literature to justify your findings and comment on the obtained results. Finally, comment on the\n",
        "limitations and structural weakness of the data processing pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FrameBERT and Machine Learning Models:**\n",
        "FrameBERT uses frame embeddings to capture complex metaphors by understanding context with frame embedding and performing well in precision, recall, and F1-score especially for simple broad metaphor expressions.\n",
        "Traditional Models (e.g SVM, Naive Bayes): They are effective at detecting frequent and commmon metaphors.\n",
        "Ensemble Model: Combines multiple algorithms, enhancing generalization and accuracy for diverse poetic language.\n",
        "\n",
        "**Datasets:**\n",
        "VU Amsterdam Metaphor Corpus: Offers varied texts, a common dataset in this field and these tasks, helping models generalize across metaphor types.\n",
        "Uottawa Dataset: Labeling with annotations allows more detailed analysis, aiding interpretability and cross-domain performance.\n",
        "\n",
        "Adding more diverse metaphor datasets and text with plenty of figurative expressions (e.g. poetry and lyrics) and using data augmentation can improve generalization and capture less common metaphor types.\n",
        "\n",
        "**More discussion, analysis, related work and insights on the report paper!**"
      ],
      "metadata": {
        "id": "xxzTtTfWaDRN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Result and Data Conlusion**"
      ],
      "metadata": {
        "id": "lW_i2e7Bs2CW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# data set VUA result combination\n",
        "results_df.loc[len(results_df.index)] = model_3_new_row\n",
        "results_df.loc[len(results_df.index)] = model_bert_new_row\n",
        "\n",
        "# data set TOELF result combination\n",
        "results_df_toelf.loc[len(results_df_toelf.index)] = model_3_new_row_toelf\n",
        "results_df_toelf.loc[len(results_df_toelf.index)] = model_bert_new_row_toelf\n",
        "\n",
        "# data set Ottawa result combination\n",
        "results_df_otw.loc[len(results_df_otw.index)] = model_3_new_row_otw\n",
        "results_df_otw.loc[len(results_df_otw.index)] = model_bert_new_row_otw\n",
        "\n",
        "result_combined = pd.concat([results_df, results_df_toelf, results_df_otw])\n",
        "\n",
        "result_combined = result_combined.drop_duplicates()\n",
        "\n",
        "print(result_combined)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7T-4OdTltaNZ",
        "outputId": "0ac7e2ee-8414-4ac0-efe1-a42ccb009e25"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Dataset  Feature Length          Model  Accuracy  Precision    Recall  \\\n",
            "0      VUA             250    Naive Bayes  0.835545   0.832494  0.986476   \n",
            "1      VUA             250            SVM  0.832768   0.830429  0.985680   \n",
            "2      VUA             250  Logistic Reg.  0.836779   0.831829  0.989658   \n",
            "3      VUA             250            MLP  0.775687   0.775687  1.000000   \n",
            "4      VUA             500    Naive Bayes  0.842333   0.839147  0.985680   \n",
            "5      VUA             500            SVM  0.889540   0.966263  0.888624   \n",
            "6      VUA             500  Logistic Reg.  0.843567   0.839824  0.986476   \n",
            "7      VUA             500            MLP  0.775687   0.775687  1.000000   \n",
            "8      VUA            1000    Naive Bayes  0.845418   0.842231  0.985282   \n",
            "9      VUA            1000            SVM  0.915150   0.966264  0.922832   \n",
            "10     VUA            1000  Logistic Reg.  0.852823   0.847255  0.988465   \n",
            "11     VUA            1000            MLP  0.886455   0.971441  0.879475   \n",
            "12     VUA            3000    Naive Bayes  0.853440   0.846415  0.990851   \n",
            "13     VUA            3000            SVM  0.933971   0.960368  0.954256   \n",
            "14     VUA            3000  Logistic Reg.  0.863622   0.856749  0.989658   \n",
            "15     VUA            3000            MLP  0.887072   0.953931  0.897772   \n",
            "16     VUA            3000       Ensemble  0.925332   0.942712  0.962212   \n",
            "17     VUA               0           BERT  0.682197   0.992042  0.595068   \n",
            "0    TOEFL             250    Naive Bayes  0.631387   0.626016  0.330472   \n",
            "1    TOEFL             250            SVM  0.656934   0.639752  0.442060   \n",
            "2    TOEFL             250  Logistic Reg.  0.656934   0.643312  0.433476   \n",
            "3    TOEFL             250            MLP  0.602190   0.532468  0.527897   \n",
            "4    TOEFL             500    Naive Bayes  0.669708   0.683099  0.416309   \n",
            "5    TOEFL             500            SVM  0.664234   0.652174  0.450644   \n",
            "6    TOEFL             500  Logistic Reg.  0.655109   0.648649  0.412017   \n",
            "7    TOEFL             500            MLP  0.662409   0.613208  0.557940   \n",
            "8    TOEFL            1000    Naive Bayes  0.660584   0.669065  0.399142   \n",
            "9    TOEFL            1000            SVM  0.684307   0.678571  0.489270   \n",
            "10   TOEFL            1000  Logistic Reg.  0.658759   0.655405  0.416309   \n",
            "11   TOEFL            1000            MLP  0.642336   0.586047  0.540773   \n",
            "12   TOEFL            3000    Naive Bayes  0.667883   0.742857  0.334764   \n",
            "13   TOEFL            3000            SVM  0.677007   0.679487  0.454936   \n",
            "14   TOEFL            3000  Logistic Reg.  0.664234   0.702479  0.364807   \n",
            "15   TOEFL            3000            MLP  0.574818   0.000000  0.000000   \n",
            "16   TOEFL            3000       Ensemble  0.678832   0.717557  0.403433   \n",
            "17   TOEFL               0           BERT  0.582117   0.700000  0.030043   \n",
            "0   Ottawa             250    Naive Bayes  0.576389   0.625000  0.410959   \n",
            "1   Ottawa             250            SVM  0.576389   0.563830  0.726027   \n",
            "2   Ottawa             250  Logistic Reg.  0.583333   0.573034  0.698630   \n",
            "3   Ottawa             250            MLP  0.604167   0.700000  0.383562   \n",
            "4   Ottawa             500    Naive Bayes  0.555556   0.571429  0.493151   \n",
            "5   Ottawa             500            SVM  0.569444   0.560440  0.698630   \n",
            "6   Ottawa             500  Logistic Reg.  0.576389   0.569767  0.671233   \n",
            "7   Ottawa             500            MLP  0.534722   0.537500  0.589041   \n",
            "8   Ottawa            1000    Naive Bayes  0.583333   0.600000  0.534247   \n",
            "9   Ottawa            1000            SVM  0.541667   0.541176  0.630137   \n",
            "10  Ottawa            1000  Logistic Reg.  0.541667   0.542169  0.616438   \n",
            "11  Ottawa            1000            MLP  0.576389   0.583333  0.575342   \n",
            "12  Ottawa            3000    Naive Bayes  0.562500   0.565789  0.589041   \n",
            "13  Ottawa            3000            SVM  0.534722   0.536585  0.602740   \n",
            "14  Ottawa            3000  Logistic Reg.  0.541667   0.543210  0.602740   \n",
            "15  Ottawa            3000            MLP  0.493056   0.000000  0.000000   \n",
            "16  Ottawa            3000       Ensemble  0.582117   0.700000  0.030043   \n",
            "17  Ottawa               0           BERT  0.582117   0.700000  0.030043   \n",
            "\n",
            "    F1-Score  \n",
            "0   0.902967  \n",
            "1   0.901419  \n",
            "2   0.903906  \n",
            "3   0.873675  \n",
            "4   0.906530  \n",
            "5   0.925818  \n",
            "6   0.907262  \n",
            "7   0.873675  \n",
            "8   0.908158  \n",
            "9   0.944049  \n",
            "10  0.912429  \n",
            "11  0.923173  \n",
            "12  0.912956  \n",
            "13  0.957302  \n",
            "14  0.918420  \n",
            "15  0.925000  \n",
            "16  0.952362  \n",
            "17  0.743909  \n",
            "0   0.432584  \n",
            "1   0.522843  \n",
            "2   0.517949  \n",
            "3   0.530172  \n",
            "4   0.517333  \n",
            "5   0.532995  \n",
            "6   0.503937  \n",
            "7   0.584270  \n",
            "8   0.500000  \n",
            "9   0.568579  \n",
            "10  0.509186  \n",
            "11  0.562500  \n",
            "12  0.461538  \n",
            "13  0.544987  \n",
            "14  0.480226  \n",
            "15  0.000000  \n",
            "16  0.516484  \n",
            "17  0.057613  \n",
            "0   0.495868  \n",
            "1   0.634731  \n",
            "2   0.629630  \n",
            "3   0.495575  \n",
            "4   0.529412  \n",
            "5   0.621951  \n",
            "6   0.616352  \n",
            "7   0.562092  \n",
            "8   0.565217  \n",
            "9   0.582278  \n",
            "10  0.576923  \n",
            "11  0.579310  \n",
            "12  0.577181  \n",
            "13  0.567742  \n",
            "14  0.571429  \n",
            "15  0.000000  \n",
            "16  0.057613  \n",
            "17  0.057613  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vua_data toelf_data otw_data\n",
        "\n",
        "# Dataset information\n",
        "result_dataset_combined = pd.concat([\n",
        "    pd.DataFrame(vua_data),\n",
        "    pd.DataFrame(toelf_data),\n",
        "    pd.DataFrame(otw_data)\n",
        "    ])\n",
        "\n",
        "print(result_dataset_combined.round(2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdHmnwgX5guF",
        "outputId": "8af7c09c-4b7a-401e-9298-dfe82f6f1112"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Dataset             Measurement     Values\n",
            "0     VUA             Sent. count   16202.00\n",
            "1     VUA                  Tokens  113765.00\n",
            "2     VUA           Unique tokens   17883.00\n",
            "3     VUA      Avg token per sent       7.02\n",
            "4     VUA      sent with methapor    8326.00\n",
            "5     VUA      Testing sent count    3241.00\n",
            "6     VUA  How many with metaphor    2514.00\n",
            "0   toelf             Sent. count    2737.00\n",
            "1   toelf                  Tokens   26737.00\n",
            "2   toelf           Unique tokens    5224.00\n",
            "3   toelf      Avg token per sent       9.76\n",
            "4   toelf      sent with methapor    1124.00\n",
            "5   toelf      Testing sent count     548.00\n",
            "6   toelf  How many with metaphor     233.00\n",
            "0  Ottawa             Sent. count     719.00\n",
            "1  Ottawa                  Tokens   10319.00\n",
            "2  Ottawa           Unique tokens    2124.00\n",
            "3  Ottawa      Avg token per sent      14.35\n",
            "4  Ottawa      sent with methapor     358.00\n",
            "5  Ottawa      Testing sent count     144.00\n",
            "6  Ottawa  How many with metaphor      73.00\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}